#include <pthread.h>
#include <fstream>
#include <iostream>
#include <string>
#include <vector>

#include <paddle/capi.h>

#include "../common/common.h"

#define CONFIG_BIN "./network_config.bin"
#define NUM_THREAD 4

using namespace std;

int dnn_input_dim = 61;
int lr_input_dim = 10040001;

struct Thread_arg {
  paddle_gradient_machine machine;
  vector<int>* dnn_col_buf;
  vector<int>* dnn_row_buf;
  vector<int>* lr_col_buf;
  vector<int>* lr_row_buf;
  vector<float>* lr_value_buf;
  paddle_matrix ctr;
};

void* thread_main(void* arg_ptr) {
  struct Thread_arg* thread_arg_ptr = (struct Thread_arg*)arg_ptr;

  paddle_gradient_machine machine = thread_arg_ptr->machine;
  vector<int>* dnn_col_buf = thread_arg_ptr->dnn_col_buf;
  vector<int>* dnn_row_buf = thread_arg_ptr->dnn_row_buf;
  vector<int>* lr_col_buf = thread_arg_ptr->lr_col_buf;
  vector<int>* lr_row_buf = thread_arg_ptr->lr_row_buf;
  vector<float>* lr_value_buf = thread_arg_ptr->lr_value_buf;
  paddle_matrix ctr = thread_arg_ptr->ctr;
  int sample_num = dnn_row_buf->size() - 1;

  paddle_arguments in_args = paddle_arguments_create_none();

  // There are two inputs of this network.
  CHECK(paddle_arguments_resize(in_args, 2));

  // Create input matrix
  paddle_matrix dnn_input =
      paddle_matrix_create_sparse(sample_num, dnn_input_dim, 1, true, false);
  paddle_matrix lr_input =
      paddle_matrix_create_sparse(sample_num, lr_input_dim, 1, false, false);

  CHECK(paddle_matrix_sparse_copy_from(dnn_input,
                                       dnn_row_buf->data(),
                                       dnn_row_buf->size(),
                                       dnn_col_buf->data(),
                                       dnn_col_buf->size(),
                                       NULL,
                                       0));
  CHECK(paddle_matrix_sparse_copy_from(lr_input,
                                       lr_row_buf->data(),
                                       lr_row_buf->size(),
                                       lr_col_buf->data(),
                                       lr_col_buf->size(),
                                       lr_value_buf->data(),
                                       lr_value_buf->size()));

  CHECK(paddle_arguments_set_value(in_args, 0, dnn_input));
  CHECK(paddle_arguments_set_value(in_args, 1, lr_input));

  paddle_arguments out_args = paddle_arguments_create_none();

  CHECK(paddle_gradient_machine_forward(machine, in_args, out_args, false));
  CHECK(paddle_arguments_get_value(out_args, 0, ctr));

  CHECK(paddle_arguments_destroy(out_args));
  CHECK(paddle_matrix_destroy(dnn_input));
  CHECK(paddle_matrix_destroy(lr_input));
  CHECK(paddle_arguments_destroy(in_args));
  CHECK(paddle_gradient_machine_destroy(machine));
  return NULL;
}


int main() {
  // Initalize Paddle
  char* argv[] = {"--use_gpu=False"};
  CHECK(paddle_init(1, (char**)argv));

  // Reading config binary file. It is generated by `convert_protobin.sh`
  long size;
  void* config_buf = read_config(CONFIG_BIN, &size);

  const char* model_path = "./ctr_model";
  const char* infer_data_path = "../../ctr/output/infer.txt";

  int sample_num = 4;

  vector<vector<int>> thread_dnn_col;
  vector<vector<int>> thread_dnn_row;
  vector<vector<int>> thread_lr_col;
  vector<vector<int>> thread_lr_row;
  vector<vector<float>> thread_lr_value;

  ifstream file;
  file.open(infer_data_path);

  for (int i = 0; i < NUM_THREAD; ++i) {
    vector<int> dnn_col_vec;
    vector<int> dnn_row_vec;
    vector<int> lr_col_vec;
    vector<int> lr_row_vec;
    vector<float> lr_value_vec;

    dnn_row_vec.push_back(0);
    lr_row_vec.push_back(0);

    string str;
    for (int num = 0; num < sample_num; ++num) {
      getline(file, str);

      size_t split_pos = str.find_first_of("\t", 0);

      dnn_col_vec.push_back(stoi(str));
      for (size_t pos = 0; pos < split_pos; ++pos) {
        if (str.at(pos) == ' ') {
          dnn_col_vec.push_back(stoi(str.substr(pos)));
        }
      }
      dnn_row_vec.push_back(dnn_col_vec.size());

      lr_col_vec.push_back(stoi(str.substr(split_pos)));
      for (size_t pos = split_pos; pos < str.length(); ++pos) {
        if (str.at(pos) == ':') {
          lr_value_vec.push_back(stof(str.substr(pos + 1)));
        } else if (str.at(pos) == ' ') {
          lr_col_vec.push_back(stoi(str.substr(pos)));
        }
      }
      lr_row_vec.push_back(lr_col_vec.size());
    }

    thread_dnn_col.push_back(dnn_col_vec);
    thread_dnn_row.push_back(dnn_row_vec);
    thread_lr_col.push_back(lr_col_vec);
    thread_lr_row.push_back(lr_row_vec);
    thread_lr_value.push_back(lr_value_vec);
  }

  file.close();

  // Create a gradient machine for inference.
  paddle_gradient_machine machine;
  CHECK(paddle_gradient_machine_create_for_inference(
      &machine, config_buf, (int)size));
  // Loading parameter.
  CHECK(paddle_gradient_machine_load_parameter_from_disk(machine, model_path));

  pthread_t threads[NUM_THREAD];
  struct Thread_arg thread_args[NUM_THREAD];
  paddle_matrix ctr[NUM_THREAD];

  for (int i = 0; i < NUM_THREAD; ++i) {
    paddle_gradient_machine thread_local_machine;
    CHECK(paddle_gradient_machine_create_shared_param(
        machine, config_buf, size, &thread_local_machine));
    ctr[i] = paddle_arguments_create_none();
    ;

    thread_args[i].machine = thread_local_machine;
    thread_args[i].dnn_row_buf = &thread_dnn_row[i];
    thread_args[i].dnn_col_buf = &thread_dnn_col[i];
    thread_args[i].lr_row_buf = &thread_lr_row[i];
    thread_args[i].lr_col_buf = &thread_lr_col[i];
    thread_args[i].lr_value_buf = &thread_lr_value[i];
    thread_args[i].ctr = ctr[i];

    pthread_create(&threads[i], NULL, thread_main, (void*)(thread_args + i));
  }

  for (int i = 0; i < NUM_THREAD; ++i) {
    pthread_join(threads[i], NULL);

    paddle_real* array;
    CHECK(paddle_matrix_get_row(ctr[i], 0, &array));

    for (int num = 0; num < sample_num; ++num) {
      cout << array[num] << endl;
    }

    CHECK(paddle_matrix_destroy(ctr[i]));
  }

  return 0;
}