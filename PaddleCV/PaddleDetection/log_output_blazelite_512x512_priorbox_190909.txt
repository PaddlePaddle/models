[33mdocstring_parser is not installed, argument description is not available[0m
conv1:(-1L, 24L, 256L, 256L)
conv2_dw:(-1L, 24L, 256L, 256L)
conv2_sep:(-1L, 24L, 256L, 256L)
conv3_dw:(-1L, 24L, 256L, 256L)
conv3_sep:(-1L, 28L, 256L, 256L)
shortcutconv3:(-1L, 28L, 256L, 256L)
conv4_dw:(-1L, 28L, 128L, 128L)
conv4_sep:(-1L, 32L, 128L, 128L)
shortcutconv4:(-1L, 32L, 128L, 128L)
conv5_dw:(-1L, 32L, 128L, 128L)
conv5_sep:(-1L, 36L, 128L, 128L)
shortcutconv5:(-1L, 36L, 128L, 128L)
conv6_dw:(-1L, 36L, 128L, 128L)
conv6_sep:(-1L, 42L, 128L, 128L)
shortcutconv6:(-1L, 42L, 128L, 128L)
conv7_dw:(-1L, 42L, 64L, 64L)
conv7_sep:(-1L, 48L, 64L, 64L)
shortcutconv7:(-1L, 48L, 64L, 64L)
conv8_dw:(-1L, 48L, 64L, 64L)
conv8_sep:(-1L, 56L, 64L, 64L)
shortcutconv8:(-1L, 56L, 64L, 64L)
conv9_dw:(-1L, 56L, 64L, 64L)
conv9_sep:(-1L, 64L, 64L, 64L)
shortcutconv9:(-1L, 64L, 64L, 64L)
conv10_dw:(-1L, 64L, 64L, 64L)
conv10_sep:(-1L, 72L, 64L, 64L)
shortcutconv10:(-1L, 72L, 64L, 64L)
conv11_dw:(-1L, 72L, 64L, 64L)
conv11_sep:(-1L, 80L, 64L, 64L)
shortcutconv11:(-1L, 80L, 64L, 64L)
conv12_dw:(-1L, 80L, 64L, 64L)
conv12_sep:(-1L, 88L, 64L, 64L)
shortcutconv12:(-1L, 88L, 64L, 64L)
conv13_dw:(-1L, 88L, 32L, 32L)
conv13_sep:(-1L, 96L, 32L, 32L)
shortcutconv13:(-1L, 96L, 32L, 32L)
conv14_dw:(-1L, 96L, 32L, 32L)
conv14_sep:(-1L, 96L, 32L, 32L)
conv15_dw:(-1L, 96L, 32L, 32L)
conv15_sep:(-1L, 96L, 32L, 32L)
conv16_dw:(-1L, 96L, 32L, 32L)
conv16_sep:(-1L, 96L, 32L, 32L)
conv17_dw:(-1L, 96L, 32L, 32L)
conv17_sep:(-1L, 96L, 32L, 32L)
[ygh-debug] num_boxes:(64L, 64L, 2L, 4L)
[ygh-debug] num_boxes:2
[ygh-debug] num_boxes:(32L, 32L, 6L, 4L)
[ygh-debug] num_boxes:6
2019-09-09 20:10:28,236-INFO: 12880 samples in file /home/users/yuehaixiao/workspace/data/WIDERFACE/wider_face_split/wider_face_train_bbx_gt.txt
2019-09-09 20:10:28,394-WARNING: 
     You can try our memory optimize feature to save your memory usage:
         # create a build_strategy variable to set memory optimize option
         build_strategy = compiler.BuildStrategy()
         build_strategy.enable_inplace = True
         build_strategy.memory_optimize = True
         
         # pass the build_strategy to with_data_parallel API
         compiled_prog = compiler.CompiledProgram(main).with_data_parallel(
             loss_name=loss.name, build_strategy=build_strategy)
      
     !!! Memory optimize is our experimental feature !!!
         some variables may be removed/reused internal to save memory usage, 
         in order to fetch the right value of the fetch_list, please set the 
         persistable property to true for each variable in fetch_list

         # Sample
         conv1 = fluid.layers.conv2d(data, 4, 5, 1, act=None) 
         # if you need to fetch conv1, then:
         conv1.persistable = True

                 
W0909 20:10:34.926568 24230 device_context.cc:259] Please NOTE: device: 0, CUDA Capability: 61, Driver API Version: 9.0, Runtime API Version: 9.0
W0909 20:10:34.941975 24230 device_context.cc:267] device: 0, cuDNN Version: 7.0.
W0909 20:10:34.942047 24230 device_context.cc:293] WARNING: device: 0. The installed Paddle is compiled with CUDNN 7.3, but CUDNN version in your machine is 7.0, which may cause serious incompatible bug. Please recompile or reinstall Paddle with compatible CUDNN version.
I0909 20:10:35.115084 24230 parallel_executor.cc:329] The number of CUDAPlace, which is used in ParallelExecutor, is 1. And the Program will be copied 1 copies
I0909 20:10:35.273705 24230 build_strategy.cc:340] SeqOnlyAllReduceOps:0, num_trainers:1
2019-09-09 20:10:39,873-INFO: iter: 0, lr: 0.002000, 'loss': '62.319981', time: 0.006, eta: 0:17:22
2019-09-09 20:10:51,081-INFO: iter: 20, lr: 0.002000, 'loss': '25.030979', time: 0.766, eta: 1 day, 14:17:29
2019-09-09 20:11:11,412-INFO: iter: 40, lr: 0.002000, 'loss': '23.715706', time: 1.024, eta: 2 days, 3:11:06
2019-09-09 20:11:35,250-INFO: iter: 60, lr: 0.002000, 'loss': '19.830383', time: 1.180, eta: 2 days, 10:58:01
2019-09-09 20:11:53,034-INFO: iter: 80, lr: 0.002000, 'loss': '18.527683', time: 0.898, eta: 1 day, 20:52:18
2019-09-09 20:12:17,110-INFO: iter: 100, lr: 0.002000, 'loss': '18.075958', time: 1.168, eta: 2 days, 10:20:54
2019-09-09 20:12:38,101-INFO: iter: 120, lr: 0.002000, 'loss': '18.599855', time: 1.101, eta: 2 days, 7:02:12
2019-09-09 20:12:56,387-INFO: iter: 140, lr: 0.002000, 'loss': '19.532610', time: 0.886, eta: 1 day, 20:16:33
2019-09-09 20:13:13,839-INFO: iter: 160, lr: 0.002000, 'loss': '20.035835', time: 0.897, eta: 1 day, 20:48:26
2019-09-09 20:13:29,160-INFO: iter: 180, lr: 0.002000, 'loss': '16.950882', time: 0.743, eta: 1 day, 13:07:42
2019-09-09 20:13:46,038-INFO: iter: 200, lr: 0.002000, 'loss': '19.584486', time: 0.854, eta: 1 day, 18:40:07
2019-09-09 20:14:02,946-INFO: iter: 220, lr: 0.002000, 'loss': '17.266394', time: 0.816, eta: 1 day, 16:45:26
2019-09-09 20:14:20,547-INFO: iter: 240, lr: 0.002000, 'loss': '15.852436', time: 0.903, eta: 1 day, 21:06:03
2019-09-09 20:14:40,961-INFO: iter: 260, lr: 0.002000, 'loss': '17.840422', time: 0.993, eta: 2 days, 1:35:00
2019-09-09 20:14:57,623-INFO: iter: 280, lr: 0.002000, 'loss': '16.064707', time: 0.855, eta: 1 day, 18:40:44
2019-09-09 20:15:13,871-INFO: iter: 300, lr: 0.002000, 'loss': '12.866518', time: 0.824, eta: 1 day, 17:06:32
2019-09-09 20:15:28,090-INFO: iter: 320, lr: 0.002000, 'loss': '13.630016', time: 0.709, eta: 1 day, 11:23:43
2019-09-09 20:15:47,704-INFO: iter: 340, lr: 0.002000, 'loss': '16.988674', time: 0.984, eta: 2 days, 1:07:04
2019-09-09 20:16:05,406-INFO: iter: 360, lr: 0.002000, 'loss': '14.173737', time: 0.881, eta: 1 day, 19:58:55
2019-09-09 20:16:19,337-INFO: iter: 380, lr: 0.002000, 'loss': '14.862745', time: 0.702, eta: 1 day, 11:00:49
2019-09-09 20:16:30,062-INFO: iter: 400, lr: 0.002000, 'loss': '14.109184', time: 0.541, eta: 1 day, 2:59:06
2019-09-09 20:16:42,201-INFO: iter: 420, lr: 0.002000, 'loss': '12.977488', time: 0.611, eta: 1 day, 6:28:36
2019-09-09 20:16:51,743-INFO: iter: 440, lr: 0.002000, 'loss': '13.437583', time: 0.481, eta: 23:58:36
2019-09-09 20:17:04,059-INFO: iter: 460, lr: 0.002000, 'loss': '13.356640', time: 0.604, eta: 1 day, 6:06:11
2019-09-09 20:17:16,178-INFO: iter: 480, lr: 0.002000, 'loss': '13.500443', time: 0.609, eta: 1 day, 6:21:06
2019-09-09 20:17:29,953-INFO: iter: 500, lr: 0.002000, 'loss': '13.588191', time: 0.689, eta: 1 day, 10:19:49
2019-09-09 20:17:43,758-INFO: iter: 520, lr: 0.002000, 'loss': '12.841953', time: 0.685, eta: 1 day, 10:10:20
2019-09-09 20:17:58,961-INFO: iter: 540, lr: 0.002000, 'loss': '13.958750', time: 0.755, eta: 1 day, 13:38:59
2019-09-09 20:18:13,793-INFO: iter: 560, lr: 0.002000, 'loss': '13.134064', time: 0.730, eta: 1 day, 12:21:44
2019-09-09 20:18:31,823-INFO: iter: 580, lr: 0.002000, 'loss': '13.188567', time: 0.938, eta: 1 day, 22:45:00
2019-09-09 20:18:44,959-INFO: iter: 600, lr: 0.002000, 'loss': '12.112755', time: 0.639, eta: 1 day, 7:50:26
2019-09-09 20:18:58,570-INFO: iter: 620, lr: 0.002000, 'loss': '11.571497', time: 0.672, eta: 1 day, 9:27:37
2019-09-09 20:19:09,613-INFO: iter: 640, lr: 0.002000, 'loss': '12.071215', time: 0.550, eta: 1 day, 3:23:03
2019-09-09 20:19:21,490-INFO: iter: 660, lr: 0.002000, 'loss': '12.582127', time: 0.604, eta: 1 day, 6:05:12
2019-09-09 20:19:37,301-INFO: iter: 680, lr: 0.002000, 'loss': '11.368156', time: 0.773, eta: 1 day, 14:30:36
2019-09-09 20:19:49,383-INFO: iter: 700, lr: 0.002000, 'loss': '13.469424', time: 0.617, eta: 1 day, 6:43:02
2019-09-09 20:20:01,713-INFO: iter: 720, lr: 0.002000, 'loss': '12.067556', time: 0.632, eta: 1 day, 7:29:14
2019-09-09 20:20:15,694-INFO: iter: 740, lr: 0.002000, 'loss': '14.021125', time: 0.707, eta: 1 day, 11:13:11
2019-09-09 20:20:24,838-INFO: iter: 760, lr: 0.002000, 'loss': '11.561380', time: 0.440, eta: 21:54:58
2019-09-09 20:20:39,348-INFO: iter: 780, lr: 0.002000, 'loss': '11.710260', time: 0.721, eta: 1 day, 11:53:41
2019-09-09 20:20:50,963-INFO: iter: 800, lr: 0.002000, 'loss': '12.293962', time: 0.593, eta: 1 day, 5:31:30
2019-09-09 20:21:05,649-INFO: iter: 820, lr: 0.002000, 'loss': '13.169966', time: 0.738, eta: 1 day, 12:43:03
2019-09-09 20:21:16,260-INFO: iter: 840, lr: 0.002000, 'loss': '11.444817', time: 0.537, eta: 1 day, 2:43:38
2019-09-09 20:21:27,055-INFO: iter: 860, lr: 0.002000, 'loss': '12.883325', time: 0.511, eta: 1 day, 1:26:12
2019-09-09 20:21:37,679-INFO: iter: 880, lr: 0.002000, 'loss': '13.079483', time: 0.560, eta: 1 day, 3:51:33
2019-09-09 20:21:50,293-INFO: iter: 900, lr: 0.002000, 'loss': '11.722790', time: 0.608, eta: 1 day, 6:14:24
2019-09-09 20:22:01,506-INFO: iter: 920, lr: 0.002000, 'loss': '11.343766', time: 0.544, eta: 1 day, 3:04:15
2019-09-09 20:22:14,308-INFO: iter: 940, lr: 0.002000, 'loss': '10.720986', time: 0.669, eta: 1 day, 9:15:17
2019-09-09 20:22:27,542-INFO: iter: 960, lr: 0.002000, 'loss': '11.334680', time: 0.672, eta: 1 day, 9:24:39
2019-09-09 20:22:40,966-INFO: iter: 980, lr: 0.002000, 'loss': '12.667932', time: 0.638, eta: 1 day, 7:42:18
2019-09-09 20:22:53,845-INFO: iter: 1000, lr: 0.002000, 'loss': '12.009016', time: 0.646, eta: 1 day, 8:05:54
2019-09-09 20:23:06,345-INFO: iter: 1020, lr: 0.002000, 'loss': '11.894291', time: 0.644, eta: 1 day, 8:01:50
2019-09-09 20:23:18,821-INFO: iter: 1040, lr: 0.002000, 'loss': '11.178143', time: 0.583, eta: 1 day, 4:58:55
2019-09-09 20:23:31,353-INFO: iter: 1060, lr: 0.002000, 'loss': '10.130476', time: 0.675, eta: 1 day, 9:34:33
2019-09-09 20:23:44,277-INFO: iter: 1080, lr: 0.002000, 'loss': '10.031537', time: 0.625, eta: 1 day, 7:02:53
2019-09-09 20:23:56,811-INFO: iter: 1100, lr: 0.002000, 'loss': '11.016607', time: 0.643, eta: 1 day, 7:56:39
