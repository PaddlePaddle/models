#copyright (c) 2019 PaddlePaddle Authors. All Rights Reserve.
#
#Licensed under the Apache License, Version 2.0 (the "License");
#you may not use this file except in compliance with the License.
#You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
#Unless required by applicable law or agreed to in writing, software
#distributed under the License is distributed on an "AS IS" BASIS,
#WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#See the License for the specific language governing permissions and
#limitations under the License.

from __future__ import absolute_import 
from __future__ import division
from __future__ import print_function

import os
import numpy as np
import time
import sys
import functools
import math

def set_paddle_flags(flags): 
    for key, value in flags.items():
        if os.environ.get(key, None) is None:
            os.environ[key] = str(value)

# NOTE(paddle-dev): All of these flags should be
# set before `import paddle`. Otherwise, it would
# not take any effect. 
set_paddle_flags({
    'FLAGS_eager_delete_tensor_gb': 0,  # enable gc 
    'FLAGS_fraction_of_gpu_memory_to_use': 0.98
})
import argparse  
import functools
import subprocess

import paddle
import paddle.fluid as fluid
import paddle.dataset.flowers as flowers
import reader_cv2 as reader
import utils
import models
from utils.fp16_utils import create_master_params_grads, master_param_to_train_param
from utils.utility import add_arguments, print_arguments,parse_args, check_args, get_device_num, create_pyreader, best_strategy, print_info, init_from
from utils.learning_rate import  Decay

from dist_train import dist_utils
from utils.metrics import Metrics, create_metrics

num_trainers = int(os.environ.get('PADDLE_TRAINERS_NUM', 1))

##add preprocess on gpu in future 
##add visreader in future ##add multiprocess in future
## multi card test prog
def build_program(is_train, main_prog, startup_prog, args):
    """ 
    return : 
    train: [Measurement, global_lr, py_reader]
    test: [Measurement, py_reader]
    """
    model_name = args.model
    model = models.__dict__[model_name]()
    with fluid.program_guard(main_prog, startup_prog):
        #main_prog.random_seed = args.random_seed
        #startup_prog.random_seed = args.random_seed
        
        with fluid.unique_name.guard():
            ### create pyreader
            py_reader, data = create_pyreader(is_train, args)
            #data = fluid.layers.read_file(py_reader)
    
            metrics = create_metrics(data, model, args, is_train)
            ### return out: [avg_cost, ...]
            out = metrics.out()
            ### add backward op in program
            if is_train:
                decay = Decay(args)
                optimizer = getattr(decay, args.lr_strategy)()
                ###NOTE: build build_program_out after minimize?
                optimizer.minimize(out[0])
                global_lr = optimizer._global_learning_rate()
                global_lr.persistable=True
                out.append(global_lr)
            out.append(py_reader)
    return out

### yield batch data

def train(args):
    startup_prog = fluid.Program()
    train_prog = fluid.Program()
    test_prog = fluid.Program()

    b_train_out = build_program(is_train=True,main_prog=train_prog,startup_prog=startup_prog,args=args)
    ### TODO:need to extract cost 
    train_py_reader = b_train_out[-1]
    train_fetch_vars = b_train_out[:-1]
    #train_fetch_list = [var.name for var in train_fetch_vars]
    train_fetch_list = []
    for var in train_fetch_vars:
        var.persistable = True
        train_fetch_list.append(var.name)
    #print(train_fetch_list)

    b_test_out = build_program(is_train=False,main_prog=test_prog,startup_prog=startup_prog,args=args)
    test_py_reader = b_test_out[-1]
    test_fetch_vars = b_test_out[:-1]
    test_fetch_list = [var.name for var in test_fetch_vars]

    gpu_id = int(os.environ.get('FLAGS_selected_gpus', 0))
    place = fluid.CUDAPlace(gpu_id) if args.use_gpu else fluid.CPUPlace() 
    exe = fluid.Executor(place)
    exe.run(startup_prog)

    init_from(exe, args, train_prog)
    
    # NOTE: the order of batch data generated by batch_reader
    # must be the same in the respective processes.
    shuffle_seed = 1 if num_trainers > 1 else None

    train_reader = reader.train(settings=args, shuffle_seed=shuffle_seed)
    test_reader = reader.val(settings=args)
    #train_py_reader.decorate_paddle_reader(train_reader)
    train_py_reader.decorate_sample_list_generator(train_reader, place)
    #test_py_reader.decorate_paddle_reader(test_reader)
    test_py_reader.decorate_sample_list_generator(test_reader, place)

    train_exe = best_strategy(args, train_prog, train_fetch_vars[0])
    
    for pass_id in range(args.num_epochs):
        train_batch_id = 0
        test_batch_id = 0
        train_batch_time_record = []
        test_batch_time_record = []
        train_batch_metrics_record = []
        test_batch_metrics_record = []

        train_py_reader.start()
        try:
            while True:

                t1 = time.time()
                train_batch_metrics = train_exe.run(fetch_list = train_fetch_list)
                #print(train_batch_metrics)
                t2 = time.time()
                train_batch_elapse = t2-t1
                train_batch_time_record.append(train_batch_elapse)

                train_batch_metrics_avg = np.mean(np.array(train_batch_metrics),axis=1)
                train_batch_metrics_record.append(train_batch_metrics_avg)
        
                print_info(pass_id, train_batch_id, args.print_step, train_batch_metrics_avg, train_batch_elapse, "batch")
                sys.stdout.flush()
                train_batch_id += 1

        except fluid.core.EOFException:
            train_py_reader.reset()
        
        test_py_reader.start()
        try:
            while True:
                t1 = time.time()
                test_batch_metrics = exe.run(program = test_prog, fetch_list = test_fetch_list)
                t2 = time.time()
                test_batch_elapse = t2-t1
                test_batch_time_record.append(test_batch_elapse)

                test_batch_metrics_avg = np.mean(np.array(test_batch_metrics),axis=1)
                test_batch_metrics_record.append(test_batch_metrics_avg)

                print_info(pass_id, test_batch_id, args.print_step, test_batch_metrics_avg, test_batch_elapse, "batch")
                sys.stdout.flush()
                test_batch_id += 1

        except fluid.core.EOFException:
            test_py_reader.reset()



        train_epoch_time_avg = np.mean(np.array(train_batch_time_record))
        train_epoch_metrics_avg = np.mean(np.array(train_batch_metrics_record),axis=0)

        test_epoch_time_avg = np.mean(np.array(test_batch_time_record))
        test_epoch_metrics_avg = np.mean(np.array(test_batch_metrics_record),axis=0)
        # 0 -> 1
        print_info(pass_id, 0, 0, train_epoch_metrics_avg+test_epoch_metrics_avg, 0, "epoch")


        #model_path = os.path.join(model_save_dir + '/' + model_name, str(pass_id))
        #if not os.path.isdir(model_path):
        #    os.makedirs(model_path)
        #fluid.io.save_persistables(exe, model_path, main_program=train_prog)

def main() : 
    args = parse_args()
    print_arguments(args)
    check_args(args)
    train(args)

if __name__ == '__main__': 
    main()
