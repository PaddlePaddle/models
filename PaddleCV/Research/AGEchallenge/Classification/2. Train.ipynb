{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Angle closure Glaucoma Evaluation Challenge](https://age.grand-challenge.org/Details/)\n",
    "## Angle closure classification Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "- Assume `Training100.zip` and `Validation_ASOCT_Image.zip` are stored @ `./AGE_challenge Baseline/datasets/`\n",
    "- Assume `weights` are stored @ `./AGE_challenge Baseline/weights/`\n",
    "- In training phase, we use standard ResNet34 with `sigmoid(fc(1))` output\n",
    "- We split a single image into two parts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download ImageNet weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-08-06 13:36:07--  https://paddle-imagenet-models-name.bj.bcebos.com/ResNet34_pretrained.tar\n",
      "Resolving paddle-imagenet-models-name.bj.bcebos.com (paddle-imagenet-models-name.bj.bcebos.com)... 220.181.33.44, 220.181.33.43\n",
      "Connecting to paddle-imagenet-models-name.bj.bcebos.com (paddle-imagenet-models-name.bj.bcebos.com)|220.181.33.44|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 87470080 (83M) [application/x-tar]\n",
      "Saving to: ‘../weights/ResNet34_pretrained.tar’\n",
      "\n",
      "ResNet34_pretrained 100%[===================>]  83.42M  1.80MB/s    in 66s     \n",
      "\n",
      "2019-08-06 13:37:13 (1.27 MB/s) - ‘../weights/ResNet34_pretrained.tar’ saved [87470080/87470080]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/PaddlePaddle/models/tree/develop/PaddleCV/image_classification\n",
    "!rm ../weights/ResNet34_pretrained.tar \n",
    "!rm -rf ../weights/ResNet34_pretrained\n",
    "\n",
    "!wget -P ../weights/ https://paddle-imagenet-models-name.bj.bcebos.com/ResNet34_pretrained.tar \n",
    "!tar xvf ../weights/ResNet34_pretrained.tar -C ../weights/ > /dev/null # silent\n",
    "!rm ../weights/ResNet34_pretrained/fc*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, functools, math\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Verify Fluid Program ... \n",
      "Your Paddle Fluid works well on SINGLE GPU or CPU.\n",
      "Your Paddle Fluid works well on MUTIPLE GPU or CPU.\n",
      "Your Paddle Fluid is installed successfully! Let's start deep Learning with Paddle Fluid now\n"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "import paddle.fluid as fluid\n",
    "import paddle.fluid.layers as FL\n",
    "import paddle.fluid.optimizer as FO\n",
    "fluid.install_check.run_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resnet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root_path = \"../datasets/Training100/\"\n",
    "image_path = os.path.join(data_root_path, \"ASOCT_Image\")\n",
    "\n",
    "train_file_path = os.path.join(data_root_path, \"cls_train_split.csv\")\n",
    "val_file_path = os.path.join(data_root_path, \"cls_val_split.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32 // 2 # image split * 2\n",
    "THREAD = 8\n",
    "BUF_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real time data augmentation in training\n",
    "\n",
    "def rotate_image(image, angle=90, scale=1.0):\n",
    "    '''\n",
    "    Rotate the image\n",
    "    :param image: image to be processed\n",
    "    :param angle: Rotation angle in degrees. Positive values mean counter-clockwise rotation (the coordinate origin is assumed to be the top-left corner).\n",
    "    :param scale: Isotropic scale factor.\n",
    "    '''\n",
    "    w = image.shape[1]\n",
    "    h = image.shape[0]\n",
    "    #rotate matrix\n",
    "    M = cv2.getRotationMatrix2D((w/2,h/2), angle, scale)\n",
    "    #rotate\n",
    "    image = cv2.warpAffine(image,M,(w,h))\n",
    "    return image\n",
    "\n",
    "def vflip_image(image):\n",
    "    return cv2.flip(image, flipCode=1)\n",
    "\n",
    "def crop_image(img, target_size, center):\n",
    "    \"\"\" crop_image \"\"\"\n",
    "    height, width = img.shape[:2]\n",
    "    size = target_size\n",
    "    if center == True:\n",
    "        w_start = (width - size) // 2\n",
    "        h_start = (height - size) // 2\n",
    "    else:\n",
    "        w_start = np.random.randint(0, width - size + 1)\n",
    "        h_start = np.random.randint(0, height - size + 1)\n",
    "    w_end = w_start + size\n",
    "    h_end = h_start + size\n",
    "    img = img[h_start:h_end, w_start:w_end, :]\n",
    "    return img\n",
    "\n",
    "def split_image(img):\n",
    "    rows,_,_ = img.shape\n",
    "    # left, right split\n",
    "    return [img[:, :rows, :], img[:, -rows:, :]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data reader and xmap wrapper to enable multiprocessing data load\n",
    "\n",
    "def reader(img_path, file_list, batch_size=32, shuffle=True, shuffle_seed=42):\n",
    "    def read_file_list():\n",
    "        batch_data = []\n",
    "        np.random.shuffle(file_list)\n",
    "        for line in file_list:\n",
    "            single_img_path, l_label, r_label = line.split(\",\")\n",
    "            batch_data.append([single_img_path, int(l_label), int(r_label)])\n",
    "            if len(batch_data) == batch_size:\n",
    "                yield batch_data\n",
    "                batch_data = []\n",
    "        if len(batch_data) != 0:\n",
    "            yield batch_data\n",
    "    return read_file_list\n",
    "\n",
    "def process_batch_data(input_data, mode, rotate=True, flip=True):\n",
    "    batch_data = []\n",
    "    for sample in input_data:\n",
    "        file, l_label, r_label = sample\n",
    "\n",
    "        img = cv2.imread( file )\n",
    "        img = img[:, :, ::-1].astype('float32') / 255\n",
    "        \n",
    "        img = np.concatenate(split_image(img), axis=-1) # concat at channel dim\n",
    "        img = cv2.resize(img, (256, 256))\n",
    "        \n",
    "        if mode == 'train':\n",
    "            img = crop_image(img, target_size=224, center=False)\n",
    "#             img = img + np.random.randn(*img.shape) * 0.3 / 255 \n",
    "            if rotate:\n",
    "                angle = np.random.randint(1, 30, size=1)\n",
    "                img = rotate_image(img, angle)\n",
    "            if flip and np.random.randint(0,2):\n",
    "                img = vflip_image(img)\n",
    "        else:\n",
    "            img = crop_image(img, target_size=224, center=True)\n",
    "        \n",
    "        img = img.transpose((2, 0, 1))\n",
    "\n",
    "        batch_data.append((img[:3,:,:], l_label))\n",
    "        batch_data.append((img[3:,:,:], r_label))\n",
    "\n",
    "    return batch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(img_list, img_path, batch_size, order=False, mode='train'):\n",
    "    data_reader = reader(img_path, img_list, batch_size)\n",
    "    mapper = functools.partial(process_batch_data, mode=mode)\n",
    "    \n",
    "    data_reader = paddle.reader.shuffle(data_reader, 32)\n",
    "    \n",
    "    return paddle.reader.xmap_readers(\n",
    "        mapper, data_reader, THREAD, BUF_SIZE, order=order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_file_path) as flist:\n",
    "    train_file_list = [os.path.join(image_path,line.strip()) for line in flist]\n",
    "\n",
    "with open(val_file_path) as flist:\n",
    "    val_file_list = [os.path.join(image_path,line.strip()) for line in flist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1296\n",
      "304\n",
      "../datasets/Training100/ASOCT_Image/T0047-06.jpg,1,1\n"
     ]
    }
   ],
   "source": [
    "print(len(train_file_list))\n",
    "print(len(val_file_list))\n",
    "\n",
    "print(train_file_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(train_file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1072, 224]\n"
     ]
    }
   ],
   "source": [
    "# Class imbalance\n",
    "classes_collaction = [0] * 2\n",
    "for line in train_file_list:\n",
    "    file, c_l, c_r = line.split(\",\")\n",
    "    classes_collaction[int(c_l)] +=1\n",
    "    \n",
    "print(classes_collaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = data_loader(train_file_list, image_path, BATCH_SIZE, False, mode='train')\n",
    "val_dataloader = data_loader(val_file_list, image_path, BATCH_SIZE, True, mode='val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model (compute graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network():\n",
    "    data_shape = [3, 224, 224]\n",
    "    \n",
    "    model = ResNet34()\n",
    "    \n",
    "    input_feature = FL.data(name='pixel', shape=data_shape, dtype='float32')\n",
    "    label = FL.data(name='label', shape=[1], dtype='int64')\n",
    "    \n",
    "    logit = model.net(input_feature, class_dim=1)\n",
    "    predict = FL.sigmoid(logit)\n",
    "\n",
    "    reader = fluid.io.PyReader(feed_list=[input_feature, label], \n",
    "                         capacity=64, iterable=True, use_double_buffer=True)\n",
    "\n",
    "    cost = FL.log_loss(predict, FL.cast(label, \"float32\"), epsilon=1e-7)\n",
    "    loss = FL.mean(cost)\n",
    "\n",
    "    accuracy = FL.mean(FL.cast(FL.equal(FL.cast(FL.round(predict),\"int64\"), label), \"float32\") )\n",
    "    \n",
    "    return [loss, accuracy, predict, reader]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_auc_numpy(y_pred, y_true):\n",
    "    auc = roc_auc_score(y_true, y_pred)\n",
    "\n",
    "    fpr, tpr, thresh = roc_curve(y_true, y_pred)\n",
    "    optimal_idx = np.argmax(tpr - fpr)\n",
    "    \n",
    "    print(\"Best Sensi: %1.4f\" % (tpr[optimal_idx]))\n",
    "    print(\"Best Speci: %1.4f\" % (1-fpr[optimal_idx]))\n",
    "    print(\"Best Thresh: %1.4f\" % (thresh[optimal_idx]))\n",
    "    \n",
    "    y_pred = (y_pred > 0.5).astype(np.int_)\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    \n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(use_cuda, params_dirname_prefix, pretrained_model=False, EPOCH_NUM=10):\n",
    "    place = fluid.CUDAPlace(0) if use_cuda else fluid.CPUPlace()\n",
    "    \n",
    "    startup_prog = fluid.Program()\n",
    "    train_prog = fluid.Program()\n",
    "    val_prog = fluid.Program()\n",
    "\n",
    "    with fluid.program_guard(train_prog, startup_prog):\n",
    "        # fluid.unique_name.guard() to share parameters with test network\n",
    "        with fluid.unique_name.guard():\n",
    "            train_loss, train_acc, train_output, train_reader = network()\n",
    "            \n",
    "            optimizer = fluid.optimizer.Adam(learning_rate=1e-4)\n",
    "            optimizer.minimize(train_loss)\n",
    "    \n",
    "    # 定义预测网络\n",
    "    with fluid.program_guard(val_prog, startup_prog):\n",
    "        # Use fluid.unique_name.guard() to share parameters with train network\n",
    "        with fluid.unique_name.guard():\n",
    "            val_loss, val_acc, val_output, val_reader = network()\n",
    "\n",
    "    val_prog = val_prog.clone(for_test=True)\n",
    "\n",
    "    train_loss.persistable = True\n",
    "    train_acc.persistable = True\n",
    "    val_loss.persistable = True\n",
    "    val_acc.persistable = True\n",
    "    val_output.persistable = True\n",
    "            \n",
    "    exe = fluid.Executor(place)\n",
    "    exe.run(startup_prog)\n",
    "\n",
    "    if pretrained_model:\n",
    "        def if_exist(var):\n",
    "            return os.path.exists(os.path.join(pretrained_model, var.name))\n",
    "\n",
    "        fluid.io.load_vars(\n",
    "            exe, pretrained_model, main_program=train_prog, predicate=if_exist)\n",
    "\n",
    "    train_reader.decorate_sample_list_generator( train_dataloader, places=place )\n",
    "    val_reader.decorate_sample_list_generator( val_dataloader, places=place )\n",
    "\n",
    "    # For training test cost\n",
    "    def train_test(val_prog, val_reader):\n",
    "        count = 0\n",
    "        accumulated = [0,0]\n",
    "        \n",
    "        prediction = []\n",
    "        label_values = []\n",
    "        \n",
    "        for tid, val_data in enumerate(val_reader()):\n",
    "            avg_cost_np = exe.run(\n",
    "                program=val_prog,\n",
    "                feed=val_data,\n",
    "                fetch_list=[val_loss, val_acc, val_output],\n",
    "                use_program_cache=True)\n",
    "            accumulated = [\n",
    "                x[0] + x[1][0] for x in zip(accumulated, avg_cost_np)\n",
    "            ]\n",
    "            prediction.append(avg_cost_np[2])\n",
    "            label_values.append( np.array(val_data[0]['label']) )\n",
    "            count += 1\n",
    "\n",
    "        prediction = np.concatenate(prediction, 0)\n",
    "        label_values = np.concatenate(label_values, 0)\n",
    "        \n",
    "        auc = calc_auc_numpy(prediction, label_values)\n",
    "        \n",
    "        return [x / count for x in accumulated], auc\n",
    "\n",
    "    # main train loop.\n",
    "    def train_loop():\n",
    "        step = 0\n",
    "        best_auc = 0.\n",
    "\n",
    "        for pass_id in range(EPOCH_NUM):\n",
    "            data_load_time = time.time()\n",
    "            for step_id, data_train in enumerate(train_reader()):\n",
    "                data_load_costtime = time.time() - data_load_time\n",
    "                start_time = time.time()\n",
    "                avg_loss_value = exe.run(\n",
    "                    train_prog,\n",
    "                    feed=data_train,\n",
    "                    fetch_list=[train_loss, train_acc], \n",
    "                    use_program_cache=True)\n",
    "                cost_time = time.time() - start_time\n",
    "                if step_id % 50 == 0:\n",
    "                    print(\"Pass %d, Epoch %d, Cost %f, Acc %f, Time %f, LoadTime %f\" % (\n",
    "                        step_id, pass_id, avg_loss_value[0], avg_loss_value[1], cost_time, data_load_costtime))\n",
    "                else:\n",
    "                    pass\n",
    "                step += 1\n",
    "                data_load_time = time.time()\n",
    "\n",
    "            metrics, auc = train_test(val_prog, val_reader)\n",
    "            avg_cost_test, accuracy_test = metrics\n",
    "            \n",
    "            print('Test with Epoch {0}, Loss {1:2.4}, Acc {2:2.4}, Auc {3:2.4}'.format(\n",
    "                pass_id, avg_cost_test, accuracy_test, auc))\n",
    "            \n",
    "            if auc >= best_auc:\n",
    "                best_data = [pass_id, avg_cost_test, accuracy_test, auc]\n",
    "                best_auc = auc\n",
    "                print(\"\\nBest AUC, Checkpoint Saved!\\n\")\n",
    "                if not os.path.isdir(params_dirname_prefix+\"_best/\"):\n",
    "                    os.makedirs(params_dirname_prefix+\"_best/\")\n",
    "                fluid.io.save_persistables(exe, params_dirname_prefix+\"_best/\", main_program=train_prog)\n",
    "\n",
    "            if not os.path.isdir(params_dirname_prefix+\"_checkpoint/\"):\n",
    "                os.makedirs(params_dirname_prefix+\"_checkpoint/\")\n",
    "            fluid.io.save_persistables(exe, params_dirname_prefix+\"_checkpoint/\", main_program=train_prog)\n",
    "    train_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download imagenet pretrain weight from:\n",
    "# https://github.com/PaddlePaddle/models/tree/develop/PaddleCV/image_classification\n",
    "# remove ResNet34_pretrained/fc*\n",
    "train(use_cuda=True, params_dirname_prefix=\"../weights/classify_weights\", \n",
    "        pretrained_model=\"../weights/ResNet34_pretrained\", EPOCH_NUM=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
