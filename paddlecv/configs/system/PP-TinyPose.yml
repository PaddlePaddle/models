det_image_shape: &det_image_shape 320
kpt_image_height: &kpt_image_height 128
kpt_image_width: &kpt_image_width 96
kpt_image_shape: &kpt_image_shape [*kpt_image_width, *kpt_image_height]

ENV:
  min_subgraph_size: 3
  trt_calib_mode: False
  cpu_threads: 1
  trt_use_static: False
  save_img: True
  save_res: True
  return_res: True

MODEL:
  - DetectionOp:
      name: det
      param_path: paddlecv://models/picodet_s_320_lcnet_pedestrian/model.pdiparams
      model_path: paddlecv://models/picodet_s_320_lcnet_pedestrian/model.pdmodel
      batch_size: 1
      image_shape: [3, *det_image_shape, *det_image_shape]
      PreProcess:
        - Resize:
            interp: 2
            keep_ratio: false
            target_size: [*det_image_shape, *det_image_shape]
        - Permute:
      PostProcess:
        - ParserDetResults:
            label_list: paddlecv://dict/detection/coco_label_list.json
            threshold: 0.5
            keep_cls_ids: [0]
      Inputs:
        - input.image

  - BboxExpandCropOp:
      name: crop
      Inputs:
        - input.image
        - det.dt_bboxes

  - KeypointOp:
      name: kpt
      param_path: paddlecv://models/tinypose_128x96/inference.pdiparams
      model_path: paddlecv://models/tinypose_128x96/inference.pdmodel
      batch_size: 2
      image_shape: [3, *kpt_image_height, *kpt_image_width]
      PreProcess:
        - TopDownEvalAffine:
            trainsize: *kpt_image_shape
        - NormalizeImage:
            is_scale: true
            mean: [0.485, 0.456, 0.406]
            std: [0.229, 0.224, 0.225]
        - Permute:
      PostProcess:
        - HRNetPostProcess:
            use_dark: True
      Inputs:
        - crop.crop_image
        - crop.tl_point

  - KptOutput:
      name: vis
      Inputs:
        - input.fn
        - input.image
        - kpt.keypoints
        - kpt.kpt_scores
