main_task: "reading_comprehension"
auxiliary_task: "mask_language_model answer_matching"

do_train: True
do_predict: True

checkpoint_path: "output"

backbone_model: "bert_model"
pretrain_model_path: "pretrain_model/squad2_model"
pretrain_config_path: "pretrain_model/squad2_model/bert_config.json"
vocab_path: "pretrain_model/squad2_model/vocab.txt"

optimizer: "bert_optimizer"
learning_rate: 3e-5
lr_scheduler: "linear_warmup_decay"
skip_steps: 100
save_steps: 10000
epoch: 2
use_cuda: True
warmup_proportion: 0.1
weight_decay: 0.1
do_lower_case: False
max_seq_len: 512
use_ema: True
ema_decay: 0.9999
random_seed: 0
use_fp16: False
loss_scaling: 1.0

