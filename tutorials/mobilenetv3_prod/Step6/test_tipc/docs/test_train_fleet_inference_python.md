# Linux GPU/CPU å¤šæœºå¤šå¡è®­ç»ƒæ¨ç†æµ‹è¯•

Linux GPU/CPU å¤šæœºå¤šå¡è®­ç»ƒæ¨ç†æµ‹è¯•çš„ä¸»ç¨‹åºä¸º`test_train_inference_python.sh`ï¼Œå¯ä»¥æµ‹è¯•åŸºäºPythonçš„æ¨¡å‹è®­ç»ƒã€è¯„ä¼°ã€æ¨ç†ç­‰åŸºæœ¬åŠŸèƒ½ã€‚

## 1. æµ‹è¯•ç»“è®ºæ±‡æ€»

- è®­ç»ƒç›¸å…³ï¼š

| ç®—æ³•åç§° | æ¨¡å‹åç§° | å¤šæœºå¤šå¡ |
|  :----: |   :----:  |    :----:  |
|  MobileNetV3  | mobilenet_v3_small | åˆ†å¸ƒå¼è®­ç»ƒ |


- æ¨ç†ç›¸å…³ï¼š

| ç®—æ³•åç§° | æ¨¡å‹åç§° | device_CPU | device_GPU | batchsize |
|  :----:   |  :----: |   :----:   |  :----:  |   :----:   |
|  MobileNetV3   |  mobilenet_v3_small |  æ”¯æŒ | æ”¯æŒ | 1 |


## 2. æµ‹è¯•æµç¨‹

### 2.1 å‡†å¤‡ç¯å¢ƒ
- å‡†å¤‡è‡³å°‘ä¸¤å°å¯ä»¥ç›¸äº’`ping`é€šçš„æœºå™¨

  è¿™é‡Œæ¨èä½¿ç”¨Dockerå®¹å™¨çš„æ–¹å¼æ¥è¿è¡Œã€‚ä»¥Paddle2.2.2 GPUç‰ˆï¼Œcuda10.2 cudnn7ä¸ºä¾‹ï¼š
  ```
  æ‹‰å–é¢„å®‰è£… PaddlePaddle çš„é•œåƒï¼š
  nvidia-docker pull registry.baidubce.com/paddlepaddle/paddle:2.2.2-gpu-cuda10.2-cudnn7

  ç”¨é•œåƒæ„å»ºå¹¶è¿›å…¥Dockerå®¹å™¨ï¼š
  nvidia-docker run --name paddle -it --net=host -v $PWD:/paddle registry.baidubce.com/paddlepaddle/paddle:2.2.2-gpu-cuda10.2-cudnn7 /bin/bash
  ```
  ä¸åŒçš„ç‰©ç†æœºç¯å¢ƒé…ç½®ï¼Œå®‰è£…è¯·å‚ç…§[å®˜ç½‘å®‰è£…è¯´æ˜](https://www.paddlepaddle.org.cn/install/quick?docurl=/documentation/docs/zh/install/docker/linux-docker.html)ã€‚

- å®‰è£…ä¾èµ–
    ```
    pip install  -r requirements.txt
    ```

- å®‰è£…AutoLogï¼ˆè§„èŒƒåŒ–æ—¥å¿—è¾“å‡ºå·¥å…·ï¼‰
    ```
    pip install  https://paddleocr.bj.bcebos.com/libs/auto_log-1.2.0-py3-none-any.whl
    ```

### 2.2 åŠŸèƒ½æµ‹è¯•

é¦–å…ˆä¿®æ”¹é…ç½®æ–‡ä»¶ä¸­çš„`ip`è®¾ç½®: å‡è®¾ä¸¤å°æœºå™¨çš„`ip`åœ°å€åˆ†åˆ«ä¸º`192.168.0.1`å’Œ`192.168.0.2`ï¼Œåˆ™å¯¹åº”çš„é…ç½®æ–‡ä»¶`gpu_list`å­—æ®µéœ€è¦ä¿®æ”¹ä¸º`gpu_list:192.168.0.1,192.168.0.2;0,1`ã€‚`ip`åœ°å€æŸ¥çœ‹å‘½ä»¤ä¸º`ifconfig`ã€‚

æµ‹è¯•æ–¹æ³•å¦‚ä¸‹æ‰€ç¤ºï¼Œå¸Œæœ›æµ‹è¯•ä¸åŒçš„æ¨¡å‹æ–‡ä»¶ï¼Œåªéœ€æ›´æ¢ä¸ºè‡ªå·±çš„å‚æ•°é…ç½®æ–‡ä»¶ï¼Œå³å¯å®Œæˆå¯¹åº”æ¨¡å‹çš„æµ‹è¯•ã€‚

```bash
bash test_tipc/test_train_inference_python.sh ${your_params_file} lite_train_lite_infer
```
**æ³¨æ„ï¼š** å¤šæœºå¤šå¡çš„è®­ç»ƒæ¨ç†æµ‹è¯•æœ‰åˆ«äºå•æœºï¼Œéœ€è¦åœ¨å„ä¸ªèŠ‚ç‚¹ä¸Šåˆ†åˆ«å¯åŠ¨å‘½ä»¤ã€‚

ä»¥`mobilenet_v3_small`çš„`Linux GPU/CPU å¤šæœºå¤šå¡è®­ç»ƒæ¨ç†æµ‹è¯•`ä¸ºä¾‹ï¼Œå‘½ä»¤å¦‚ä¸‹æ‰€ç¤ºã€‚

```bash
bash test_tipc/prepare.sh test_tipc/configs/mobilenet_v3_small/train_fleet_infer_python.txt lite_train_lite_infer
```

```bash
bash test_tipc/test_train_inference_python.sh test_tipc/configs/mobilenet_v3_small/train_fleet_infer_python.txt lite_train_lite_infer
```

è¾“å‡ºç»“æœå¦‚ä¸‹ï¼Œè¡¨ç¤ºå‘½ä»¤è¿è¡ŒæˆåŠŸã€‚

```bash
Run successfully with command - python3.7 -m paddle.distributed.launch --ips=192.168.0.1,192.168.0.2 --gpus=0,1 train.py --output-dir=./log/mobilenet_v3_small/lite_train_lite_infer/norm_train_gpus_0,1_nodes_2 --epochs=5   --batch-size=4!
......
Run successfully with command - python3.7 deploy/inference_python/infer.py --use-gpu=False --model-dir=./log/mobilenet_v3_small/lite_train_lite_infer/norm_train_gpus_0,1_nodes_2 --batch-size=1   --benchmark=True > ./log/mobilenet_v3_small/lite_train_lite_infer/python_infer_cpu_batchsize_1.log 2>&1 !
```

åœ¨å¼€å¯benchmarkå‚æ•°æ—¶ï¼Œå¯ä»¥å¾—åˆ°æµ‹è¯•çš„è¯¦ç»†æ•°æ®ï¼ŒåŒ…å«è¿è¡Œç¯å¢ƒä¿¡æ¯ï¼ˆç³»ç»Ÿç‰ˆæœ¬ã€CUDAç‰ˆæœ¬ã€CUDNNç‰ˆæœ¬ã€é©±åŠ¨ç‰ˆæœ¬ï¼‰ï¼ŒPaddleç‰ˆæœ¬ä¿¡æ¯ï¼Œå‚æ•°è®¾ç½®ä¿¡æ¯ï¼ˆè¿è¡Œè®¾å¤‡ã€çº¿ç¨‹æ•°ã€æ˜¯å¦å¼€å¯å†…å­˜ä¼˜åŒ–ç­‰ï¼‰ï¼Œæ¨¡å‹ä¿¡æ¯ï¼ˆæ¨¡å‹åç§°ã€ç²¾åº¦ï¼‰ï¼Œæ•°æ®ä¿¡æ¯ï¼ˆbatchsizeã€æ˜¯å¦ä¸ºåŠ¨æ€shapeç­‰ï¼‰ï¼Œæ€§èƒ½ä¿¡æ¯ï¼ˆCPU,GPUçš„å ç”¨ã€è¿è¡Œè€—æ—¶ã€é¢„å¤„ç†è€—æ—¶ã€æ¨ç†è€—æ—¶ã€åå¤„ç†è€—æ—¶ï¼‰ï¼Œå†…å®¹å¦‚ä¸‹æ‰€ç¤ºï¼š

```
[2022/03/22 06:15:51] root INFO: ---------------------- Env info ----------------------
[2022/03/22 06:15:51] root INFO:  OS_version: Ubuntu 16.04
[2022/03/22 06:15:51] root INFO:  CUDA_version: 10.2.89
[2022/03/22 06:15:51] root INFO:  CUDNN_version: 7.6.5
[2022/03/22 06:15:51] root INFO:  drivier_version: 440.64.00
[2022/03/22 06:15:51] root INFO: ---------------------- Paddle info ----------------------
[2022/03/22 06:15:51] root INFO:  paddle_version: 2.2.2
[2022/03/22 06:15:51] root INFO:  paddle_commit: b031c389938bfa15e15bb20494c76f86289d77b0
[2022/03/22 06:15:51] root INFO:  log_api_version: 1.0
[2022/03/22 06:15:51] root INFO: ----------------------- Conf info -----------------------
[2022/03/22 06:15:51] root INFO:  runtime_device: cpu
[2022/03/22 06:15:51] root INFO:  ir_optim: True
[2022/03/22 06:15:51] root INFO:  enable_memory_optim: True
[2022/03/22 06:15:51] root INFO:  enable_tensorrt: False
[2022/03/22 06:15:51] root INFO:  enable_mkldnn: False
[2022/03/22 06:15:51] root INFO:  cpu_math_library_num_threads: 1
[2022/03/22 06:15:51] root INFO: ----------------------- Model info ----------------------
[2022/03/22 06:15:51] root INFO:  model_name: classification
[2022/03/22 06:15:51] root INFO:  precision: fp32
[2022/03/22 06:15:51] root INFO: ----------------------- Data info -----------------------
[2022/03/22 06:15:51] root INFO:  batch_size: 1
[2022/03/22 06:15:51] root INFO:  input_shape: dynamic
[2022/03/22 06:15:51] root INFO:  data_num: 1
[2022/03/22 06:15:51] root INFO: ----------------------- Perf info -----------------------
[2022/03/22 06:15:51] root INFO:  cpu_rss(MB): 227.2812, gpu_rss(MB): None, gpu_util: None%
[2022/03/22 06:15:51] root INFO:  total time spent(s): 0.1583
[2022/03/22 06:15:51] root INFO:  preprocess_time(ms): 18.6493, inference_time(ms): 139.591, postprocess_time(ms): 0.0875
```

è¯¥ä¿¡æ¯å¯ä»¥åœ¨è¿è¡Œlogä¸­æŸ¥çœ‹ï¼Œä»¥`mobilenet_v3_small`ä¸ºä¾‹ï¼Œlogä½ç½®åœ¨`./log/mobilenet_v3_small/lite_train_lite_infer/python_infer_gpu_batchsize_1.log`ã€‚

å¦‚æœè¿è¡Œå¤±è´¥ï¼Œä¹Ÿä¼šåœ¨ç»ˆç«¯ä¸­è¾“å‡ºè¿è¡Œå¤±è´¥çš„æ—¥å¿—ä¿¡æ¯ä»¥åŠå¯¹åº”çš„è¿è¡Œå‘½ä»¤ã€‚å¯ä»¥åŸºäºè¯¥å‘½ä»¤ï¼Œåˆ†æè¿è¡Œå¤±è´¥çš„åŸå› ã€‚
