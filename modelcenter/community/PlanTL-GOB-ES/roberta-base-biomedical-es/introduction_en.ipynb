{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7029fde",
   "metadata": {},
   "source": [
    "# Biomedical language model for Spanish\n",
    "Biomedical pretrained language model for Spanish. For more details about the corpus, the pretraining and the evaluation, check the official [repository](https://github.com/PlanTL-SANIDAD/lm-biomedical-clinical-es) and read our [preprint](https://arxiv.org/abs/2109.03570) \"_Carrino, C. P., Armengol-Estapé, J., Gutiérrez-Fandiño, A., Llop-Palao, J., Pàmies, M., Gonzalez-Agirre, A., & Villegas, M. (2021). Biomedical and Clinical Language Models for Spanish: On the Benefits of Domain-Specific Pretraining in a Mid-Resource Scenario._\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a30a9f8",
   "metadata": {},
   "source": [
    "## Tokenization and model pretraining\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e61e190",
   "metadata": {},
   "source": [
    "This model is a [RoBERTa-based](https://github.com/pytorch/fairseq/tree/master/examples/roberta) model trained on a\n",
    "**biomedical** corpus in Spanish collected from several sources (see next section).\n",
    "The training corpus has been tokenized using a byte version of [Byte-Pair Encoding (BPE)](https://github.com/openai/gpt-2)\n",
    "used in the original [RoBERTA](https://github.com/pytorch/fairseq/tree/master/examples/roberta) model with a vocabulary size of 52,000 tokens. The pretraining consists of a masked language model training at the subword level following the approach employed for the RoBERTa base model with the same hyperparameters as in the original work. The training lasted a total of 48 hours with 16 NVIDIA V100 GPUs of 16GB DDRAM, using Adam optimizer with a peak learning rate of 0.0005 and an effective batch size of 2,048 sentences.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586b5b1f",
   "metadata": {},
   "source": [
    "## Training corpora and preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245aed04",
   "metadata": {},
   "source": [
    "The training corpus is composed of several biomedical corpora in Spanish, collected from publicly available corpora and crawlers.\n",
    "To obtain a high-quality training corpus, a cleaning pipeline with the following operations has been applied:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beecd6e5",
   "metadata": {},
   "source": [
    "- data parsing in different formats\n",
    "- sentence splitting\n",
    "- language detection\n",
    "- filtering of ill-formed sentences\n",
    "- deduplication of repetitive contents\n",
    "- keep the original document boundaries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f83037",
   "metadata": {},
   "source": [
    "Finally, the corpora are concatenated and further global deduplication among the corpora have been applied.\n",
    "The result is a medium-size biomedical corpus for Spanish composed of about 963M tokens. The table below shows some basic statistics of the individual cleaned corpora:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4713b28c",
   "metadata": {},
   "source": [
    "| Name                                                                                    | No. tokens  | Description                                                                                                                                                                                                                                          |\n",
    "|-----------------------------------------------------------------------------------------|-------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| [Medical crawler](https://zenodo.org/record/4561970)                                    | 745,705,946 | Crawler of more than 3,000 URLs belonging to Spanish biomedical and health domains.                                                                                                                                                                                 |\n",
    "| Clinical cases misc.                                                                    | 102,855,267 | A miscellany of medical content, essentially clinical cases. Note that a clinical case report is a scientific publication where medical practitioners share patient cases and it is different from a clinical note or document.                                                                                                                                                                                 |\n",
    "| [Scielo](https://github.com/PlanTL-SANIDAD/SciELO-Spain-Crawler)                        | 60,007,289  | Publications written in Spanish crawled from the Spanish SciELO server in 2017.                                                                                                                                       |\n",
    "| [BARR2_background](https://temu.bsc.es/BARR2/downloads/background_set.raw_text.tar.bz2) | 24,516,442  | Biomedical Abbreviation Recognition and Resolution (BARR2) containing Spanish clinical case study sections from a variety of clinical disciplines.                                                                                       |\n",
    "| Wikipedia_life_sciences                                                                 | 13,890,501  | Wikipedia articles crawled 04/01/2021 with the [Wikipedia API python library](https://pypi.org/project/Wikipedia-API/) starting from the \"Ciencias\\_de\\_la\\_vida\" category up to a maximum of 5 subcategories. Multiple links to the same articles are then discarded to avoid repeating content.                                                                                                                                                                    |\n",
    "| Patents                                                                                 | 13,463,387  | Google Patent in Medical Domain for Spain (Spanish). The accepted codes (Medical Domain) for Json files of patents are: \"A61B\", \"A61C\",\"A61F\", \"A61H\", \"A61K\", \"A61L\",\"A61M\", \"A61B\", \"A61P\".                                                        |\n",
    "| [EMEA](http://opus.nlpl.eu/download.php?f=EMEA/v3/moses/en-es.txt.zip)                  | 5,377,448   | Spanish-side documents extracted from parallel corpora made out of PDF documents from the European Medicines Agency.                                                                                                                            |\n",
    "| [mespen_Medline](https://zenodo.org/record/3562536#.YTt1fH2xXbR)                        | 4,166,077   | Spanish-side articles extracted from a collection of Spanish-English parallel corpus consisting of biomedical scientific literature.  The collection of parallel resources are aggregated from the MedlinePlus source. |\n",
    "| PubMed                                                                                  | 1,858,966   | Open-access articles from the PubMed repository crawled in 2017.                                                                                                                                              |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d04540",
   "metadata": {},
   "source": [
    "## Evaluation and results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4244f93",
   "metadata": {},
   "source": [
    "The model has been evaluated on the Named Entity Recognition (NER) using the following datasets:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e719959",
   "metadata": {},
   "source": [
    "- [PharmaCoNER](https://zenodo.org/record/4270158): is a track on chemical and drug mention recognition from Spanish medical texts (for more info see: https://temu.bsc.es/pharmaconer/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a3e1a2",
   "metadata": {},
   "source": [
    "- [CANTEMIST](https://zenodo.org/record/3978041#.YTt5qH2xXbQ): is a shared task specifically focusing on named entity recognition of tumor morphology, in Spanish (for more info see: https://zenodo.org/record/3978041#.YTt5qH2xXbQ).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca19735",
   "metadata": {},
   "source": [
    "- ICTUSnet: consists of 1,006 hospital discharge reports of patients admitted for stroke from 18 different Spanish hospitals. It contains more than 79,000 annotations for 51 different kinds of variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b4a442",
   "metadata": {},
   "source": [
    "The evaluation results are compared against the [mBERT](https://huggingface.co/bert-base-multilingual-cased) and [BETO](https://huggingface.co/dccuchile/bert-base-spanish-wwm-cased) models:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49463f9",
   "metadata": {},
   "source": [
    "| F1 - Precision - Recall | roberta-base-biomedical-es | mBERT                   | BETO                    |\n",
    "|---------------------------|----------------------------|-------------------------------|-------------------------|\n",
    "| PharmaCoNER               | **89.48** - **87.85** - **91.18**    | 87.46 - 86.50 - 88.46 | 88.18 - 87.12 - 89.28 |\n",
    "| CANTEMIST                 | **83.87** - **81.70** - **86.17**    | 82.61 - 81.12 - 84.15 | 82.42 - 80.91 - 84.00 |\n",
    "| ICTUSnet                  | **88.12** - **85.56** - **90.83**    | 86.75 - 83.53 - 90.23 | 85.95 - 83.10 - 89.02 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639c2b98",
   "metadata": {},
   "source": [
    "## Intended uses & limitations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae325b0",
   "metadata": {},
   "source": [
    "The model is ready-to-use only for masked language modelling to perform the Fill Mask task (try the inference API or read the next section)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e428a4c2",
   "metadata": {},
   "source": [
    "However, the is intended to be fine-tuned on downstream tasks such as Named Entity Recognition or Text Classification.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bbe544",
   "metadata": {},
   "source": [
    "## Cite\n",
    "If you use our models, please cite our latest preprint:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34833cb3",
   "metadata": {},
   "source": [
    "```\n",
    "@misc{carrino2021biomedical,\n",
    "      title={Biomedical and Clinical Language Models for Spanish: On the Benefits of Domain-Specific Pretraining in a Mid-Resource Scenario}, \n",
    "      author={Casimiro Pio Carrino and Jordi Armengol-Estapé and Asier Gutiérrez-Fandiño and Joan Llop-Palao and Marc Pàmies and Aitor Gonzalez-Agirre and Marta Villegas},\n",
    "      year={2021},\n",
    "      eprint={2109.03570},\n",
    "      archivePrefix={arXiv},\n",
    "      primaryClass={cs.CL}\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2765e917",
   "metadata": {},
   "source": [
    "If you use our Medical Crawler corpus, please cite the preprint:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571bc4b7",
   "metadata": {},
   "source": [
    "```\n",
    "@misc{carrino2021spanish,\n",
    "      title={Spanish Biomedical Crawled Corpus: A Large, Diverse Dataset for Spanish Biomedical Language Models}, \n",
    "      author={Casimiro Pio Carrino and Jordi Armengol-Estapé and Ona de Gibert Bonet and Asier Gutiérrez-Fandiño and Aitor Gonzalez-Agirre and Martin Krallinger and Marta Villegas},\n",
    "      year={2021},\n",
    "      eprint={2109.07765},\n",
    "      archivePrefix={arXiv},\n",
    "      primaryClass={cs.CL}\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366bf14d",
   "metadata": {},
   "source": [
    "## How to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "438a89af",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: paddlenlp in /Users/wujingjing05/miniconda3/envs/paddlenlp/lib/python3.8/site-packages (2.4.2)\n",
      "Requirement already satisfied: colorama in /Users/wujingjing05/miniconda3/envs/paddlenlp/lib/python3.8/site-packages (from paddlenlp) (0.4.5)\n",
      "Requirement already satisfied: protobuf<=3.20.0,>=3.1.0 in /Users/wujingjing05/miniconda3/envs/paddlenlp/lib/python3.8/site-packages (from paddlenlp) (3.20.0)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /Users/wujingjing05/miniconda3/envs/paddlenlp/lib/python3.8/site-packages (from paddlenlp) (2.6.1)\n",
      "Requirement already satisfied: tqdm in /Users/wujingjing05/miniconda3/envs/paddlenlp/lib/python3.8/site-packages (from paddlenlp) (4.64.1)\n",
      "Requirement already satisfied: multiprocess<=0.70.12.2 in /Users/wujingjing05/miniconda3/envs/paddlenlp/lib/python3.8/site-packages (from paddlenlp) (0.70.12.2)\n",
      "Requirement already satisfied: paddlefsl in /Users/wujingjing05/miniconda3/envs/paddlenlp/lib/python3.8/site-packages (from paddlenlp) (1.1.0)\n",
      "Requirement already satisfied: sentencepiece in /Users/wujingjing05/miniconda3/envs/paddlenlp/lib/python3.8/site-packages (from paddlenlp) (0.1.97)\n",
      "Requirement already satisfied: paddle2onnx in /Users/wujingjing05/miniconda3/envs/paddlenlp/lib/python3.8/site-packages (from paddlenlp) (0.9.7)\n",
      "Requirement already satisfied: jieba in /Users/wujingjing05/miniconda3/envs/paddlenlp/lib/python3.8/site-packages (from paddlenlp) (0.42.1)\n",
      "Requirement already satisfied: visualdl in /Users/wujingjing05/miniconda3/envs/paddlenlp/lib/python3.8/site-packages (from paddlenlp) (2.4.1)\n",
      "Requirement already satisfied: colorlog in /Users/wujingjing05/miniconda3/envs/paddlenlp/lib/python3.8/site-packages (from paddlenlp) (6.7.0)\n",
      "Requirement already satisfied: seqeval in /Users/wujingjing05/miniconda3/envs/paddlenlp/lib/python3.8/site-packages (from paddlenlp) (1.2.2)\n",
      "Requirement already satisfied: dill<0.3.5 in /Users/wujingjing05/miniconda3/envs/paddlenlp/lib/python3.8/site-packages (from paddlenlp) (0.3.4)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /Users/wujingjing05/miniconda3/envs/paddlenlp/lib/python3.8/site-packages (from datasets>=2.0.0->paddlenlp) (2022.8.2)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /Users/wujingjing05/miniconda3/envs/paddlenlp/lib/python3.8/site-packages (from datasets>=2.0.0->paddlenlp) (8.0.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/wujingjing05/miniconda3/envs/paddlenlp/lib/python3.8/site-packages (from datasets>=2.0.0->paddlenlp) (2.28.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /Users/wujingjing05/miniconda3/envs/paddlenlp/lib/python3.8/site-packages (from datasets>=2.0.0->paddlenlp) (0.9.1)\n",
      "Requirement already satisfied: responses<0.19 in /Users/wujingjing05/miniconda3/envs/paddlenlp/lib/python3.8/site-packages (from datasets>=2.0.0->paddlenlp) (0.18.0)\n",
      "Requirement already satisfied: xxhash in /Users/wujingjing05/miniconda3/envs/paddlenlp/lib/python3.8/site-packages (from datasets>=2.0.0->paddlenlp) (3.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/wujingjing05/miniconda3/envs/paddlenlp/lib/python3.8/site-packages (from datasets>=2.0.0->paddlenlp) (6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/wujingjing05/miniconda3/envs/paddlenlp/lib/python3.8/site-packages (from datasets>=2.0.0->paddlenlp) (1.23.1)\n",
      "Requirement already satisfied: packaging in /Users/wujingjing05/miniconda3/envs/paddlenlp/lib/python3.8/site-packages (from datasets>=2.0.0->paddlenlp) (21.3)\n",
      "Requirement already satisfied: pandas in /Users/wujingjing05/miniconda3/envs/paddlenlp/lib/python3.8/site-packages (from datasets>=2.0.0->paddlenlp) (1.4.3)\n",
      "Requirement already satisfied: aiohttp in /Users/wujingjing05/miniconda3/envs/paddlenlp/lib/python3.8/site-packages (from datasets>=2.0.0->paddlenlp) (3.8.1)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /Users/wujingjing05/miniconda3/envs/paddlenlp/lib/python3.8/site-packages (from seqeval->paddlenlp) (1.1.1)\n",
      "Requirement already satisfied: Flask-Babel>=1.0.0 in /Users/wujingjing05/miniconda3/envs/paddlenlp/lib/python3.8/site-packages (from visualdl->paddlenlp) (2.0.0)\n",
      "Requirement already satisfied: matplotlib in /Users/wujingjing05/miniconda3/envs/paddlenlp/lib/python3.8/site-packages (from visualdl->paddlenlp) (3.6.0)\n",
      "Requirement already satisfied: bce-python-sdk in /Users/wujingjing05/miniconda3/envs/paddlenlp/lib/python3.8/site-packages (from visualdl->paddlenlp) (0.8.74)\n",
      "Requirement already satisfied: six>=1.14.0 in /Users/wujingjing05/miniconda3/envs/paddlenlp/lib/python3.8/site-packages (from visualdl->paddlenlp) (1.16.0)\n",
      "Requirement already satisfied: Pillow>=7.0.0 in /Users/wujingjing05/miniconda3/envs/paddlenlp/lib/python3.8/site-packages (from visualdl->paddlenlp) (9.2.0)\n",
      "Requirement already satisfied: flask>=1.1.1 in /Users/wujingjing05/miniconda3/envs/paddlenlp/lib/python3.8/site-packages (from visualdl->paddlenlp) (2.2.2)\n",
      "Requirement already satisfied: Werkzeug>=2.2.2 in /Users/wujingjing05/miniconda3/envs/paddlenlp/lib/python3.8/site-packages (from flask>=1.1.1->visualdl->paddlenlp) (2.2.2)\n",
      "Requirement already satisfied: Jinja2>=3.0 in /Users/wujingjing05/miniconda3/envs/paddlenlp/lib/python3.8/site-packages (from flask>=1.1.1->visualdl->paddlenlp) (3.1.2)\n",
      "Requirement already satisfied: importlib-metadata>=3.6.0 in /Users/wujingjing05/miniconda3/envs/paddlenlp/lib/python3.8/site-packages (from flask>=1.1.1->visualdl->paddlenlp) (4.12.0)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in /Users/wujingjing05/miniconda3/envs/paddlenlp/lib/python3.8/site-packages (from flask>=1.1.1->visualdl->paddlenlp) (2.1.2)\n",
      "Requirement already satisfied: click>=8.0 in /Users/wujingjing05/miniconda3/envs/paddlenlp/lib/python3.8/site-packages (from flask>=1.1.1->visualdl->paddlenlp) (8.1.3)\n",
      "Requirement already satisfied: Babel>=2.3 in /Users/wujingjing05/miniconda3/envs/paddlenlp/lib/python3.8/site-packages (from Flask-Babel>=1.0.0->visualdl->paddlenlp) (2.10.3)\n",
      "Requirement already satisfied: pytz in /Users/wujingjing05/miniconda3/envs/paddlenlp/lib/python3.8/site-packages (from Flask-Babel>=1.0.0->visualdl->paddlenlp) (2022.1)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /Users/wujingjing05/miniconda3/envs/paddlenlp/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp) (2.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/wujingjing05/miniconda3/envs/paddlenlp/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp) (1.3.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/wujingjing05/miniconda3/envs/paddlenlp/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp) (21.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/wujingjing05/miniconda3/envs/paddlenlp/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/wujingjing05/miniconda3/envs/paddlenlp/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/wujingjing05/miniconda3/envs/paddlenlp/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp) (1.7.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/wujingjing05/miniconda3/envs/paddlenlp/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp) (1.2.0)\n",
      "Requirement already satisfied: filelock in /Users/wujingjing05/miniconda3/envs/paddlenlp/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets>=2.0.0->paddlenlp) (3.7.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/wujingjing05/miniconda3/envs/paddlenlp/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets>=2.0.0->paddlenlp) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/wujingjing05/miniconda3/envs/paddlenlp/lib/python3.8/site-packages (from packaging->datasets>=2.0.0->paddlenlp) (3.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/wujingjing05/miniconda3/envs/paddlenlp/lib/python3.8/site-packages (from requests>=2.19.0->datasets>=2.0.0->paddlenlp) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/wujingjing05/miniconda3/envs/paddlenlp/lib/python3.8/site-packages (from requests>=2.19.0->datasets>=2.0.0->paddlenlp) (1.26.10)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/wujingjing05/miniconda3/envs/paddlenlp/lib/python3.8/site-packages (from requests>=2.19.0->datasets>=2.0.0->paddlenlp) (3.3)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /Users/wujingjing05/miniconda3/envs/paddlenlp/lib/python3.8/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /Users/wujingjing05/miniconda3/envs/paddlenlp/lib/python3.8/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (1.9.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/wujingjing05/miniconda3/envs/paddlenlp/lib/python3.8/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (3.1.0)\n",
      "Requirement already satisfied: pycryptodome>=3.8.0 in /Users/wujingjing05/miniconda3/envs/paddlenlp/lib/python3.8/site-packages (from bce-python-sdk->visualdl->paddlenlp) (3.15.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: future>=0.6.0 in /Users/wujingjing05/miniconda3/envs/paddlenlp/lib/python3.8/site-packages (from bce-python-sdk->visualdl->paddlenlp) (0.18.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/wujingjing05/miniconda3/envs/paddlenlp/lib/python3.8/site-packages (from matplotlib->visualdl->paddlenlp) (2.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/wujingjing05/miniconda3/envs/paddlenlp/lib/python3.8/site-packages (from matplotlib->visualdl->paddlenlp) (1.0.5)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/wujingjing05/miniconda3/envs/paddlenlp/lib/python3.8/site-packages (from matplotlib->visualdl->paddlenlp) (1.4.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/wujingjing05/miniconda3/envs/paddlenlp/lib/python3.8/site-packages (from matplotlib->visualdl->paddlenlp) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/wujingjing05/miniconda3/envs/paddlenlp/lib/python3.8/site-packages (from matplotlib->visualdl->paddlenlp) (4.37.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/wujingjing05/miniconda3/envs/paddlenlp/lib/python3.8/site-packages (from importlib-metadata>=3.6.0->flask>=1.1.1->visualdl->paddlenlp) (3.8.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/wujingjing05/miniconda3/envs/paddlenlp/lib/python3.8/site-packages (from Jinja2>=3.0->flask>=1.1.1->visualdl->paddlenlp) (2.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade paddlenlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b5570c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle\n",
    "from paddlenlp.transformers import AutoModel\n",
    "\n",
    "model = AutoModel.from_pretrained(\"PlanTL-GOB-ES/roberta-base-biomedical-es\")\n",
    "input_ids = paddle.randint(100, 200, shape=[1, 20])\n",
    "print(model(input_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c499df",
   "metadata": {},
   "source": [
    "## Copyright\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb0cb73",
   "metadata": {},
   "source": [
    "Copyright by the Spanish State Secretariat for Digitalization and Artificial Intelligence (SEDIA) (2022)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bf317e",
   "metadata": {},
   "source": [
    "## Licensing information\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0101d3ac",
   "metadata": {},
   "source": [
    "[Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb167c4",
   "metadata": {},
   "source": [
    "## Funding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed7d2a3",
   "metadata": {},
   "source": [
    "This work was funded by the Spanish State Secretariat for Digitalization and Artificial Intelligence (SEDIA) within the framework of the Plan-TL.\n",
    "> The introduciton and weight file of this model are from [https://huggingface.co/PlanTL-GOB-ES/roberta-base-biomedical-es](https://huggingface.co/PlanTL-GOB-ES/roberta-base-biomedical-es), and we convert them to paddle related files.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
