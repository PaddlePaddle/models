---
Model_Info:
   name: "PlanTL-GOB-ES/roberta-base-biomedical-clinical-es"
   description: ""
   description_en: ""
   icon: ""
   from_repo: "https://huggingface.co/PlanTL-GOB-ES/roberta-base-biomedical-clinical-es"

Task:
- tag_en: "NLP"
     tag: "自然语言处理"
     sub_tag_en: "Fill-Mask"
     sub_tag: "槽位填充"

Example:

Datasets: ""
Pulisher: "PlanTL-GOB-ES"
License: "License: apache-2.0"
Paper:
   - title: 'Biomedical and Clinical Language Models for Spanish: On the Benefits of Domain-Specific Pretraining in a Mid-Resource Scenario'
   -url: 'http://arxiv.org/abs/2109.03570v2'
   - title: 'Spanish Biomedical Crawled Corpus: A Large, Diverse Dataset for Spanish Biomedical Language Models'
   -url: 'http://arxiv.org/abs/2109.07765v1'
IfTraining: 0
IfOnlineDemo: 0