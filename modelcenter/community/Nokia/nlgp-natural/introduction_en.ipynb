{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66997434",
   "metadata": {},
   "source": [
    "# NLGP natural model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e421ee45",
   "metadata": {},
   "source": [
    "The NLGP natural model was introduced in the paper [Natural Language-Guided Programming](https://arxiv.org/abs/2108.05198).  The model was trained on a collection of Jupyter notebooks and can be used to synthesize Python code that addresses a natural language **intent** in a certain code **context** (see the example below). This work was carried out by a research team in Nokia Bell Labs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2d2e3b",
   "metadata": {},
   "source": [
    "**Context**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb628564",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade paddlenlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4445cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle\n",
    "from paddlenlp.transformers import AutoModel\n",
    "\n",
    "model = AutoModel.from_pretrained(\"Nokia/nlgp-natural\")\n",
    "input_ids = paddle.randint(100, 200, shape=[1, 20])\n",
    "print(model(input_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3f547e",
   "metadata": {},
   "source": [
    "import re\n",
    "from transformers import GPT2LMHeadModel, GPT2TokenizerFast\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a90d68d",
   "metadata": {},
   "source": [
    "# load the model\n",
    "tok = GPT2TokenizerFast.from_pretrained(\"Nokia/nlgp-natural\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"Nokia/nlgp-natural\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964945fd",
   "metadata": {},
   "source": [
    "# preprocessing functions\n",
    "num_spaces = [2, 4, 6, 8, 10, 12, 14, 16, 18]\n",
    "def preprocess(context, query):\n",
    "\"\"\"\n",
    "Encodes context + query as a single string and\n",
    "replaces whitespace with special tokens <|2space|>, <|4space|>, ...\n",
    "\"\"\"\n",
    "input_str = f\"{context}\\n{query} <|endofcomment|>\\n\"\n",
    "indentation_symbols = {n: f\"<|{n}space|>\" for n in num_spaces}\n",
    "m = re.match(\"^[ ]+\", input_str)\n",
    "if not m:\n",
    "return input_str\n",
    "leading_whitespace = m.group(0)\n",
    "N = len(leading_whitespace)\n",
    "for n in self.num_spaces:\n",
    "leading_whitespace = leading_whitespace.replace(n * \" \", self.indentation_symbols[n])\n",
    "return leading_whitespace + input_str[N:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fb8f75",
   "metadata": {},
   "source": [
    "detokenize_pattern = re.compile(fr\"<\\|(\\d+)space\\|>\")\n",
    "def postprocess(output):\n",
    "output = output.split(\"<|cell|>\")[0]\n",
    "def insert_space(m):\n",
    "num_spaces = int(m.group(1))\n",
    "return num_spaces * \" \"\n",
    "return detokenize_pattern.sub(insert_space, output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1a99e8",
   "metadata": {},
   "source": [
    "# inference\n",
    "code_context = \"\"\"\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de48eab8",
   "metadata": {},
   "source": [
    "values = [1, 2, 3, 4]\n",
    "labels = [\"a\", \"b\", \"c\", \"d\"]\n",
    "\"\"\"\n",
    "query = \"# plot a bar chart\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5ea4eb",
   "metadata": {},
   "source": [
    "input_str = preprocess(code_context, query)\n",
    "input_ids = tok(input_str, return_tensors=\"pt\").input_ids\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17de94b",
   "metadata": {},
   "source": [
    "max_length = 150 # don't generate output longer than this length\n",
    "total_max_length = min(1024 - input_ids.shape[-1], input_ids.shape[-1] + 150) # total = input + output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b84084",
   "metadata": {},
   "source": [
    "input_and_output = model.generate(\n",
    "input_ids=input_ids,\n",
    "max_length=total_max_length,\n",
    "min_length=10,\n",
    "do_sample=False,\n",
    "num_beams=4,\n",
    "early_stopping=True,\n",
    "eos_token_id=tok.encode(\"<|cell|>\")[0]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e855771e",
   "metadata": {},
   "source": [
    "output = input_and_output[:, input_ids.shape[-1]:] # remove the tokens that correspond to the input_str\n",
    "output_str = tok.decode(output[0])\n",
    "postprocess(output_str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46809dfb",
   "metadata": {},
   "source": [
    "## License and copyright\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e2962e",
   "metadata": {},
   "source": [
    "Copyright 2021 Nokia\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e510acf0",
   "metadata": {},
   "source": [
    "Licensed under the Apache License 2.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71fc6ba",
   "metadata": {},
   "source": [
    "SPDX-License-Identifier: Apache-2.0\n",
    "> 此模型来源于：[https://huggingface.co/Nokia/nlgp-natural](https://huggingface.co/https://huggingface.co/Nokia/nlgp-natural)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
