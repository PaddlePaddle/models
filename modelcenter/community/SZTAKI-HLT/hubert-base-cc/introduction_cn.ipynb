{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b5ca8ec",
   "metadata": {},
   "source": [
    "# huBERT base model (cased)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69267284",
   "metadata": {},
   "source": [
    "## Model description\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d1e580",
   "metadata": {},
   "source": [
    "Cased BERT model for Hungarian, trained on the (filtered, deduplicated) Hungarian subset of the Common Crawl and a snapshot of the Hungarian Wikipedia.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7cd99a",
   "metadata": {},
   "source": [
    "## Intended uses & limitations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193dbdb3",
   "metadata": {},
   "source": [
    "The model can be used as any other (cased) BERT model. It has been tested on the chunking and\n",
    "named entity recognition tasks and set a new state-of-the-art on the former.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d087c79",
   "metadata": {},
   "source": [
    "## Training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81749152",
   "metadata": {},
   "source": [
    "Details of the training data and procedure can be found in the PhD thesis linked below. (With the caveat that it only contains preliminary results\n",
    "based on the Wikipedia subcorpus. Evaluation of the full model will appear in a future paper.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f473e9fd",
   "metadata": {},
   "source": [
    "## Eval results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07fe127",
   "metadata": {},
   "source": [
    "When fine-tuned (via `BertForTokenClassification`) on chunking and NER, the model outperforms multilingual BERT, achieves state-of-the-art results on\n",
    "both tasks. The exact scores are\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f169051a",
   "metadata": {},
   "source": [
    "| NER | Minimal NP | Maximal NP |\n",
    "|-----|------------|------------|\n",
    "| **97.62%** | **97.14%** | **96.97%** |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e37368",
   "metadata": {},
   "source": [
    "### BibTeX entry and citation info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3692d57",
   "metadata": {},
   "source": [
    "If you use the model, please cite the following papers:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9104796",
   "metadata": {},
   "source": [
    "[Nemeskey, Dávid Márk (2020). \"Natural Language Processing Methods for Language Modeling.\" PhD Thesis. Eötvös Loránd University.](https://hlt.bme.hu/en/publ/nemeskey_2020)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f284872",
   "metadata": {},
   "source": [
    "Bibtex:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb277d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade paddlenlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4943d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle\n",
    "from paddlenlp.transformers import AutoModel\n",
    "\n",
    "model = AutoModel.from_pretrained(\"SZTAKI-HLT/hubert-base-cc\")\n",
    "input_ids = paddle.randint(100, 200, shape=[1, 20])\n",
    "print(model(input_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b06cca0",
   "metadata": {},
   "source": [
    "@InProceedings{ Nemeskey:2021a,\n",
    "author = {Nemeskey, Dávid Márk},\n",
    "title = {Introducing \\texttt{huBERT}},\n",
    "booktitle = {{XVII}.\\ Magyar Sz{\\'a}m{\\'i}t{\\'o}g{\\'e}pes Nyelv{\\'e}szeti Konferencia ({MSZNY}2021)},\n",
    "year = 2021,\n",
    "pages = {TBA},\n",
    "address = {Szeged},\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12a5a5f",
   "metadata": {},
   "source": [
    "> 此模型来源于：[https://huggingface.co/SZTAKI-HLT/hubert-base-cc](https://huggingface.co/https://huggingface.co/SZTAKI-HLT/hubert-base-cc)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
