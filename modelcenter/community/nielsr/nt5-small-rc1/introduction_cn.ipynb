{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "941bcbae",
   "metadata": {},
   "source": [
    "# NT5, a T5 model trained to perform numerical reasoning\n",
    "\n",
    "T5-small model pre-trained on 3 million (partly synthetic) texts and fine-tuned on [DROP](https://allennlp.org/drop.html). It was introduced in the paper [NT5?! Training T5 to Perform Numerical Reasoning](https://arxiv.org/abs/2104.07307) by Yang et al. and first released in [this repository](https://github.com/lesterpjy/numeric-t5). As the original implementation was in Tensorflow 2, I've converted the weigths to PyTorch. This model corresponds to RC Experiment 1 (see the paper), their best performing model.\n",
    "\n",
    "Disclaimer: The team releasing NT5 did not write a model card for this model so this model card has been written by me.\n",
    "\n",
    "## Model description\n",
    "\n",
    "The NT5 model is a T5 model, in other words, an encoder-decoder Transformer. In order to encourage numerical reasoning, the model was further pre-trained on three datasets designed to strengthen skills necessary for numerical reasoning over text (NRoT) and general reading comprehension before being fine-tuned on the Discrete Reasoning over Text (DROP) dataset.\n",
    "\n",
    "## Intended uses & limitations\n",
    "\n",
    "You can use the model for numerical reasoning over text.\n",
    "\n",
    "### How to use\n",
    "\n",
    "Here is how to use this model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba2dba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle\n",
    "from paddlenlp.transformers import AutoModel\n",
    "\n",
    "model = AutoModel.from_pretrained(\"nielsr/nt5-small-rc1\")\n",
    "input_ids = paddle.randint(100, 200, shape=[1, 20])\n",
    "print(model(input_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e7da3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@article{DBLP:journals/corr/abs-1903-00161,\n",
    "author    = {Dheeru Dua and\n",
    "Yizhong Wang and\n",
    "Pradeep Dasigi and\n",
    "Gabriel Stanovsky and\n",
    "Sameer Singh and\n",
    "Matt Gardner},\n",
    "title     = {{DROP:} {A} Reading Comprehension Benchmark Requiring Discrete Reasoning\n",
    "Over Paragraphs},\n",
    "journal   = {CoRR},\n",
    "volume    = {abs/1903.00161},\n",
    "year      = {2019},\n",
    "url       = {http://arxiv.org/abs/1903.00161},\n",
    "archivePrefix = {arXiv},\n",
    "eprint    = {1903.00161},\n",
    "timestamp = {Wed, 03 Jul 2019 07:17:04 +0200},\n",
    "biburl    = {https://dblp.org/rec/journals/corr/abs-1903-00161.bib},\n",
    "bibsource = {dblp computer science bibliography, https://dblp.org}\n",
    "}\n",
    "a service of Schloss Dagstuhl - Leibniz Center for Informatics\\\\\\\\thomebrowsesearchabout\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f64b56",
   "metadata": {},
   "source": [
    "> 此模型来源于：[https://huggingface.co/nielsr/nt5-small-rc1](https://huggingface.co/https://huggingface.co/nielsr/nt5-small-rc1)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
