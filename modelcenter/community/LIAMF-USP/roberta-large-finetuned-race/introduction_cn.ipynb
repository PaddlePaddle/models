{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Roberta Large Fine Tuned on RACE\n", "\n", "## Model description\n", "\n", "This model is a fine-tuned model of Roberta-large applied on RACE\n", "\n", "#### How to use\n"]}, {"cell_type": "code", "metadata": {}, "source": "import paddle\nfrom paddlenlp.transformers import AutoModel\n\nmodel = AutoModel.from_pretrained(\"LIAMF-USP/roberta-large-finetuned-race\")\ninput_ids = paddle.randint(100, 200, shape=[1, 20])\nprint(model(input_ids))"}, {"cell_type": "markdown", "metadata": {}, "source": ["\n", "## Training data\n", "\n", "The initial model was [roberta large model](https://huggingface.co/roberta-large) which was then fine-tuned on [RACE dataset](https://www.cs.cmu.edu/~glai1/data/race/)\n", "\n", "## Training procedure\n", "\n", "It was necessary to preprocess the data with a method that is exemplified for a single instance in the _How to use_ section. The used hyperparameters were the following:\n", "\n", "| Hyperparameter | Value |\n", "|:----:|:----:|\n", "| adam_beta1                  | 0.9      |\n", "| adam_beta2                  | 0.98     |\n", "| adam_epsilon                | 1.000e-8 |\n", "| eval_batch_size             | 32       |\n", "| train_batch_size            | 1        |\n", "| fp16                        | True     |\n", "| gradient_accumulation_steps | 16       |\n", "| learning_rate               | 0.00001  |\n", "| warmup_steps                | 1000     |\n", "| max_length                  | 512      |\n", "| epochs                      | 4        |\n", "\n", "## Eval results:\n", "| Dataset Acc | Eval | All Test |High School Test |Middle School Test |\n", "|:----:|:----:|:----:|:----:|:----:|\n", "|      | 85.2 | 84.9|83.5|88.0|\n", "\n", "**The model was trained with a Tesla V100-PCIE-16GB**\n", "> 此模型来源于：[https://huggingface.co/LIAMF-USP/roberta-large-finetuned-race](https://huggingface.co/https://huggingface.co/LIAMF-USP/roberta-large-finetuned-race)"]}, {"cell_type": "markdown", "metadata": {}, "source": "> 此模型来源于：[LIAMF-USP/roberta-large-finetuned-race](https://huggingface.co/LIAMF-USP/roberta-large-finetuned-race)"}], "metadata": {"language_info": {"name": "python"}, "orig_nbformat": 4}, "nbformat": 4, "nbformat_minor": 2}