{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19290815",
   "metadata": {},
   "source": [
    "# Roberta Large Fine Tuned on RACE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2020c7",
   "metadata": {},
   "source": [
    "## Model description\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca26a86",
   "metadata": {},
   "source": [
    "This model is a fine-tuned model of Roberta-large applied on RACE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b1546b",
   "metadata": {},
   "source": [
    "#### How to use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379b7da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade paddlenlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0ae78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle\n",
    "from paddlenlp.transformers import AutoModel\n",
    "\n",
    "model = AutoModel.from_pretrained(\"LIAMF-USP/roberta-large-finetuned-race\")\n",
    "input_ids = paddle.randint(100, 200, shape=[1, 20])\n",
    "print(model(input_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0908b657",
   "metadata": {},
   "source": [
    "## Training data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c4a675",
   "metadata": {},
   "source": [
    "The initial model was [roberta large model](https://huggingface.co/roberta-large) which was then fine-tuned on [RACE dataset](https://www.cs.cmu.edu/~glai1/data/race/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dced57c2",
   "metadata": {},
   "source": [
    "## Training procedure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4b836d",
   "metadata": {},
   "source": [
    "It was necessary to preprocess the data with a method that is exemplified for a single instance in the _How to use_ section. The used hyperparameters were the following:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eace378",
   "metadata": {},
   "source": [
    "| Hyperparameter | Value |\n",
    "|:----:|:----:|\n",
    "| adam_beta1                  | 0.9      |\n",
    "| adam_beta2                  | 0.98     |\n",
    "| adam_epsilon                | 1.000e-8 |\n",
    "| eval_batch_size             | 32       |\n",
    "| train_batch_size            | 1        |\n",
    "| fp16                        | True     |\n",
    "| gradient_accumulation_steps | 16       |\n",
    "| learning_rate               | 0.00001  |\n",
    "| warmup_steps                | 1000     |\n",
    "| max_length                  | 512      |\n",
    "| epochs                      | 4        |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d06a3a",
   "metadata": {},
   "source": [
    "## Eval results:\n",
    "| Dataset Acc | Eval | All Test |High School Test |Middle School Test |\n",
    "|:----:|:----:|:----:|:----:|:----:|\n",
    "|      | 85.2 | 84.9|83.5|88.0|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa888de",
   "metadata": {},
   "source": [
    "**The model was trained with a Tesla V100-PCIE-16GB**\n",
    "> 此模型来源于：[https://huggingface.co/LIAMF-USP/roberta-large-finetuned-race](https://huggingface.co/https://huggingface.co/LIAMF-USP/roberta-large-finetuned-race)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
