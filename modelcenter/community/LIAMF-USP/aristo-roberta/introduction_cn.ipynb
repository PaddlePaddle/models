{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Roberta Large Fine Tuned on RACE\n", "\n", "## Model description\n", "\n", "This model follows the implementation by Allen AI team about [Aristo Roberta V7 Model](https://leaderboard.allenai.org/arc/submission/blcotvl7rrltlue6bsv0) given in [ARC Challenge](https://leaderboard.allenai.org/arc/submissions/public)\n", "\n", "#### How to use\n"]}, {"cell_type": "code", "metadata": {}, "source": "import paddle\nfrom paddlenlp.transformers import AutoModel\n\nmodel = AutoModel.from_pretrained(\"LIAMF-USP/aristo-roberta\")\ninput_ids = paddle.randint(100, 200, shape=[1, 20])\nprint(model(input_ids))"}, {"cell_type": "markdown", "metadata": {}, "source": ["\n", "## Training data\n", "\n", "the Training data was the same as proposed [here](https://leaderboard.allenai.org/arc/submission/blcotvl7rrltlue6bsv0)\n", "\n", "The only diferrence was the hypeparameters of RACE fine tuned model, which were reported [here](https://huggingface.co/LIAMF-USP/roberta-large-finetuned-race#eval-results)\n", "\n", "## Training procedure\n", "\n", "It was necessary to preprocess the data with a method that is exemplified for a single instance in the _How to use_ section. The used hyperparameters were the following:\n", "\n", "| Hyperparameter | Value |\n", "|:----:|:----:|\n", "| adam_beta1                  | 0.9      |\n", "| adam_beta2                  | 0.98     |\n", "| adam_epsilon                | 1.000e-8 |\n", "| eval_batch_size             | 16       |\n", "| train_batch_size            | 4        |\n", "| fp16                        | True     |\n", "| gradient_accumulation_steps | 4       |\n", "| learning_rate               | 0.00001  |\n", "| warmup_steps                | 0.06     |\n", "| max_length                  | 256      |\n", "| epochs                  |   4      |\n", "\n", "The other parameters were the default ones from [Trainer](https://huggingface.co/transformers/main_classes/trainer.html) and [Trainer Arguments](https://huggingface.co/transformers/main_classes/trainer.html#trainingarguments)\n", "\n", "## Eval results:\n", "| Dataset Acc | Challenge Test |\n", "|:----:|:----:|\n", "|      | 65.358 |\n", "\n", "**The model was trained with a TITAN RTX**\n", "> 此模型来源于：[https://huggingface.co/LIAMF-USP/aristo-roberta](https://huggingface.co/https://huggingface.co/LIAMF-USP/aristo-roberta)"]}, {"cell_type": "markdown", "metadata": {}, "source": "> 此模型来源于：[LIAMF-USP/aristo-roberta](https://huggingface.co/LIAMF-USP/aristo-roberta)"}], "metadata": {"language_info": {"name": "python"}, "orig_nbformat": 4}, "nbformat": 4, "nbformat_minor": 2}