{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57a8ca57",
   "metadata": {},
   "source": [
    "# Roberta Large Fine Tuned on RACE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1936768",
   "metadata": {},
   "source": [
    "## Model description\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fa2d03",
   "metadata": {},
   "source": [
    "This model follows the implementation by Allen AI team about [Aristo Roberta V7 Model](https://leaderboard.allenai.org/arc/submission/blcotvl7rrltlue6bsv0) given in [ARC Challenge](https://leaderboard.allenai.org/arc/submissions/public)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58421a8",
   "metadata": {},
   "source": [
    "#### How to use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df48843",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade paddlenlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3a6f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle\n",
    "from paddlenlp.transformers import AutoModel\n",
    "\n",
    "model = AutoModel.from_pretrained(\"LIAMF-USP/aristo-roberta\")\n",
    "input_ids = paddle.randint(100, 200, shape=[1, 20])\n",
    "print(model(input_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c34a135",
   "metadata": {},
   "source": [
    "## Training data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9231d71b",
   "metadata": {},
   "source": [
    "the Training data was the same as proposed [here](https://leaderboard.allenai.org/arc/submission/blcotvl7rrltlue6bsv0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289dae97",
   "metadata": {},
   "source": [
    "The only diferrence was the hypeparameters of RACE fine tuned model, which were reported [here](https://huggingface.co/LIAMF-USP/roberta-large-finetuned-race#eval-results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a297945c",
   "metadata": {},
   "source": [
    "## Training procedure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594e0168",
   "metadata": {},
   "source": [
    "It was necessary to preprocess the data with a method that is exemplified for a single instance in the _How to use_ section. The used hyperparameters were the following:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e546a0f3",
   "metadata": {},
   "source": [
    "| Hyperparameter | Value |\n",
    "|:----:|:----:|\n",
    "| adam_beta1                  | 0.9      |\n",
    "| adam_beta2                  | 0.98     |\n",
    "| adam_epsilon                | 1.000e-8 |\n",
    "| eval_batch_size             | 16       |\n",
    "| train_batch_size            | 4        |\n",
    "| fp16                        | True     |\n",
    "| gradient_accumulation_steps | 4       |\n",
    "| learning_rate               | 0.00001  |\n",
    "| warmup_steps                | 0.06     |\n",
    "| max_length                  | 256      |\n",
    "| epochs                  |   4      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6525dd",
   "metadata": {},
   "source": [
    "The other parameters were the default ones from [Trainer](https://huggingface.co/transformers/main_classes/trainer.html) and [Trainer Arguments](https://huggingface.co/transformers/main_classes/trainer.html#trainingarguments)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15768579",
   "metadata": {},
   "source": [
    "## Eval results:\n",
    "| Dataset Acc | Challenge Test |\n",
    "|:----:|:----:|\n",
    "|      | 65.358 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8958ba",
   "metadata": {},
   "source": [
    "**The model was trained with a TITAN RTX**\n",
    "> 此模型来源于：[https://huggingface.co/LIAMF-USP/aristo-roberta](https://huggingface.co/https://huggingface.co/LIAMF-USP/aristo-roberta)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
