{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3dbf349",
   "metadata": {},
   "source": [
    "# ğŸ¤— + ğŸ“š dbmdz Turkish BERT model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479d8e10",
   "metadata": {},
   "source": [
    "In this repository the MDZ Digital Library team (dbmdz) at the Bavarian State\n",
    "Library open sources an uncased model for Turkish ğŸ‰\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc31d938",
   "metadata": {},
   "source": [
    "# ğŸ‡¹ğŸ‡· BERTurk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05c98f4",
   "metadata": {},
   "source": [
    "BERTurk is a community-driven uncased BERT model for Turkish.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116bbd89",
   "metadata": {},
   "source": [
    "Some datasets used for pretraining and evaluation are contributed from the\n",
    "awesome Turkish NLP community, as well as the decision for the model name: BERTurk.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d16f47",
   "metadata": {},
   "source": [
    "## Stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12663467",
   "metadata": {},
   "source": [
    "The current version of the model is trained on a filtered and sentence\n",
    "segmented version of the Turkish [OSCAR corpus](https://traces1.inria.fr/oscar/),\n",
    "a recent Wikipedia dump, various [OPUS corpora](http://opus.nlpl.eu/) and a\n",
    "special corpus provided by [Kemal Oflazer](http://www.andrew.cmu.edu/user/ko/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec62302d",
   "metadata": {},
   "source": [
    "The final training corpus has a size of 35GB and 44,04,976,662 tokens.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ded1a0",
   "metadata": {},
   "source": [
    "Thanks to Google's TensorFlow Research Cloud (TFRC) we could train an uncased model\n",
    "on a TPU v3-8 for 2M steps.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f5c5f0",
   "metadata": {},
   "source": [
    "## Model weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886bbcb6",
   "metadata": {},
   "source": [
    "Currently only PyTorch-[Transformers](https://github.com/huggingface/transformers)\n",
    "compatible weights are available. If you need access to TensorFlow checkpoints,\n",
    "please raise an issue!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915fd9da",
   "metadata": {},
   "source": [
    "| Model                             | Downloads\n",
    "| --------------------------------- | ---------------------------------------------------------------------------------------------------------------\n",
    "| `dbmdz/bert-base-turkish-uncased`   | [`config.json`](https://cdn.huggingface.co/dbmdz/bert-base-turkish-uncased/config.json) â€¢ [`pytorch_model.bin`](https://cdn.huggingface.co/dbmdz/bert-base-turkish-uncased/pytorch_model.bin) â€¢ [`vocab.txt`](https://cdn.huggingface.co/dbmdz/bert-base-turkish-uncased/vocab.txt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab29ae1",
   "metadata": {},
   "source": [
    "## Usage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531e7c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade paddlenlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23a11a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle\n",
    "from paddlenlp.transformers import AutoModel\n",
    "\n",
    "model = AutoModel.from_pretrained(\"dbmdz/bert-base-turkish-uncased\")\n",
    "input_ids = paddle.randint(100, 200, shape=[1, 20])\n",
    "print(model(input_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13378dbb",
   "metadata": {},
   "source": [
    "## Results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19c402a",
   "metadata": {},
   "source": [
    "For results on PoS tagging or NER tasks, please refer to\n",
    "[this repository](https://github.com/stefan-it/turkish-bert).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d84c09f",
   "metadata": {},
   "source": [
    "# Contact (Bugs, Feedback, Contribution and more)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d8ae70",
   "metadata": {},
   "source": [
    "For questions about our BERT models just open an issue\n",
    "[here](https://github.com/dbmdz/berts/issues/new) ğŸ¤—\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4d2556",
   "metadata": {},
   "source": [
    "# Acknowledgments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e64d983",
   "metadata": {},
   "source": [
    "Thanks to [Kemal Oflazer](http://www.andrew.cmu.edu/user/ko/) for providing us\n",
    "additional large corpora for Turkish. Many thanks to Reyyan Yeniterzi for providing\n",
    "us the Turkish NER dataset for evaluation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331c3e2d",
   "metadata": {},
   "source": [
    "Research supported with Cloud TPUs from Google's TensorFlow Research Cloud (TFRC).\n",
    "Thanks for providing access to the TFRC â¤ï¸\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e10e25f",
   "metadata": {},
   "source": [
    "Thanks to the generous support from the [Hugging Face](https://huggingface.co/) team,\n",
    "it is possible to download both cased and uncased models from their S3 storage ğŸ¤—\n",
    "> æ­¤æ¨¡å‹ä»‹ç»åŠæƒé‡æ¥æºäº[https://huggingface.co/dbmdz/bert-base-turkish-uncased](https://huggingface.co/dbmdz/bert-base-turkish-uncased)ï¼Œå¹¶è½¬æ¢ä¸ºé£æ¡¨æ¨¡å‹æ ¼å¼\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
