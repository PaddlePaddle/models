{"cells": [{"cell_type": "code", "metadata": {}, "source": "import paddle\nfrom paddlenlp.transformers import AutoModel\n\nmodel = AutoModel.from_pretrained(\"dbmdz/bert-base-german-uncased\")\ninput_ids = paddle.randint(100, 200, shape=[1, 20])\nprint(model(input_ids))"}, {"cell_type": "markdown", "metadata": {}, "source": ["## Results\n", "\n", "For results on downstream tasks like NER or PoS tagging, please refer to\n", "[this repository](https://github.com/stefan-it/fine-tuned-berts-seq).\n", "\n", "# Huggingface model hub\n", "\n", "All models are available on the [Huggingface model hub](https://huggingface.co/dbmdz).\n", "\n", "# Contact (Bugs, Feedback, Contribution and more)\n", "\n", "For questions about our BERT models just open an issue\n", "[here](https://github.com/dbmdz/berts/issues/new) ðŸ¤—\n", "\n", "# Acknowledgments\n", "\n", "Research supported with Cloud TPUs from Google's TensorFlow Research Cloud (TFRC).\n", "Thanks for providing access to the TFRC â¤ï¸\n", "\n", "Thanks to the generous support from the [Hugging Face](https://huggingface.co/) team,\n", "it is possible to download both cased and uncased models from their S3 storage ðŸ¤—\n", "> æ­¤æ¨¡åž‹æ¥æºäºŽï¼š[https://huggingface.co/dbmdz/bert-base-german-uncased](https://huggingface.co/https://huggingface.co/dbmdz/bert-base-german-uncased)"]}, {"cell_type": "markdown", "metadata": {}, "source": "> this model is from [dbmdz/bert-base-german-uncased](https://huggingface.co/dbmdz/bert-base-german-uncased)"}], "metadata": {"language_info": {"name": "python"}, "orig_nbformat": 4}, "nbformat": 4, "nbformat_minor": 2}