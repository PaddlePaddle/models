{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2670bf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle\n",
    "from paddlenlp.transformers import AutoModel\n",
    "\n",
    "model = AutoModel.from_pretrained(\"dbmdz/bert-base-german-cased\")\n",
    "input_ids = paddle.randint(100, 200, shape=[1, 20])\n",
    "print(model(input_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333d4421",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "For results on downstream tasks like NER or PoS tagging, please refer to\n",
    "[this repository](https://github.com/stefan-it/fine-tuned-berts-seq).\n",
    "\n",
    "# Huggingface model hub\n",
    "\n",
    "All models are available on the [Huggingface model hub](https://huggingface.co/dbmdz).\n",
    "\n",
    "# Contact (Bugs, Feedback, Contribution and more)\n",
    "\n",
    "For questions about our BERT models just open an issue\n",
    "[here](https://github.com/dbmdz/berts/issues/new) ğŸ¤—\n",
    "\n",
    "# Acknowledgments\n",
    "\n",
    "Research supported with Cloud TPUs from Google's TensorFlow Research Cloud (TFRC).\n",
    "Thanks for providing access to the TFRC â¤ï¸\n",
    "\n",
    "Thanks to the generous support from the [Hugging Face](https://huggingface.co/) team,\n",
    "it is possible to download both cased and uncased models from their S3 storage ğŸ¤—\n",
    "> æ­¤æ¨¡å‹æ¥æºäºï¼š[https://huggingface.co/dbmdz/bert-base-german-cased](https://huggingface.co/https://huggingface.co/dbmdz/bert-base-german-cased)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
