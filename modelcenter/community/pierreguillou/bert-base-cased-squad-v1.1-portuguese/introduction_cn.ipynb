{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea71fd20",
   "metadata": {},
   "source": [
    "# Portuguese BERT base cased QA (Question Answering), finetuned on SQUAD v1.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f4378c",
   "metadata": {},
   "source": [
    "![Exemple of what can do the Portuguese BERT base cased QA (Question Answering), finetuned on SQUAD v1.1](https://miro.medium.com/max/2000/1*te5MmdesAHCmg4KmK8zD3g.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98422c18",
   "metadata": {},
   "source": [
    "## Introduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a736dfe8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17b73f8f",
   "metadata": {},
   "source": [
    "The language model used is the [BERTimbau Base](https://huggingface.co/neuralmind/bert-base-portuguese-cased) (aka \"bert-base-portuguese-cased\") from [Neuralmind.ai](https://neuralmind.ai/): BERTimbau Base is a pretrained BERT model for Brazilian Portuguese that achieves state-of-the-art performances on three downstream NLP tasks: Named Entity Recognition, Sentence Textual Similarity and Recognizing Textual Entailment. It is available in two sizes: Base and Large.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d419b6b3",
   "metadata": {},
   "source": [
    "## Informations on the method used\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e760b4",
   "metadata": {},
   "source": [
    "All the informations are in the blog post : [NLP | Modelo de Question Answering em qualquer idioma baseado no BERT base (estudo de caso em português)](https://medium.com/@pierre_guillou/nlp-modelo-de-question-answering-em-qualquer-idioma-baseado-no-bert-base-estudo-de-caso-em-12093d385e78)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76457ed3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad2f4efd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4ffc44cd",
   "metadata": {},
   "source": [
    "## Performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06a185c",
   "metadata": {},
   "source": [
    "The results obtained are the following:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e14ab34",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade paddlenlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71a2bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle\n",
    "from paddlenlp.transformers import AutoModel\n",
    "\n",
    "model = AutoModel.from_pretrained(\"pierreguillou/bert-base-cased-squad-v1.1-portuguese\")\n",
    "input_ids = paddle.randint(100, 200, shape=[1, 20])\n",
    "print(model(input_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42517bf2",
   "metadata": {},
   "source": [
    "@inproceedings{pierreguillou2021bertbasecasedsquadv11portuguese,\n",
    "title={Portuguese BERT base cased QA (Question Answering), finetuned on SQUAD v1.1},\n",
    "author={Pierre Guillou},\n",
    "year={2021}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ea0040",
   "metadata": {},
   "source": [
    "> 此模型来源于：[https://huggingface.co/pierreguillou/bert-base-cased-squad-v1.1-portuguese](https://huggingface.co/https://huggingface.co/pierreguillou/bert-base-cased-squad-v1.1-portuguese)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
