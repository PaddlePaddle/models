{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f78a62a0",
   "metadata": {},
   "source": [
    "# Portuguese BERT base cased QA (Question Answering), finetuned on SQUAD v1.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120a9dd3",
   "metadata": {},
   "source": [
    "![Exemple of what can do the Portuguese BERT base cased QA (Question Answering), finetuned on SQUAD v1.1](https://miro.medium.com/max/2000/1*te5MmdesAHCmg4KmK8zD3g.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf0f2a8",
   "metadata": {},
   "source": [
    "## Introduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8370d055",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9efad775",
   "metadata": {},
   "source": [
    "The language model used is the [BERTimbau Base](https://huggingface.co/neuralmind/bert-base-portuguese-cased) (aka \"bert-base-portuguese-cased\") from [Neuralmind.ai](https://neuralmind.ai/): BERTimbau Base is a pretrained BERT model for Brazilian Portuguese that achieves state-of-the-art performances on three downstream NLP tasks: Named Entity Recognition, Sentence Textual Similarity and Recognizing Textual Entailment. It is available in two sizes: Base and Large.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e0e02f",
   "metadata": {},
   "source": [
    "## Informations on the method used\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f62216",
   "metadata": {},
   "source": [
    "All the informations are in the blog post : [NLP | Modelo de Question Answering em qualquer idioma baseado no BERT base (estudo de caso em português)](https://medium.com/@pierre_guillou/nlp-modelo-de-question-answering-em-qualquer-idioma-baseado-no-bert-base-estudo-de-caso-em-12093d385e78)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b483708f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d050490f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab145c92",
   "metadata": {},
   "source": [
    "## Performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d339c5c",
   "metadata": {},
   "source": [
    "The results obtained are the following:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df39da20",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade paddlenlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507374a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle\n",
    "from paddlenlp.transformers import AutoModel\n",
    "\n",
    "model = AutoModel.from_pretrained(\"pierreguillou/bert-base-cased-squad-v1.1-portuguese\")\n",
    "input_ids = paddle.randint(100, 200, shape=[1, 20])\n",
    "print(model(input_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea38db2d",
   "metadata": {},
   "source": [
    "@inproceedings{pierreguillou2021bertbasecasedsquadv11portuguese,\n",
    "title={Portuguese BERT base cased QA (Question Answering), finetuned on SQUAD v1.1},\n",
    "author={Pierre Guillou},\n",
    "year={2021}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb52637",
   "metadata": {},
   "source": [
    "> 此模型来源于：[https://huggingface.co/pierreguillou/bert-base-cased-squad-v1.1-portuguese](https://huggingface.co/https://huggingface.co/pierreguillou/bert-base-cased-squad-v1.1-portuguese)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
