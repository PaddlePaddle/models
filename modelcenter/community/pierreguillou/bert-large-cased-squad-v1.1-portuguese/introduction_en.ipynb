{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f0a3f4d",
   "metadata": {},
   "source": [
    "# Portuguese BERT large cased QA (Question Answering), finetuned on SQUAD v1.1\n",
    "\n",
    "![Exemple of what can do the Portuguese BERT large cased QA (Question Answering), finetuned on SQUAD v1.1](https://miro.medium.com/max/5256/1*QxyeAjT2V1OfE2B6nEcs3w.png)\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The model was trained on the dataset SQUAD v1.1 in portuguese from the [Deep Learning Brasil group](http://www.deeplearningbrasil.com.br/).\n",
    "\n",
    "The language model used is the [BERTimbau Large](https://huggingface.co/neuralmind/bert-large-portuguese-cased) (aka \"bert-large-portuguese-cased\") from [Neuralmind.ai](https://neuralmind.ai/): BERTimbau is a pretrained BERT model for Brazilian Portuguese that achieves state-of-the-art performances on three downstream NLP tasks: Named Entity Recognition, Sentence Textual Similarity and Recognizing Textual Entailment. It is available in two sizes: Base and Large.\n",
    "\n",
    "## Informations on the method used\n",
    "\n",
    "All the informations are in the blog post : [NLP | Como treinar um modelo de Question Answering em qualquer linguagem baseado no BERT large, melhorando o desempenho do modelo utilizando o BERT base? (estudo de caso em português)](https://medium.com/@pierre_guillou/nlp-como-treinar-um-modelo-de-question-answering-em-qualquer-linguagem-baseado-no-bert-large-1c899262dd96)\n",
    "\n",
    "## Notebook in GitHub\n",
    "\n",
    "[question_answering_BERT_large_cased_squad_v11_pt.ipynb](https://github.com/piegu/language-models/blob/master/question_answering_BERT_large_cased_squad_v11_pt.ipynb) ([nbviewer version](https://nbviewer.jupyter.org/github/piegu/language-models/blob/master/question_answering_BERT_large_cased_squad_v11_pt.ipynb))\n",
    "\n",
    "## Performance\n",
    "\n",
    "The results obtained are the following:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dae8b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle\n",
    "from paddlenlp.transformers import AutoModel\n",
    "\n",
    "model = AutoModel.from_pretrained(\"pierreguillou/bert-large-cased-squad-v1.1-portuguese\")\n",
    "input_ids = paddle.randint(100, 200, shape=[1, 20])\n",
    "print(model(input_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f740e810",
   "metadata": {},
   "source": [
    "> 此模型来源于：[https://huggingface.co/pierreguillou/bert-large-cased-squad-v1.1-portuguese](https://huggingface.co/https://huggingface.co/pierreguillou/bert-large-cased-squad-v1.1-portuguese)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
