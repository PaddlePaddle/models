{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Portuguese BERT large cased QA (Question Answering), finetuned on SQUAD v1.1\n", "\n", "![Exemple of what can do the Portuguese BERT large cased QA (Question Answering), finetuned on SQUAD v1.1](https://miro.medium.com/max/5256/1*QxyeAjT2V1OfE2B6nEcs3w.png)\n", "\n", "## Introduction\n", "\n", "The model was trained on the dataset SQUAD v1.1 in portuguese from the [Deep Learning Brasil group](http://www.deeplearningbrasil.com.br/).\n", "\n", "The language model used is the [BERTimbau Large](https://huggingface.co/neuralmind/bert-large-portuguese-cased) (aka \"bert-large-portuguese-cased\") from [Neuralmind.ai](https://neuralmind.ai/): BERTimbau is a pretrained BERT model for Brazilian Portuguese that achieves state-of-the-art performances on three downstream NLP tasks: Named Entity Recognition, Sentence Textual Similarity and Recognizing Textual Entailment. It is available in two sizes: Base and Large.\n", "\n", "## Informations on the method used\n", "\n", "All the informations are in the blog post : [NLP | Como treinar um modelo de Question Answering em qualquer linguagem baseado no BERT large, melhorando o desempenho do modelo utilizando o BERT base? (estudo de caso em português)](https://medium.com/@pierre_guillou/nlp-como-treinar-um-modelo-de-question-answering-em-qualquer-linguagem-baseado-no-bert-large-1c899262dd96)\n", "\n", "## Notebook in GitHub\n", "\n", "[question_answering_BERT_large_cased_squad_v11_pt.ipynb](https://github.com/piegu/language-models/blob/master/question_answering_BERT_large_cased_squad_v11_pt.ipynb) ([nbviewer version](https://nbviewer.jupyter.org/github/piegu/language-models/blob/master/question_answering_BERT_large_cased_squad_v11_pt.ipynb))\n", "\n", "## Performance\n", "\n", "The results obtained are the following:\n"]}, {"cell_type": "code", "metadata": {}, "source": "import paddle\nfrom paddlenlp.transformers import AutoModel\n\nmodel = AutoModel.from_pretrained(\"pierreguillou/bert-large-cased-squad-v1.1-portuguese\")\ninput_ids = paddle.randint(100, 200, shape=[1, 20])\nprint(model(input_ids))"}, {"cell_type": "code", "metadata": {}, "source": ["@inproceedings{pierreguillou2021bertlargecasedsquadv11portuguese,\n", "title={Portuguese BERT large cased QA (Question Answering), finetuned on SQUAD v1.1},\n", "author={Pierre Guillou},\n", "year={2021}\n", "}\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["> 此模型来源于：[https://huggingface.co/pierreguillou/bert-large-cased-squad-v1.1-portuguese](https://huggingface.co/https://huggingface.co/pierreguillou/bert-large-cased-squad-v1.1-portuguese)"]}, {"cell_type": "markdown", "metadata": {}, "source": "> 此模型来源于：[pierreguillou/bert-large-cased-squad-v1.1-portuguese](https://huggingface.co/pierreguillou/bert-large-cased-squad-v1.1-portuguese)"}], "metadata": {"language_info": {"name": "python"}, "orig_nbformat": 4}, "nbformat": 4, "nbformat_minor": 2}