{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62b544a3",
   "metadata": {},
   "source": [
    "# COVID-Twitter-BERT v2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229d13d6",
   "metadata": {},
   "source": [
    "## Model description\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e17af45",
   "metadata": {},
   "source": [
    "BERT-large-uncased model, pretrained on a corpus of messages from Twitter about COVID-19. This model is identical to [covid-twitter-bert](https://huggingface.co/digitalepidemiologylab/covid-twitter-bert) - but trained on more data, resulting in higher downstream performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5daddc05",
   "metadata": {},
   "source": [
    "Find more info on our [GitHub page](https://github.com/digitalepidemiologylab/covid-twitter-bert).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7430dcfc",
   "metadata": {},
   "source": [
    "## Intended uses & limitations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c97eaf",
   "metadata": {},
   "source": [
    "The model can e.g. be used in the `fill-mask` task (see below). You can also use the model without the MLM/NSP heads and train a classifier with it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e180d053",
   "metadata": {},
   "source": [
    "#### How to use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be08538",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade paddlenlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0dc1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle\n",
    "from paddlenlp.transformers import AutoModel\n",
    "\n",
    "model = AutoModel.from_pretrained(\"digitalepidemiologylab/covid-twitter-bert-v2\")\n",
    "input_ids = paddle.randint(100, 200, shape=[1, 20])\n",
    "print(model(input_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b164817",
   "metadata": {},
   "source": [
    "COVID-Twitter-BERT: A Natural Language Processing Model to Analyse COVID-19 Content on Twitter.\n",
    "arXiv preprint arXiv:2005.07503 (2020).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfddf28f",
   "metadata": {},
   "source": [
    "> 此模型来源于：[https://huggingface.co/digitalepidemiologylab/covid-twitter-bert-v2](https://huggingface.co/https://huggingface.co/digitalepidemiologylab/covid-twitter-bert-v2)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
