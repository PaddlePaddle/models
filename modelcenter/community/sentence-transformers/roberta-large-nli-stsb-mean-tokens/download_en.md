#  model list

##  

| model  | description | model_size  | download         |
| --- | --- | --- | --- |
|sentence-transformers/roberta-large-nli-stsb-mean-tokens|  | 1.32G | [merges.txt](https://bj.bcebos.com/paddlenlp/models/community/sentence-transformers/roberta-large-nli-stsb-mean-tokens/merges.txt)<br>[model_config.json](https://bj.bcebos.com/paddlenlp/models/community/sentence-transformers/roberta-large-nli-stsb-mean-tokens/model_config.json)<br>[model_state.pdparams](https://bj.bcebos.com/paddlenlp/models/community/sentence-transformers/roberta-large-nli-stsb-mean-tokens/model_state.pdparams)<br>[tokenizer_config.json](https://bj.bcebos.com/paddlenlp/models/community/sentence-transformers/roberta-large-nli-stsb-mean-tokens/tokenizer_config.json)<br>[vocab.json](https://bj.bcebos.com/paddlenlp/models/community/sentence-transformers/roberta-large-nli-stsb-mean-tokens/vocab.json)<br>[vocab.txt](https://bj.bcebos.com/paddlenlp/models/community/sentence-transformers/roberta-large-nli-stsb-mean-tokens/vocab.txt) |

or you can download all of model file with the following steps:

* install paddlenlp

```shell
pip install --upgrade paddlenlp
```

* download model with cli tool

```shell
paddlenlp download --cache-dir ./pretrained_models sentence-transformers/roberta-large-nli-stsb-mean-tokens
```

If you have any problems with it, you can post issue on [PaddleNLP](https://github.com/PaddlePaddle/PaddleNLP) to get support.
