{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b33225b",
   "metadata": {},
   "source": [
    "# This model is specifically designed for legal domain.\n",
    "\n",
    "## Chinese ELECTRA\n",
    "Google and Stanford University released a new pre-trained model called ELECTRA, which has a much compact model size and relatively competitive performance compared to BERT and its variants.\n",
    "For further accelerating the research of the Chinese pre-trained model, the Joint Laboratory of HIT and iFLYTEK Research (HFL) has released the Chinese ELECTRA models based on the official code of ELECTRA.\n",
    "ELECTRA-small could reach similar or even higher scores on several NLP tasks with only 1/10 parameters compared to BERT and its variants.\n",
    "\n",
    "This project is based on the official code of ELECTRA: [https://github.com/google-research/electra](https://github.com/google-research/electra)\n",
    "\n",
    "You may also interested in,\n",
    "- Chinese BERT series: https://github.com/ymcui/Chinese-BERT-wwm\n",
    "- Chinese ELECTRA: https://github.com/ymcui/Chinese-ELECTRA\n",
    "- Chinese XLNet: https://github.com/ymcui/Chinese-XLNet\n",
    "- Knowledge Distillation Toolkit - TextBrewer: https://github.com/airaria/TextBrewer\n",
    "\n",
    "More resources by HFL: https://github.com/ymcui/HFL-Anthology\n",
    "\n",
    "\n",
    "## Citation\n",
    "If you find our resource or paper is useful, please consider including the following citation in your paper.\n",
    "- https://arxiv.org/abs/2004.13922\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c29e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "@inproceedings{cui-etal-2020-revisiting,\n",
    "title = \"Revisiting Pre-Trained Models for {C}hinese Natural Language Processing\",\n",
    "author = \"Cui, Yiming  and\n",
    "Che, Wanxiang  and\n",
    "Liu, Ting  and\n",
    "Qin, Bing  and\n",
    "Wang, Shijin  and\n",
    "Hu, Guoping\",\n",
    "booktitle = \"Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: Findings\",\n",
    "month = nov,\n",
    "year = \"2020\",\n",
    "address = \"Online\",\n",
    "publisher = \"Association for Computational Linguistics\",\n",
    "url = \"https://www.aclweb.org/anthology/2020.findings-emnlp.58\",\n",
    "pages = \"657--668\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483ee979",
   "metadata": {},
   "source": [
    "> 此模型来源于：[https://huggingface.co/hfl/chinese-legal-electra-small-generator](https://huggingface.co/https://huggingface.co/hfl/chinese-legal-electra-small-generator)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
