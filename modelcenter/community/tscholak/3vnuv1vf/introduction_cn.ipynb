{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "714ae1fe",
   "metadata": {},
   "source": [
    "## tscholak/3vnuv1vf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96845346",
   "metadata": {},
   "source": [
    "Fine-tuned weights for [PICARD - Parsing Incrementally for Constrained Auto-Regressive Decoding from Language Models](https://arxiv.org/abs/2109.05093) based on [t5.1.1.lm100k.large](https://github.com/google-research/text-to-text-transfer-transformer/blob/main/released_checkpoints.md#lm-adapted-t511lm100k).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a5d334",
   "metadata": {},
   "source": [
    "### Training Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9427b7",
   "metadata": {},
   "source": [
    "The model has been fine-tuned on the 7000 training examples in the [Spider text-to-SQL dataset](https://yale-lily.github.io/spider). The model solves Spider's zero-shot text-to-SQL translation task, and that means that it can generalize to unseen SQL databases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf5075f",
   "metadata": {},
   "source": [
    "### Training Objective\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68258b94",
   "metadata": {},
   "source": [
    "This model was initialized with [t5.1.1.lm100k.large](https://github.com/google-research/text-to-text-transfer-transformer/blob/main/released_checkpoints.md#lm-adapted-t511lm100k) and fine-tuned with the text-to-text generation objective.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927f7110",
   "metadata": {},
   "source": [
    "Questions are always grounded in a database schema, and the model is trained to predict the SQL query that would be used to answer the question. The input to the model is composed of the user's natural language question, the database identifier, and a list of tables and their columns:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eceb8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade paddlenlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0120d979",
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle\n",
    "from paddlenlp.transformers import AutoModel\n",
    "\n",
    "model = AutoModel.from_pretrained(\"tscholak/3vnuv1vf\")\n",
    "input_ids = paddle.randint(100, 200, shape=[1, 20])\n",
    "print(model(input_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a866985",
   "metadata": {},
   "source": [
    "@inproceedings{Scholak2021:PICARD,\n",
    "author = {Torsten Scholak and Nathan Schucher and Dzmitry Bahdanau},\n",
    "title = \"{PICARD}: Parsing Incrementally for Constrained Auto-Regressive Decoding from Language Models\",\n",
    "booktitle = \"Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing\",\n",
    "month = nov,\n",
    "year = \"2021\",\n",
    "publisher = \"Association for Computational Linguistics\",\n",
    "url = \"https://aclanthology.org/2021.emnlp-main.779\",\n",
    "pages = \"9895--9901\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1d9f2b",
   "metadata": {},
   "source": [
    "> 此模型来源于：[https://huggingface.co/tscholak/3vnuv1vf](https://huggingface.co/https://huggingface.co/tscholak/3vnuv1vf)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
