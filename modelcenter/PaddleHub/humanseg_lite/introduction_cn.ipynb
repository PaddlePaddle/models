{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8afb2a9",
   "metadata": {
    "id": "humanseg_lite"
   },
   "source": [
    "# humanseg_lite\n",
    "\n",
    "|模型名称|humanseg_lite|\n",
    "| :--- | :---: |\n",
    "|类别|图像-图像分割|\n",
    "|网络|shufflenet|\n",
    "|数据集|百度自建数据集|\n",
    "|是否支持Fine-tuning|否|\n",
    "|模型大小|541k|\n",
    "|指标|-|\n",
    "|最新更新日期|2021-02-26|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e7df87",
   "metadata": {
    "id": "一-模型基本信息"
   },
   "source": [
    "## 一、模型基本信息\n",
    "\n",
    "- ### 应用效果展示\n",
    "\n",
    "  - 样例结果示例：\n",
    "    <p align=\"center\">\n",
    "    <img src=\"https://user-images.githubusercontent.com/35907364/130913092-312a5f37-842e-4fd0-8db4-5f853fd8419f.jpg\" width=\"337\" height=\"505\" hspace=\"10\"/> <img src=\"https://user-images.githubusercontent.com/35907364/130916087-7d537ad9-bbc8-4bce-9382-8eb132b35532.png\" width=\"337\" height=\"505\" hspace=\"10\"/>\n",
    "    </p>\n",
    "- ### 模型介绍\n",
    "\n",
    "    - HumanSeg_lite是在ShuffleNetV2网络结构的基础上进行优化，进一步减小了网络规模，网络大小只有541K，量化后只有187K， 适用于手机自拍人像分割，且能在移动端进行实时分割。\n",
    "\n",
    "    - 更多详情请参考：[humanseg_lite](https://github.com/PaddlePaddle/PaddleSeg/tree/release/2.2/contrib/HumanSeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693906a7",
   "metadata": {
    "id": "二-安装"
   },
   "source": [
    "## 二、安装\n",
    "\n",
    "- ### 1、环境依赖\n",
    "\n",
    "    - paddlepaddle >= 2.0.0\n",
    "\n",
    "    - paddlehub >= 2.0.0\n",
    "\n",
    "- ### 2、安装\n",
    "\n",
    "    - ```shell\n",
    "      $ hub install humanseg_lite\n",
    "      ```\n",
    "\n",
    "    -  如您安装时遇到问题，可参考：[零基础windows安装](../../../../docs/docs_ch/get_start/windows_quickstart.md)\n",
    "      | [零基础Linux安装](../../../../docs/docs_ch/get_start/linux_quickstart.md) | [零基础MacOS安装](../../../../docs/docs_ch/get_start/mac_quickstart.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b185b524",
   "metadata": {
    "id": "三-模型api预测"
   },
   "source": [
    "## 三、模型API预测\n",
    "\n",
    "- ### 1、命令行预测\n",
    "\n",
    "    ```\n",
    "    hub run humanseg_lite --input_path \"/PATH/TO/IMAGE\"\n",
    "    ```\n",
    "- ### 2、预测代码示例\n",
    "\n",
    "    - 图片分割及视频分割代码示例：\n",
    "\n",
    "    ```python\n",
    "    import cv2\n",
    "    import paddlehub as hub\n",
    "\n",
    "    human_seg = hub.Module(name='humanseg_lite')\n",
    "    im = cv2.imread('/PATH/TO/IMAGE')\n",
    "    #visualization=True可以用于查看人像分割图片效果，可设置为False提升运行速度。\n",
    "    res = human_seg.segment(images=[im],visualization=True)\n",
    "    print(res[0]['data'])\n",
    "    human_seg.video_segment('/PATH/TO/VIDEO')\n",
    "    ```\n",
    "    - 视频流预测代码示例：\n",
    "\n",
    "    ```python\n",
    "    import cv2\n",
    "    import numpy as np\n",
    "    import paddlehub as hub\n",
    "\n",
    "    human_seg = hub.Module(name='humanseg_lite')\n",
    "    cap_video = cv2.VideoCapture('\\PATH\\TO\\VIDEO')\n",
    "    fps = cap_video.get(cv2.CAP_PROP_FPS)\n",
    "    save_path = 'humanseg_lite_video.avi'\n",
    "    width = int(cap_video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap_video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    cap_out = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc('M', 'J', 'P', 'G'), fps, (width, height))\n",
    "    prev_gray = None\n",
    "    prev_cfd = None\n",
    "    while cap_video.isOpened():\n",
    "        ret, frame_org = cap_video.read()\n",
    "        if ret:\n",
    "            [img_matting, prev_gray, prev_cfd] = human_seg.video_stream_segment(frame_org=frame_org, frame_id=cap_video.get(1), prev_gray=prev_gray, prev_cfd=prev_cfd)\n",
    "            img_matting = np.repeat(img_matting[:, :, np.newaxis], 3, axis=2)\n",
    "            bg_im = np.ones_like(img_matting) * 255\n",
    "            comb = (img_matting * frame_org + (1 - img_matting) * bg_im).astype(np.uint8)\n",
    "            cap_out.write(comb)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    cap_video.release()\n",
    "    cap_out.release()\n",
    "\n",
    "    ```\n",
    "\n",
    "- ### 3、API\n",
    "\n",
    "    ```python\n",
    "    def segment(images=None,\n",
    "                paths=None,\n",
    "                batch_size=1,\n",
    "                use_gpu=False,\n",
    "                visualization=False,\n",
    "                output_dir='humanseg_lite_output')\n",
    "    ```\n",
    "\n",
    "    - 预测API，用于人像分割。\n",
    "\n",
    "    - **参数**\n",
    "\n",
    "        * images (list\\[numpy.ndarray\\]): 图片数据，ndarray.shape 为 \\[H, W, C\\]，BGR格式；\n",
    "        * paths (list\\[str\\]): 图片的路径；\n",
    "        * batch\\_size (int): batch 的大小；\n",
    "        * use\\_gpu (bool): 是否使用 GPU预测，如果使用GPU预测，则在预测之前，请设置CUDA_VISIBLE_DEVICES环境变量，否则不用设置；\n",
    "        * visualization (bool): 是否将识别结果保存为图片文件；\n",
    "        * output\\_dir (str): 图片的保存路径。\n",
    "\n",
    "    - **返回**\n",
    "\n",
    "        * res (list\\[dict\\]): 识别结果的列表，列表中每一个元素为 dict，关键字有 'save\\_path', 'data'，对应的取值为：\n",
    "            * save\\_path (str, optional): 可视化图片的保存路径（仅当visualization=True时存在）；\n",
    "            * data (numpy.ndarray): 人像分割结果，仅包含Alpha通道，取值为0-255 (0为全透明，255为不透明)，也即取值越大的像素点越可能为人体，取值越小的像素点越可能为背景。\n",
    "\n",
    "    ```python\n",
    "    def video_stream_segment(self,\n",
    "                            frame_org,\n",
    "                            frame_id,\n",
    "                            prev_gray,\n",
    "                            prev_cfd,\n",
    "                            use_gpu=False):\n",
    "    ```\n",
    "\n",
    "    -  预测API，用于逐帧对视频人像分割。\n",
    "\n",
    "    - **参数**\n",
    "\n",
    "        * frame_org (numpy.ndarray): 单帧图片数据，ndarray.shape 为 \\[H, W, C\\]，BGR格式；\n",
    "        * frame_id (int): 当前帧的编号；\n",
    "        * prev_gray (numpy.ndarray): 前一帧输入网络图像的灰度图；\n",
    "        * prev_cfd (numpy.ndarray): 前一帧光流追踪图和预测结果融合图\n",
    "        * use\\_gpu (bool): 是否使用 GPU预测，如果使用GPU预测，则在预测之前，请设置CUDA_VISIBLE_DEVICES环境变量，否则不用设置；\n",
    "\n",
    "    -  **返回**\n",
    "\n",
    "        * img_matting (numpy.ndarray): 人像分割结果，仅包含Alpha通道，取值为0-1 (0为全透明，1为不透明)。\n",
    "        * cur_gray (numpy.ndarray): 当前帧输入网络图像的灰度图；\n",
    "        * optflow_map (numpy.ndarray): 当前帧光流追踪图和预测结果融合图\n",
    "\n",
    "    ```python\n",
    "    def video_segment(self,\n",
    "                      video_path=None,\n",
    "                      use_gpu=False,\n",
    "                      save_dir='humanseg_lite_video_result'):\n",
    "    ```\n",
    "\n",
    "    -  预测API，用于视频人像分割。\n",
    "\n",
    "    - **参数**\n",
    "\n",
    "        * video\\_path (str): 待分割视频路径。若为None，则从本地摄像头获取视频，并弹出窗口显示在线分割结果。\n",
    "        * use\\_gpu (bool): 是否使用 GPU预测，如果使用GPU预测，则在预测之前，请设置CUDA_VISIBLE_DEVICES环境变量，否则不用设置；\n",
    "        * save\\_dir (str): 视频保存路径，仅在video\\_path不为None时启用，保存离线视频处理结果。\n",
    "\n",
    "    ```python\n",
    "    def save_inference_model(dirname)\n",
    "    ```\n",
    "\n",
    "    -  将模型保存到指定路径。\n",
    "\n",
    "    - **参数**\n",
    "        * dirname: 模型保存路径"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f03add",
   "metadata": {
    "id": "四-服务部署"
   },
   "source": [
    "## 四、服务部署\n",
    "\n",
    "- PaddleHub Serving可以部署一个人像分割的在线服务。\n",
    "\n",
    "- ### 第一步：启动PaddleHub Serving\n",
    "\n",
    "    - 运行启动命令：\n",
    "\n",
    "    ```shell\n",
    "    $ hub serving start -m humanseg_lite\n",
    "    ```\n",
    "\n",
    "    - 这样就完成了一个人像分割的服务化API的部署，默认端口号为8866。\n",
    "\n",
    "    - **NOTE:** 如使用GPU预测，则需要在启动服务之前，设置CUDA_VISIBLE_DEVICES环境变量，否则不用设置。\n",
    "\n",
    "- ### 第二步：发送预测请求\n",
    "\n",
    "    - 配置好服务端，以下数行代码即可实现发送预测请求，获取预测结果\n",
    "\n",
    "        ```python\n",
    "        import requests\n",
    "        import json\n",
    "        import base64\n",
    "\n",
    "        import cv2\n",
    "        import numpy as np\n",
    "\n",
    "        def cv2_to_base64(image):\n",
    "            data = cv2.imencode('.jpg', image)[1]\n",
    "            return base64.b64encode(data.tostring()).decode('utf8')\n",
    "        def base64_to_cv2(b64str):\n",
    "            data = base64.b64decode(b64str.encode('utf8'))\n",
    "            data = np.fromstring(data, np.uint8)\n",
    "            data = cv2.imdecode(data, cv2.IMREAD_COLOR)\n",
    "            return data\n",
    "\n",
    "        # 发送HTTP请求\n",
    "        org_im = cv2.imread('/PATH/TO/IMAGE')\n",
    "        data = {'images':[cv2_to_base64(org_im)]}\n",
    "        headers = {\"Content-type\": \"application/json\"}\n",
    "        url = \"http://127.0.0.1:8866/predict/humanseg_lite\"\n",
    "        r = requests.post(url=url, headers=headers, data=json.dumps(data))\n",
    "\n",
    "        # 保存图片\n",
    "        mask =cv2.cvtColor(base64_to_cv2(r.json()[\"results\"][0]['data']), cv2.COLOR_BGR2GRAY)\n",
    "        rgba = np.concatenate((org_im, np.expand_dims(mask, axis=2)), axis=2)\n",
    "        cv2.imwrite(\"segment_human_lite.png\", rgba)\n",
    "        ```\n",
    "\n",
    "- ### Gradio APP 支持\n",
    "\n",
    "    从 PaddleHub 2.3.1 开始支持使用链接 http://127.0.0.1:8866/gradio/humanseg_lite 在浏览器中访问 humanseg_lite 的 Gradio APP。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5d0c53",
   "metadata": {
    "id": "五-更新历史"
   },
   "source": [
    "## 五、更新历史\n",
    "\n",
    "* 1.0.0\n",
    "\n",
    "    初始发布\n",
    "\n",
    "* 1.1.0\n",
    "\n",
    "    新增视频人像分割接口\n",
    "\n",
    "    新增视频流人像分割接口\n",
    "\n",
    "* 1.1.1\n",
    "\n",
    "   修复cudnn为8.0.4显存泄露问题\n",
    "\n",
    "* 1.2.0\n",
    "\n",
    "    移除 Fluid API\n",
    "\n",
    "* 1.3.0\n",
    "\n",
    "    添加 Gradio APP 支持\n",
    "\n",
    "    ```shell\n",
    "    $ hub install humanseg_lite == 1.3.0\n",
    "    ```"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "humanseg_lite",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "python3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
