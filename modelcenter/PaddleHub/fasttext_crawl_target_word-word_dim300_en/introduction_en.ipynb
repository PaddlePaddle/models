{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a723d68",
   "metadata": {
    "id": "fasttext_crawl_target_word-word_dim300_en"
   },
   "source": [
    "# fasttext_crawl_target_word-word_dim300_en\n",
    "\n",
    "|Module Name|fasttext_crawl_target_word-word_dim300_en|\n",
    "| :--- | :---: |\n",
    "|Category|Word Embedding|\n",
    "|Network|fasttext|\n",
    "|Dataset|crawl|\n",
    "|Fine-tuning supported|No|\n",
    "|Module Size|1.19GB|\n",
    "|Vocab Size|2,000,002|\n",
    "|Last update date|26 Feb, 2021|\n",
    "|Data Indicators|-|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeee74a8",
   "metadata": {
    "id": "i-basic-information"
   },
   "source": [
    "## I. Basic Information\n",
    "\n",
    "- ### Module Introduction\n",
    "\n",
    "    - PaddleHub provides several open source pretrained word embedding models. These embedding models are distinguished by the corpus, training methods and word embedding dimensions. For more informations, please refer to: [Summary of embedding models](https://github.com/PaddlePaddle/models/blob/release/2.0-beta/PaddleNLP/docs/embeddings.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ee0c1b",
   "metadata": {
    "id": "ii-installation"
   },
   "source": [
    "## II. Installation\n",
    "\n",
    "- ### 1. Environmental Dependence\n",
    "\n",
    "  - paddlepaddle >= 2.0.0\n",
    "\n",
    "  - paddlehub >= 2.0.0    | [PaddleHub Installation Guide](../../../../docs/docs_ch/get_start/installation_en.rst)\n",
    "\n",
    "- ### 2. Installation\n",
    "\n",
    "  - ```shell\n",
    "    $ hub install fasttext_crawl_target_word-word_dim300_en\n",
    "    ```\n",
    "\n",
    "  - In case of any problems during installation, please refer to: [Windows_Quickstart](../../../../docs/docs_ch/get_start/windows_quickstart_en.md) | [Linux_Quickstart](../../../../docs/docs_ch/get_start/linux_quickstart_en.md) | [Mac_Quickstart](../../../../docs/docs_ch/get_start/mac_quickstart_en.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e37c16f",
   "metadata": {
    "id": "iii-module-api-prediction"
   },
   "source": [
    "## III. Module API Prediction\n",
    "\n",
    "- ### 1. Prediction Code Example\n",
    "\n",
    "  - ```\n",
    "    import paddlehub as hub\n",
    "    embedding = hub.Module(name='fasttext_crawl_target_word-word_dim300_en')\n",
    "\n",
    "    # Get the embedding of the word\n",
    "    embedding.search(\"中国\")\n",
    "    # Calculate the cosine similarity of two word vectors\n",
    "    embedding.cosine_sim(\"中国\", \"美国\")\n",
    "    # Calculate the inner product of two word vectors\n",
    "    embedding.dot(\"中国\", \"美国\")\n",
    "    ```\n",
    "\n",
    "- ### 2、API\n",
    "\n",
    "  - ```python\n",
    "    def __init__(\n",
    "        *args,\n",
    "        **kwargs\n",
    "    )\n",
    "    ```\n",
    "\n",
    "    - Construct an embedding module object without parameters by default.\n",
    "\n",
    "    - **Parameters**\n",
    "      - `*args`： Arguments specified by the user.\n",
    "      - `**kwargs`：Keyword arguments specified by the user.\n",
    "\n",
    "    - More info[paddlenlp.embeddings](https://github.com/PaddlePaddle/models/tree/release/2.0-beta/PaddleNLP/paddlenlp/embeddings)\n",
    "\n",
    "  - ```python\n",
    "    def search(\n",
    "        words: Union[List[str], str, int],\n",
    "    )\n",
    "    ```\n",
    "\n",
    "    - Return the embedding of one or multiple words. The input data type can be `str`, `List[str]` and `int`, represent word, multiple words and the embedding of specified word id accordingly. Word id is related to the model vocab, vocab can be obtained by the attribute of `vocab`.\n",
    "\n",
    "    - **参数**\n",
    "      - `words`： input words or word id.\n",
    "\n",
    "  - ```python\n",
    "    def cosine_sim(\n",
    "        word_a: str,\n",
    "        word_b: str,\n",
    "    )\n",
    "    ```\n",
    "\n",
    "    - Cosine similarity calculation. `word_a` and `word_b` should be in the voacb, or they will be replaced by `unknown_token`.\n",
    "\n",
    "    - **参数**\n",
    "      - `word_a`： input word a.\n",
    "      - `word_b`： input word b.\n",
    "\n",
    "  - ```python\n",
    "    def dot(\n",
    "        word_a: str,\n",
    "        word_b: str,\n",
    "    )\n",
    "    ```\n",
    "\n",
    "    - Inner product calculation. `word_a` and `word_b` should be in the voacb, or they will be replaced by `unknown_token`.\n",
    "\n",
    "    - **参数**\n",
    "      - `word_a`： input word a.\n",
    "      - `word_b`： input word b.\n",
    "\n",
    "  - ```python\n",
    "    def get_vocab_path()\n",
    "    ```\n",
    "\n",
    "    - Get the path of the local vocab file.\n",
    "\n",
    "  - ```python\n",
    "    def get_tokenizer(*args, **kwargs)\n",
    "    ```\n",
    "\n",
    "    - Get the tokenizer of current model, it will return an instance of JiebaTokenizer, only supports the chinese embedding models currently.\n",
    "\n",
    "    - **参数**\n",
    "      - `*args`: Arguments specified by the user.\n",
    "      - `**kwargs`: Keyword arguments specified by the user.\n",
    "\n",
    "    - For more information about the arguments, please refer to[paddlenlp.data.tokenizer.JiebaTokenizer](https://github.com/PaddlePaddle/models/blob/release/2.0-beta/PaddleNLP/paddlenlp/data/tokenizer.py)\n",
    "\n",
    "  - For more information about the usage, please refer to[paddlenlp.embeddings](https://github.com/PaddlePaddle/models/tree/release/2.0-beta/PaddleNLP/paddlenlp/embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e6ba3f",
   "metadata": {
    "id": "iv-server-deployment"
   },
   "source": [
    "## IV. Server Deployment\n",
    "\n",
    "- PaddleHub Serving can deploy an online service of cosine similarity calculation.\n",
    "\n",
    "- ### Step 1: Start PaddleHub Serving\n",
    "\n",
    "  - Run the startup command:\n",
    "\n",
    "  - ```shell\n",
    "    $ hub serving start -m fasttext_crawl_target_word-word_dim300_en\n",
    "    ```\n",
    "\n",
    "  - The servitization API is now deployed and the default port number is 8866.\n",
    "\n",
    "  - **NOTE:** If GPU is used for prediction, set `CUDA_VISIBLE_DEVICES` environment variable before the service, otherwise it need not be set.\n",
    "\n",
    "- ### Step 2: Send a predictive request\n",
    "\n",
    "  - With a configured server, use the following lines of code to send the prediction request and obtain the result\n",
    "\n",
    "  - ```python\n",
    "    import requests\n",
    "    import json\n",
    "\n",
    "    # Specify the word pairs used to calculate the cosine similarity [[word_a, word_b], [word_a, word_b], ... ]]\n",
    "    word_pairs = [[\"中国\", \"美国\"], [\"今天\", \"明天\"]]\n",
    "    data = {\"data\": word_pairs}\n",
    "    # Send an HTTP request\n",
    "    url = \"http://127.0.0.1:8866/predict/fasttext_crawl_target_word-word_dim300_en\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "    r = requests.post(url=url, headers=headers, data=json.dumps(data))\n",
    "    print(r.json())\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c409ad6",
   "metadata": {
    "id": "v-release-note"
   },
   "source": [
    "## V. Release Note\n",
    "\n",
    "* 1.0.0\n",
    "\n",
    "  First release\n",
    "\n",
    "* 1.0.1\n",
    "\n",
    "  Model optimization\n",
    "  - ```shell\n",
    "    $ hub install fasttext_crawl_target_word-word_dim300_en==1.0.1\n",
    "    ```"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "fasttext_crawl_target_word-word_dim300_en",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "python3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
