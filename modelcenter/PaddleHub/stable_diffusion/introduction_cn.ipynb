{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f934ea04",
   "metadata": {
    "id": "stable_diffusion"
   },
   "source": [
    "# stable_diffusion\n",
    "\n",
    "|模型名称|stable_diffusion|\n",
    "| :--- | :---: |\n",
    "|类别|多模态-文图生成|\n",
    "|网络|CLIP Text Encoder+UNet+VAD|\n",
    "|数据集|-|\n",
    "|是否支持Fine-tuning|否|\n",
    "|模型大小|4.0GB|\n",
    "|最新更新日期|2022-08-26|\n",
    "|数据指标|-|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079ea848",
   "metadata": {
    "id": "一-模型基本信息"
   },
   "source": [
    "## 一、模型基本信息"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421f1148",
   "metadata": {
    "id": "应用效果展示"
   },
   "source": [
    "### 应用效果展示\n",
    "\n",
    "  - 输入文本 \"in the morning light,Overlooking TOKYO city by greg rutkowski and thomas kinkade,Trending on artstation.\"\n",
    "\n",
    "  - 输出图像\n",
    "  <p align=\"center\">\n",
    "    <img src=\"https://user-images.githubusercontent.com/22424850/186873437-2e426acd-7656-4d37-9ee4-8cafa48f097f.png\" width=\"80%\" hspace=\"10\"/>\n",
    "  <br/>\n",
    "\n",
    "  - 生成过程\n",
    "  </p><p align=\"center\">\n",
    "    <img src=\"https://user-images.githubusercontent.com/22424850/186873216-d2a9761a-78b0-4f6a-97ec-919768f324f5.gif\" width=\"80%\" hspace=\"10\"/>\n",
    "  <br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a746b62",
   "metadata": {
    "id": "模型介绍"
   },
   "source": [
    "### 模型介绍\n",
    "\n",
    "Stable Diffusion是一种潜在扩散模型(Latent Diffusion)， 属于生成类模型，这类模型通过对随机噪声进行一步步地迭代降噪并采样来获得感兴趣的图像，当前取得了令人惊艳的效果。相比于Disco Diffusion, Stable Diffusion通过在低纬度的潜在空间（lower dimensional latent space）而不是原像素空间来做迭代，极大地降低了内存和计算量的需求，并且在V100上一分钟之内即可以渲染出想要的图像，欢迎体验。\n",
    "\n",
    "更多详情请参考论文：[High-Resolution Image Synthesis with Latent Diffusion Models](https://arxiv.org/abs/2112.10752)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022e9746",
   "metadata": {
    "id": "二-安装"
   },
   "source": [
    "## 二、安装\n",
    "\n",
    "- ### 1、环境依赖\n",
    "\n",
    "  - paddlepaddle >= 2.0.0\n",
    "\n",
    "  - paddlehub >= 2.0.0    | [如何安装PaddleHub](../../../../docs/docs_ch/get_start/installation.rst)\n",
    "\n",
    "- ### 2、安装\n",
    "\n",
    "  - ```shell\n",
    "    $ hub install stable_diffusion\n",
    "    ```\n",
    "  - 如您安装时遇到问题，可参考：[零基础windows安装](../../../../docs/docs_ch/get_start/windows_quickstart.md)\n",
    " | [零基础Linux安装](../../../../docs/docs_ch/get_start/linux_quickstart.md) | [零基础MacOS安装](../../../../docs/docs_ch/get_start/mac_quickstart.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6611b07",
   "metadata": {
    "id": "三-模型api预测"
   },
   "source": [
    "## 三、模型API预测\n",
    "\n",
    "- ### 1、命令行预测\n",
    "\n",
    "  - ```shell\n",
    "    $ hub run stable_diffusion --text_prompts \"in the morning light,Overlooking TOKYO city by greg rutkowski and thomas kinkade,Trending on artstation.\" --output_dir stable_diffusion_out\n",
    "    ```\n",
    "\n",
    "- ### 2、预测代码示例\n",
    "\n",
    "  - ```python\n",
    "    import paddlehub as hub\n",
    "\n",
    "    module = hub.Module(name=\"stable_diffusion\")\n",
    "    text_prompts = [\"in the morning light,Overlooking TOKYO city by greg rutkowski and thomas kinkade,Trending on artstation.\"]\n",
    "    # 生成图像, 默认会在stable_diffusion_out目录保存图像\n",
    "    # 返回的da是一个DocumentArray对象，保存了所有的结果，包括最终结果和迭代过程的中间结果\n",
    "    # 可以通过操作DocumentArray对象对生成的图像做后处理，保存或者分析\n",
    "    # 您可以设置batch_size一次生成多张\n",
    "    da = module.generate_image(text_prompts=text_prompts, batch_size=3, output_dir='./stable_diffusion_out/')\n",
    "    # 展示所有的中间结果\n",
    "    da[0].chunks[-1].chunks.plot_image_sprites(skip_empty=True, show_index=True, keep_aspect_ratio=True)\n",
    "    # 将整个生成过程保存为一个动态图gif\n",
    "    da[0].chunks[-1].chunks.save_gif('stable_diffusion_out-merged-result.gif')\n",
    "    # da索引的是prompt, da[0].chunks索引的是该prompt下生成的第一张图，在batch_size不为1时能同时生成多张图\n",
    "    # 您也可以按照上述操作显示单张图，如第0张的生成过程\n",
    "    da[0].chunks[0].chunks.plot_image_sprites(skip_empty=True, show_index=True, keep_aspect_ratio=True)\n",
    "    da[0].chunks[0].chunks.save_gif('stable_diffusion_out-image-0-result.gif')\n",
    "    ```\n",
    "\n",
    "- ### 3、API\n",
    "\n",
    "  - ```python\n",
    "    def generate_image(\n",
    "            text_prompts,\n",
    "            style: Optional[str] = None,\n",
    "            artist: Optional[str] = None,\n",
    "            width_height: Optional[List[int]] = [512, 512],\n",
    "            seed: Optional[int] = None,\n",
    "            batch_size: Optional[int] = 1,\n",
    "            output_dir: Optional[str] = 'stable_diffusion_out'):\n",
    "    ```\n",
    "\n",
    "    - 文图生成API，生成文本描述内容的图像。\n",
    "\n",
    "    - **参数**\n",
    "\n",
    "      - text_prompts(str): 输入的语句，描述想要生成的图像的内容。通常比较有效的构造方式为 \"一段描述性的文字内容\" + \"指定艺术家的名字\"，如\"in the morning light,Overlooking TOKYO city by greg rutkowski and thomas kinkade,Trending on artstation.\"。prompt的构造可以参考[网站](https://docs.google.com/document/d/1XUT2G9LmkZataHFzmuOtRXnuWBfhvXDAo8DkS--8tec/edit#)。\n",
    "      - style(Optional[str]): 指定绘画的风格，如'watercolor','Chinese painting'等。当不指定时，风格完全由您所填写的prompt决定。\n",
    "      - artist(Optional[str]): 指定特定的艺术家，如Greg Rutkowsk、krenz，将会生成所指定艺术家的绘画风格。当不指定时，风格完全由您所填写的prompt决定。各种艺术家的风格可以参考[网站](https://weirdwonderfulai.art/resources/disco-diffusion-70-plus-artist-studies/)。\n",
    "      - width_height(Optional[List[int]]): 指定最终输出图像的宽高，宽和高都需要是64的倍数，生成的图像越大，所需要的计算时间越长。\n",
    "      - seed(Optional[int]): 随机种子，由于输入默认是随机高斯噪声，设置不同的随机种子会由不同的初始输入，从而最终生成不同的结果，可以设置该参数来获得不同的输出图像。\n",
    "      - batch_size(Optional[int]): 指定每个prompt一次生成的图像的数量。\n",
    "      - output_dir(Optional[str]): 保存输出图像的目录，默认为\"stable_diffusion_out\"。\n",
    "\n",
    "    - **返回**\n",
    "      - ra(DocumentArray): DocumentArray对象， 包含`batch_size`个Documents，其中每个Document都保存了迭代过程的所有中间结果。详细可参考[DocumentArray使用文档](https://docarray.jina.ai/fundamentals/documentarray/index.html)。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab8c190",
   "metadata": {
    "id": "四-服务部署"
   },
   "source": [
    "## 四、服务部署\n",
    "\n",
    "- PaddleHub Serving可以部署一个在线文图生成服务。\n",
    "\n",
    "- ### 第一步：启动PaddleHub Serving\n",
    "\n",
    "  - 运行启动命令：\n",
    "  - ```shell\n",
    "    $ hub serving start -m stable_diffusion\n",
    "    ```\n",
    "\n",
    "  - 这样就完成了一个文图生成的在线服务API的部署，默认端口号为8866。\n",
    "\n",
    "  - **NOTE:** 如使用GPU预测，则需要在启动服务之前，请设置CUDA\\_VISIBLE\\_DEVICES环境变量，否则不用设置。\n",
    "\n",
    "- ### 第二步：发送预测请求\n",
    "\n",
    "  - 配置好服务端，以下数行代码即可实现发送预测请求，获取预测结果，返回的预测结果在反序列化后即是上述接口声明中说明的DocumentArray类型，返回后对结果的操作方式和使用generate_image接口完全相同。\n",
    "\n",
    "  - ```python\n",
    "    import requests\n",
    "    import json\n",
    "    import cv2\n",
    "    import base64\n",
    "    from docarray import DocumentArray\n",
    "\n",
    "    # 发送HTTP请求\n",
    "    data = {'text_prompts': 'in the morning light,Overlooking TOKYO city by greg rutkowski and thomas kinkade,Trending on artstation.'}\n",
    "    headers = {\"Content-type\": \"application/json\"}\n",
    "    url = \"http://127.0.0.1:8866/predict/stable_diffusion\"\n",
    "    r = requests.post(url=url, headers=headers, data=json.dumps(data))\n",
    "\n",
    "    # 获取返回结果\n",
    "    r.json()[\"results\"]\n",
    "    da = DocumentArray.from_base64(r.json()[\"results\"])\n",
    "    # 保存结果图\n",
    "    da[0].save_uri_to_file('stable_diffusion_out.png')\n",
    "    # 将生成过程保存为一个动态图gif\n",
    "    da[0].chunks[0].chunks.save_gif('stable_diffusion_out.gif')\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22842b0",
   "metadata": {
    "id": "五-更新历史"
   },
   "source": [
    "## 五、更新历史\n",
    "\n",
    "* 1.0.0\n",
    "\n",
    "  初始发布\n",
    "\n",
    "  ```shell\n",
    "  $ hub install stable_diffusion == 1.0.0\n",
    "  ```</p>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "stable_diffusion",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "python3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
