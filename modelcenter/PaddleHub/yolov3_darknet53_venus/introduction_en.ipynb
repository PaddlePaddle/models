{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2076b4a",
   "metadata": {
    "id": "yolov3_darknet53_venus"
   },
   "source": [
    "# yolov3_darknet53_venus\n",
    "\n",
    "|Module Name|yolov3_darknet53_venus|\n",
    "| :--- | :---: |\n",
    "|Category|object detection|\n",
    "|Network|YOLOv3|\n",
    "|Dataset|Baidu Detection Dataset|\n",
    "|Fine-tuning supported or not|Yes|\n",
    "|Module Size|501MB|\n",
    "|Latest update date|2021-02-26|\n",
    "|Data indicators|-|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50973add",
   "metadata": {
    "id": "i-basic-information"
   },
   "source": [
    "## I.Basic Information\n",
    "\n",
    "- ### Module Introduction\n",
    "\n",
    "  - YOLOv3 is a one-stage detector proposed by Joseph Redmon and Ali Farhadi, which can reach comparable accuracy but twice as fast as traditional methods. This module is based on YOLOv3, trained on Baidu Vehicle Dataset which consists of 170w pictures and 1000w+ boxes, improve the accuracy on 8 test datasets for average 5.36%, and can be used for vehicle detection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9037d7",
   "metadata": {
    "id": "ii-installation"
   },
   "source": [
    "## II.Installation\n",
    "\n",
    "- ### 1、Environmental Dependence\n",
    "\n",
    "  - paddlepaddle >= 1.6.2\n",
    "\n",
    "  - paddlehub >= 1.6.0  | [How to install PaddleHub](../../../../docs/docs_en/get_start/installation.rst)\n",
    "\n",
    "- ### 2、Installation\n",
    "\n",
    "  - ```shell\n",
    "    $ hub install yolov3_darknet53_venus\n",
    "    ```\n",
    "  - In case of any problems during installation, please refer to: [Windows_Quickstart](../../../../docs/docs_en/get_start/windows_quickstart.md) | [Linux_Quickstart](../../../../docs/docs_en/get_start/linux_quickstart.md) | [Mac_Quickstart](../../../../docs/docs_en/get_start/mac_quickstart.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe6e157",
   "metadata": {
    "id": "iii-module-api-prediction"
   },
   "source": [
    "## III.Module API Prediction\n",
    "\n",
    "- ### 1、API\n",
    "\n",
    "  - ```python\n",
    "    def context(trainable=True,\n",
    "                pretrained=True,\n",
    "                get_prediction=False)\n",
    "    ```\n",
    "\n",
    "    - Extract features, and do transfer learning\n",
    "\n",
    "    - **Parameters**\n",
    "\n",
    "      - trainable(bool): whether parameters trainable or not\n",
    "      - pretrained (bool): whether load pretrained model or not\n",
    "      - get\\_prediction (bool): whether perform prediction\n",
    "\n",
    "    - **Return**\n",
    "      - inputs (dict): inputs, a dict, include two keys: \"image\" and \"im\\_size\"\n",
    "        - image (Variable): image variable\n",
    "        - im\\_size (Variable): image size\n",
    "      - outputs (dict): model output\n",
    "      - program for transfer learning\n",
    "\n",
    "  - ```python\n",
    "    def object_detection(paths=None,\n",
    "                         images=None,\n",
    "                         batch_size=1,\n",
    "                         use_gpu=False,\n",
    "                         score_thresh=0.5,\n",
    "                         visualization=True,\n",
    "                         output_dir='detection_result')\n",
    "    ```\n",
    "\n",
    "    - Detection API, detect positions of all objects in image\n",
    "\n",
    "    - **Parameters**\n",
    "\n",
    "      - paths (list[str]): image path;\n",
    "      - images (list\\[numpy.ndarray\\]): image data, ndarray.shape is in the format [H, W, C], BGR;\n",
    "      - batch_size (int): the size of batch;\n",
    "      - use_gpu (bool): use GPU or not; **set the CUDA_VISIBLE_DEVICES environment variable first if you are using GPU**\n",
    "      - score\\_thresh (float): confidence threshold；<br/>\n",
    "      - visualization (bool): Whether to save the results as picture files;\n",
    "      - output_dir (str): save path of images;\n",
    "\n",
    "    - **Return**\n",
    "\n",
    "      - res (list\\[dict\\]): classication results, each element in the list is dict, key is the label name, and value is the corresponding probability\n",
    "        - data (list): detection results, each element in the list is dict\n",
    "          - confidence (float): the confidence of the result\n",
    "          - label (str): label\n",
    "          - left (int): the upper left corner x coordinate of the detection box\n",
    "          - top (int): the upper left corner y coordinate of the detection box\n",
    "          - right (int): the lower right corner x coordinate of the detection box\n",
    "          - bottom (int): the lower right corner y coordinate of the detection box\n",
    "        - save\\_path (str, optional): output path for saving results\n",
    "\n",
    "  - ```python\n",
    "    def save_inference_model(dirname,\n",
    "                             model_filename=None,\n",
    "                             params_filename=None,\n",
    "                             combined=True)\n",
    "    ```\n",
    "    - Save model to specific path\n",
    "\n",
    "    - **Parameters**\n",
    "\n",
    "      - dirname: output dir for saving model\n",
    "      - model\\_filename: filename for saving model\n",
    "      - params\\_filename: filename for saving parameters\n",
    "      - combined: whether save parameters into one file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d03353e",
   "metadata": {
    "id": "iv-release-note"
   },
   "source": [
    "## IV.Release Note\n",
    "\n",
    "* 1.0.0\n",
    "\n",
    "  First release\n",
    "  - ```shell\n",
    "    $ hub install yolov3_darknet53_venus==1.0.0\n",
    "    ```"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "yolov3_darknet53_venus",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "python3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
