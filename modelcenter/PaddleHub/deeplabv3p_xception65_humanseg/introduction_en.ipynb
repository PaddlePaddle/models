{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "416044fd",
   "metadata": {
    "id": "deeplabv3p_xception65_humanseg"
   },
   "source": [
    "# deeplabv3p_xception65_humanseg\n",
    "\n",
    "|Module Name |deeplabv3p_xception65_humanseg|\n",
    "| :--- | :---: |\n",
    "|Category|Image segmentation|\n",
    "|Network|deeplabv3p|\n",
    "|Dataset|Baidu self-built dataset|\n",
    "|Fine-tuning supported or not|No|\n",
    "|Module Size|162MB|\n",
    "|Data indicators |-|\n",
    "|Latest update date|2021-02-26|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58dd86a7",
   "metadata": {
    "id": "i-basic-information"
   },
   "source": [
    "## I. Basic Information\n",
    "\n",
    "- ### Application Effect Display\n",
    "\n",
    "  - Sample results:\n",
    "    <p align=\"center\">\n",
    "    <img src=\"https://user-images.githubusercontent.com/35907364/130913092-312a5f37-842e-4fd0-8db4-5f853fd8419f.jpg\" width=\"337\" height=\"505\" hspace=\"10\"/> <img src=\"https://user-images.githubusercontent.com/35907364/130913256-41056b21-1c3d-4ee2-b481-969c94754609.png\" width=\"337\" height=\"505\" hspace=\"10\"/>\n",
    "    </p>\n",
    "\n",
    "- ### Module Introduction\n",
    "\n",
    "  - DeepLabv3+ model is trained by Baidu self-built dataset, which can be used for portrait segmentation.\n",
    "<p align=\"center\">\n",
    "<img src=\"https://paddlehub.bj.bcebos.com/paddlehub-img/deeplabv3plus.png\" hspace=\"10\"/> <br/>\n",
    "</p>\n",
    "\n",
    "- For more information, please refer to: [deeplabv3p](https://github.com/PaddlePaddle/PaddleSeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c14ef26",
   "metadata": {
    "id": "ii-installation"
   },
   "source": [
    "## II. Installation\n",
    "\n",
    "- ### 1、Environmental Dependence\n",
    "\n",
    "  - paddlepaddle >= 2.0.0\n",
    "\n",
    "  - paddlehub >= 2.0.0\n",
    "\n",
    "- ### 2、Installation\n",
    "\n",
    "    - ```shell\n",
    "      $ hub install deeplabv3p_xception65_humanseg\n",
    "      ```\n",
    "    - In case of any problems during installation, please refer to:[Windows_Quickstart](../../../../docs/docs_en/get_start/windows_quickstart.md)\n",
    "    | [Linux_Quickstart](../../../../docs/docs_en/get_start/linux_quickstart.md) | [Mac_Quickstart](../../../../docs/docs_en/get_start/mac_quickstart.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73945fa",
   "metadata": {
    "id": "iii-module-api-prediction"
   },
   "source": [
    "## III. Module API Prediction\n",
    "\n",
    "- ### 1、Command line Prediction\n",
    "\n",
    "  - ```shell\n",
    "    hub run deeplabv3p_xception65_humanseg --input_path \"/PATH/TO/IMAGE\"\n",
    "    ```\n",
    "  - If you want to call the Hub module through the command line, please refer to: [PaddleHub Command Line Instruction](../../../../docs/docs_en/tutorial/cmd_usage.rst)\n",
    "\n",
    "- ### 2、Prediction Code Example\n",
    "\n",
    "  - ```python\n",
    "    import paddlehub as hub\n",
    "    import cv2\n",
    "\n",
    "    human_seg = hub.Module(name=\"deeplabv3p_xception65_humanseg\")\n",
    "    result = human_seg.segmentation(images=[cv2.imread('/PATH/TO/IMAGE')])\n",
    "    ```\n",
    "\n",
    "- ### 3.API\n",
    "\n",
    "    - ```python\n",
    "      def segmentation(images=None,\n",
    "                       paths=None,\n",
    "                       batch_size=1,\n",
    "                       use_gpu=False,\n",
    "                       visualization=False,\n",
    "                       output_dir='humanseg_output')\n",
    "      ```\n",
    "\n",
    "      - Prediction API, generating segmentation result.\n",
    "\n",
    "      - **Parameter**\n",
    "        * images (list\\[numpy.ndarray\\]): Image data, ndarray.shape is in the format [H, W, C], BGR.\n",
    "        * paths (list\\[str\\]): Image path.\n",
    "        * batch\\_size (int): Batch size.\n",
    "        * use\\_gpu (bool): Use GPU or not. **set the CUDA_VISIBLE_DEVICES environment variable first if you are using GPU**\n",
    "        * visualization (bool): Whether to save the recognition results as picture files.\n",
    "        * output\\_dir (str): Save path of images.\n",
    "\n",
    "      - **Return**\n",
    "\n",
    "          * res (list\\[dict\\]): The list of recognition results, where each element is dict and each field is:\n",
    "              * save\\_path (str, optional): Save path of the result.\n",
    "              * data (numpy.ndarray): The result of portrait segmentation.\n",
    "\n",
    "    - ```python\n",
    "      def save_inference_model(dirname)\n",
    "      ```\n",
    "\n",
    "      - Save the model to the specified path.\n",
    "\n",
    "      - **Parameters**\n",
    "        * dirname: Model save path."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc23bd6b",
   "metadata": {
    "id": "iv-server-deployment"
   },
   "source": [
    "## IV. Server Deployment\n",
    "\n",
    "- PaddleHub Serving can deploy an online service of for human segmentation.\n",
    "\n",
    "- ### Step 1: Start PaddleHub Serving\n",
    "\n",
    "    - Run the startup command:\n",
    "\n",
    "      - ```shell\n",
    "        $ hub serving start -m deeplabv3p_xception65_humanseg\n",
    "        ```\n",
    "\n",
    "    - **NOTE:**  If GPU is used for prediction, set CUDA_VISIBLE_DEVICES environment variable before the service, otherwise it need not be set.\n",
    "\n",
    "- ### Step 2: Send a predictive request\n",
    "\n",
    "  - With a configured server, use the following lines of code to send the prediction request and obtain the result\n",
    "\n",
    "  - ```python\n",
    "    import requests\n",
    "    import json\n",
    "    import cv2\n",
    "    import base64\n",
    "    import numpy as np\n",
    "\n",
    "    def cv2_to_base64(image):\n",
    "        data = cv2.imencode('.jpg', image)[1]\n",
    "        return base64.b64encode(data.tostring()).decode('utf8')\n",
    "\n",
    "    def base64_to_cv2(b64str):\n",
    "        data = base64.b64decode(b64str.encode('utf8'))\n",
    "        data = np.fromstring(data, np.uint8)\n",
    "        data = cv2.imdecode(data, cv2.IMREAD_COLOR)\n",
    "        return data\n",
    "\n",
    "    org_im = cv2.imread(\"/PATH/TO/IMAGE\")\n",
    "    # Send an HTTP request\n",
    "    data = {'images':[cv2_to_base64(org_im)]}\n",
    "    headers = {\"Content-type\": \"application/json\"}\n",
    "    url = \"http://127.0.0.1:8866/predict/deeplabv3p_xception65_humanseg\"\n",
    "    r = requests.post(url=url, headers=headers, data=json.dumps(data))\n",
    "    mask =cv2.cvtColor(base64_to_cv2(r.json()[\"results\"][0]['data']), cv2.COLOR_BGR2GRAY)\n",
    "    rgba = np.concatenate((org_im, np.expand_dims(mask, axis=2)), axis=2)\n",
    "    cv2.imwrite(\"segment_human_server.png\", rgba)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18416cc9",
   "metadata": {
    "id": "v-release-note"
   },
   "source": [
    "## V. Release Note\n",
    "\n",
    "- 1.0.0\n",
    "\n",
    "  First release\n",
    "\n",
    "* 1.1.0\n",
    "\n",
    "   Improve prediction performance\n",
    "\n",
    "* 1.1.1\n",
    "\n",
    "   Fix the bug of image value out of range\n",
    "\n",
    "* 1.2.0\n",
    "\n",
    "   Remove fluid api\n",
    "\n",
    "  - ```shell\n",
    "    $ hub install deeplabv3p_xception65_humanseg==1.2.0\n",
    "    ```"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "deeplabv3p_xception65_humanseg",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "python3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
