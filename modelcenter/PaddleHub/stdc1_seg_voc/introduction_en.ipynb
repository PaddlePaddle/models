{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c46e7e2",
   "metadata": {
    "id": "stdc1_seg_voc"
   },
   "source": [
    "# stdc1_seg_voc\n",
    "\n",
    "|Module Name|stdc1_seg_voc|\n",
    "| :--- | :---: |\n",
    "|Category|Image Segmentation|\n",
    "|Network|stdc1_seg|\n",
    "|Dataset|PascalVOC2012|\n",
    "|Fine-tuning supported or not|Yes|\n",
    "|Module Size|370MB|\n",
    "|Data indicators|-|\n",
    "|Latest update date|2022-03-22|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae79e829",
   "metadata": {
    "id": "i-basic-information"
   },
   "source": [
    "## I. Basic Information\n",
    "\n",
    "- ### Application Effect Display\n",
    "    - Sample results:\n",
    "    <p align=\"center\">\n",
    "    <img src=\"https://user-images.githubusercontent.com/35907364/159212097-443a5a65-2f2e-4126-9c07-d7c3c220e55f.jpg\" width=\"420\" height=\"505\" hspace=\"10\"/> <img src=\"https://user-images.githubusercontent.com/35907364/159212375-52e123af-4699-4c25-8f50-4240bbb714b4.png\" width=\"420\" height=\"505\" hspace=\"10\"/>\n",
    "    </p>\n",
    "\n",
    "- ### Module Introduction\n",
    "\n",
    "    - We will show how to use PaddleHub to finetune the pre-trained model and complete the prediction.\n",
    "    - For more information, please refer to: [stdc](https://arxiv.org/abs/2104.13188)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f651023",
   "metadata": {
    "id": "ii-installation"
   },
   "source": [
    "## II. Installation\n",
    "\n",
    "- ### 1、Environmental Dependence\n",
    "\n",
    "    - paddlepaddle >= 2.0.0\n",
    "\n",
    "    - paddlehub >= 2.0.0\n",
    "\n",
    "- ### 2、Installation\n",
    "\n",
    "    - ```shell\n",
    "      $ hub install stdc1_seg_voc\n",
    "      ```\n",
    "\n",
    "    - In case of any problems during installation, please refer to:[Windows_Quickstart](../../../../docs/docs_en/get_start/windows_quickstart.md)\n",
    "    | [Linux_Quickstart](../../../../docs/docs_en/get_start/linux_quickstart.md) | [Mac_Quickstart](../../../../docs/docs_en/get_start/mac_quickstart.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c18784",
   "metadata": {
    "id": "iii-module-api-prediction"
   },
   "source": [
    "## III. Module API Prediction\n",
    "\n",
    "- ### 1、Prediction Code Example\n",
    "\n",
    "    - ```python\n",
    "      import cv2\n",
    "      import paddle\n",
    "      import paddlehub as hub\n",
    "\n",
    "      if __name__ == '__main__':\n",
    "          model = hub.Module(name='stdc1_seg_voc')\n",
    "          img = cv2.imread(\"/PATH/TO/IMAGE\")\n",
    "          result = model.predict(images=[img], visualization=True)\n",
    "      ```\n",
    "\n",
    "- ### 2.Fine-tune and Encapsulation\n",
    "\n",
    "    - After completing the installation of PaddlePaddle and PaddleHub, you can start using the stdc1_seg_voc model to fine-tune datasets such as OpticDiscSeg.\n",
    "\n",
    "    - Steps:\n",
    "\n",
    "         - Step1: Define the data preprocessing method\n",
    "\n",
    "            - ```python\n",
    "              from paddlehub.vision.segmentation_transforms import Compose, Resize, Normalize\n",
    "\n",
    "              transform = Compose([Resize(target_size=(512, 512)), Normalize()])\n",
    "              ```\n",
    "\n",
    "            - `segmentation_transforms`: The data enhancement module defines lots of data preprocessing methods. Users can replace the data preprocessing methods according to their needs.\n",
    "\n",
    "         - Step2: Download the dataset\n",
    "\n",
    "            - ```python\n",
    "              from paddlehub.datasets import OpticDiscSeg\n",
    "\n",
    "              train_reader = OpticDiscSeg(transform, mode='train')\n",
    "              ```\n",
    "                * `transforms`: data preprocessing methods.\n",
    "\n",
    "                * `mode`: Select the data mode, the options are `train`, `test`, `val`. Default is `train`.\n",
    "\n",
    "                * Dataset preparation can be referred to [opticdiscseg.py](../../paddlehub/datasets/opticdiscseg.py)。`hub.datasets.OpticDiscSeg()`will be automatically downloaded from the network and decompressed to the `$HOME/.paddlehub/dataset` directory under the user directory.\n",
    "\n",
    "        - Step3: Load the pre-trained model\n",
    "\n",
    "            - ```python\n",
    "              import paddlehub as hub\n",
    "\n",
    "              model = hub.Module(name='stdc1_seg_voc', num_classes=2, pretrained=None)\n",
    "              ```\n",
    "                - `name`: model name.\n",
    "                - `load_checkpoint`: Whether to load the self-trained model, if it is None, load the provided parameters.\n",
    "\n",
    "        - Step4:  Optimization strategy\n",
    "\n",
    "            - ```python\n",
    "              import paddle\n",
    "              from paddlehub.finetune.trainer import Trainer\n",
    "\n",
    "              scheduler = paddle.optimizer.lr.PolynomialDecay(learning_rate=0.01, decay_steps=1000, power=0.9,  end_lr=0.0001)\n",
    "              optimizer = paddle.optimizer.Adam(learning_rate=scheduler, parameters=model.parameters())\n",
    "              trainer = Trainer(model, optimizer, checkpoint_dir='test_ckpt_img_seg', use_gpu=True)\n",
    "              trainer.train(train_reader, epochs=10, batch_size=4, log_interval=10, save_interval=4)\n",
    "              ```\n",
    "\n",
    "    -  Model prediction\n",
    "\n",
    "        - When Fine-tune is completed, the model with the best performance on the verification set will be saved in the `${CHECKPOINT_DIR}/best_model` directory. We use this model to make predictions. The `predict.py` script is as follows:\n",
    "\n",
    "            ```python\n",
    "            import paddle\n",
    "            import cv2\n",
    "            import paddlehub as hub\n",
    "\n",
    "            if __name__ == '__main__':\n",
    "                model = hub.Module(name='stdc1_seg_voc', pretrained='/PATH/TO/CHECKPOINT')\n",
    "                img = cv2.imread(\"/PATH/TO/IMAGE\")\n",
    "                model.predict(images=[img], visualization=True)\n",
    "            ```\n",
    "\n",
    "            - **Args**\n",
    "                * `images`: Image path or ndarray data with format [H, W, C], BGR.\n",
    "                * `visualization`: Whether to save the recognition results as picture files.\n",
    "                * `save_path`: Save path of the result, default is 'seg_result'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa3d844",
   "metadata": {
    "id": "iv-server-deployment"
   },
   "source": [
    "## IV. Server Deployment\n",
    "\n",
    "- PaddleHub Serving can deploy an online service of image segmentation.\n",
    "\n",
    "- ### Step 1: Start PaddleHub Serving\n",
    "\n",
    "    - Run the startup command:\n",
    "\n",
    "        - ```shell\n",
    "          $ hub serving start -m stdc1_seg_voc\n",
    "          ```\n",
    "\n",
    "    - The servitization API is now deployed and the default port number is 8866.\n",
    "\n",
    "    - **NOTE:**  If GPU is used for prediction, set CUDA_VISIBLE_DEVICES environment variable before the service, otherwise it need not be set.\n",
    "\n",
    "- ### Step 2: Send a predictive request\n",
    "\n",
    "    - With a configured server, use the following lines of code to send the prediction request and obtain the result:\n",
    "\n",
    "        ```python\n",
    "        import requests\n",
    "        import json\n",
    "        import cv2\n",
    "        import base64\n",
    "\n",
    "        import numpy as np\n",
    "\n",
    "        def cv2_to_base64(image):\n",
    "            data = cv2.imencode('.jpg', image)[1]\n",
    "            return base64.b64encode(data.tostring()).decode('utf8')\n",
    "\n",
    "        def base64_to_cv2(b64str):\n",
    "            data = base64.b64decode(b64str.encode('utf8'))\n",
    "            data = np.fromstring(data, np.uint8)\n",
    "            data = cv2.imdecode(data, cv2.IMREAD_COLOR)\n",
    "            return data\n",
    "\n",
    "        org_im = cv2.imread('/PATH/TO/IMAGE')\n",
    "        data = {'images':[cv2_to_base64(org_im)]}\n",
    "        headers = {\"Content-type\": \"application/json\"}\n",
    "        url = \"http://127.0.0.1:8866/predict/stdc1_seg_voc\"\n",
    "        r = requests.post(url=url, headers=headers, data=json.dumps(data))\n",
    "        mask = base64_to_cv2(r.json()[\"results\"][0])\n",
    "        ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a541077",
   "metadata": {
    "id": "v-release-note"
   },
   "source": [
    "## V. Release Note\n",
    "\n",
    "- 1.0.0\n",
    "\n",
    "  First release"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "stdc1_seg_voc",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "python3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
