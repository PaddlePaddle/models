{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31ff580b",
   "metadata": {
    "id": "wav2lip"
   },
   "source": [
    "# wav2lip\n",
    "\n",
    "|模型名称|wav2lip|\n",
    "| :--- | :---: |\n",
    "|类别|图像 - 视频生成|\n",
    "|网络|Wav2Lip|\n",
    "|数据集|LRS2|\n",
    "|是否支持Fine-tuning|否|\n",
    "|模型大小|139MB|\n",
    "|最新更新日期|2021-12-14|\n",
    "|数据指标|-|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690d7dcd",
   "metadata": {
    "id": "一-模型基本信息"
   },
   "source": [
    "## 一、模型基本信息\n",
    "\n",
    "- ### 应用效果展示\n",
    "  - 样例结果示例：\n",
    "    <p align=\"center\">\n",
    "    <img src=\"https://user-images.githubusercontent.com/22424850/146481773-4ec50285-3b13-4a86-84a2-b105787b63d1.png\" width=\"40%\" hspace=\"10\"/>\n",
    "    <br/>\n",
    "    输入图像\n",
    "    <br/>\n",
    "    <img src=\"https://user-images.githubusercontent.com/22424850/146482210-5f309fc3-7582-452d-bcf5-f2c54b5c8dc8.gif\" width=\"40%\" hspace=\"10\"/>\n",
    "    <br/>\n",
    "    输出视频\n",
    "     <br/>\n",
    "    </p>\n",
    "\n",
    "- ### 模型介绍\n",
    "\n",
    "  - Wav2Lip实现的是视频人物根据输入音频生成与语音同步的人物唇形，使得生成的视频人物口型与输入语音同步。Wav2Lip不仅可以基于静态图像来输出与目标语音匹配的唇形同步视频，还可以直接将动态的视频进行唇形转换，输出与目标语音匹配的视频。Wav2Lip实现唇形与语音精准同步突破的关键在于，它采用了唇形同步判别器，以强制生成器持续产生准确而逼真的唇部运动。此外，它通过在鉴别器中使用多个连续帧而不是单个帧，并使用视觉质量损失（而不仅仅是对比损失）来考虑时间相关性，从而改善了视觉质量。Wav2Lip适用于任何人脸、任何语言，对任意视频都能达到很高都准确率，可以无缝地与原始视频融合，还可以用于转换动画人脸。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffbf2a6",
   "metadata": {
    "id": "二-安装"
   },
   "source": [
    "## 二、安装\n",
    "\n",
    "- ### 1、环境依赖\n",
    "  - ffmpeg\n",
    "  - libsndfile\n",
    "- ### 2、安装\n",
    "\n",
    "  - ```shell\n",
    "    $ hub install wav2lip\n",
    "    ```\n",
    "  - 如您安装时遇到问题，可参考：[零基础windows安装](../../../../docs/docs_ch/get_start/windows_quickstart.md)\n",
    " | [零基础Linux安装](../../../../docs/docs_ch/get_start/linux_quickstart.md) | [零基础MacOS安装](../../../../docs/docs_ch/get_start/mac_quickstart.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed24f3cd",
   "metadata": {
    "id": "三-模型api预测"
   },
   "source": [
    "## 三、模型API预测\n",
    "\n",
    "- ### 1、命令行预测\n",
    "\n",
    "  - ```shell\n",
    "    # Read from a file\n",
    "    $ hub run wav2lip --face \"/PATH/TO/VIDEO or IMAGE\" --audio \"/PATH/TO/AUDIO\"\n",
    "    ```\n",
    "  - 通过命令行方式人物唇形生成模型的调用，更多请见 [PaddleHub命令行指令](../../../../docs/docs_ch/tutorial/cmd_usage.rst)\n",
    "\n",
    "- ### 2、预测代码示例\n",
    "\n",
    "  - ```python\n",
    "    import paddlehub as hub\n",
    "\n",
    "    module = hub.Module(name=\"wav2lip\")\n",
    "    face_input_path = \"/PATH/TO/VIDEO or IMAGE\"\n",
    "    audio_input_path = \"/PATH/TO/AUDIO\"\n",
    "    module.wav2lip_transfer(face=face_input_path, audio=audio_input_path, output_dir='./transfer_result/', use_gpu=True)\n",
    "    ```\n",
    "\n",
    "- ### 3、API\n",
    "\n",
    "  - ```python\n",
    "    def wav2lip_transfer(face, audio, output_dir ='./output_result/', use_gpu=False, visualization=True):\n",
    "    ```\n",
    "    - 人脸唇形生成API。\n",
    "\n",
    "    - **参数**\n",
    "\n",
    "      - face (str): 视频或图像文件的路径<br/>\n",
    "      - audio (str): 音频文件的路径<br/>\n",
    "      - output\\_dir (str): 结果保存的路径； <br/>\n",
    "      - use\\_gpu (bool): 是否使用 GPU；<br/>\n",
    "      - visualization(bool): 是否保存结果到本地文件夹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c6e340",
   "metadata": {
    "id": "四-更新历史"
   },
   "source": [
    "## 四、更新历史\n",
    "\n",
    "* 1.0.0\n",
    "\n",
    "  初始发布\n",
    "\n",
    "  - ```shell\n",
    "    $ hub install wav2lip==1.0.0\n",
    "    ```"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "wav2lip",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "python3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
