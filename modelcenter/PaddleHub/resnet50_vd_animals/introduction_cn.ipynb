{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b40ba1d7",
   "metadata": {
    "id": "resnet50_vd_animals"
   },
   "source": [
    "# resnet50_vd_animals\n",
    "\n",
    "|模型名称|resnet50_vd_animals|\n",
    "| :--- | :---: |\n",
    "|类别|图像-图像分类|\n",
    "|网络|ResNet50_vd|\n",
    "|数据集|百度自建动物数据集|\n",
    "|是否支持Fine-tuning|否|\n",
    "|模型大小|154MB|\n",
    "|指标|-|\n",
    "|最新更新日期|2021-02-26|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3415ab",
   "metadata": {
    "id": "一-模型基本信息"
   },
   "source": [
    "## 一、模型基本信息\n",
    "\n",
    "- ### 模型介绍\n",
    "\n",
    "    - ResNet-vd 其实就是 ResNet-D，是ResNet 原始结构的变种，可用于图像分类和特征提取。该 PaddleHub Module 采用百度自建动物数据集训练得到，支持7978种动物的分类识别。\n",
    "\n",
    "    - 模型的详情可参考[论文](https://arxiv.org/pdf/1812.01187.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c44968f",
   "metadata": {
    "id": "二-安装"
   },
   "source": [
    "## 二、安装\n",
    "\n",
    "- ### 1、环境依赖\n",
    "\n",
    "    - paddlepaddle >= 2.0.0\n",
    "\n",
    "    - paddlehub >= 2.0.0\n",
    "\n",
    "- ### 2、安装\n",
    "\n",
    "    - ```shell\n",
    "      $ hub install resnet50_vd_animals\n",
    "      ```\n",
    "    - 如您安装时遇到问题，可参考：[零基础windows安装](../../../../docs/docs_ch/get_start/windows_quickstart.md)\n",
    "      | [零基础Linux安装](../../../../docs/docs_ch/get_start/linux_quickstart.md) | [零基础MacOS安装](../../../../docs/docs_ch/get_start/mac_quickstart.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2caa0b",
   "metadata": {
    "id": "三-模型api预测"
   },
   "source": [
    "## 三、模型API预测\n",
    "\n",
    "- ### 1、命令行预测\n",
    "\n",
    "    - ```\n",
    "      hub run resnet50_vd_animals --input_path \"/PATH/TO/IMAGE\"\n",
    "      ```\n",
    "\n",
    "- ### 2、预测代码示例\n",
    "\n",
    "    - ```python\n",
    "      import paddlehub as hub\n",
    "      import cv2\n",
    "\n",
    "      classifier = hub.Module(name=\"resnet50_vd_animals\")\n",
    "\n",
    "      result = classifier.classification(images=[cv2.imread('/PATH/TO/IMAGE')])\n",
    "      # or\n",
    "      # result = classifier.classification(paths=['/PATH/TO/IMAGE'])\n",
    "      ```\n",
    "- ### 3、API\n",
    "\n",
    "    - ```python\n",
    "      def get_expected_image_width()\n",
    "      ```\n",
    "\n",
    "        - 返回预处理的图片宽度，也就是224。\n",
    "\n",
    "    - ```python\n",
    "      def get_expected_image_height()\n",
    "      ```\n",
    "\n",
    "        - 返回预处理的图片高度，也就是224。\n",
    "\n",
    "    - ```python\n",
    "      def get_pretrained_images_mean()\n",
    "      ```\n",
    "\n",
    "        - 返回预处理的图片均值，也就是 \\[0.485, 0.456, 0.406\\]。\n",
    "\n",
    "    - ```python\n",
    "      def get_pretrained_images_std()\n",
    "      ```\n",
    "\n",
    "        - 返回预处理的图片标准差，也就是 \\[0.229, 0.224, 0.225\\]。\n",
    "\n",
    "    - ```python\n",
    "      def classification(images=None,\n",
    "                         paths=None,\n",
    "                         batch_size=1,\n",
    "                         use_gpu=False,\n",
    "                         top_k=1):\n",
    "      ```\n",
    "\n",
    "        - **参数**\n",
    "\n",
    "            * images (list\\[numpy.ndarray\\]): 图片数据，每一个图片数据的shape 均为 \\[H, W, C\\]，颜色空间为 BGR；\n",
    "            * paths (list\\[str\\]): 图片的路径；\n",
    "            * batch\\_size (int): batch 的大小；\n",
    "            * use\\_gpu (bool): 是否使用 GPU 来预测；\n",
    "            * top\\_k (int): 返回预测结果的前 k 个。\n",
    "\n",
    "        - **返回**\n",
    "\n",
    "            -   res (list\\[dict\\]): 分类结果，列表的每一个元素均为字典，其中 key 为识别动物的类别，value为置信度。\n",
    "\n",
    "    - ```python\n",
    "      def save_inference_model(dirname,\n",
    "                               model_filename=None,\n",
    "                               params_filename=None,\n",
    "                               combined=True)\n",
    "      ```\n",
    "\n",
    "        - 将模型保存到指定路径。\n",
    "\n",
    "        - **参数**\n",
    "\n",
    "            * dirname: 存在模型的目录名称\n",
    "            * model_filename: 模型文件名称，默认为\\_\\_model\\_\\_\n",
    "            * params_filename: 参数文件名称，默认为\\_\\_params\\_\\_(仅当`combined`为True时生效)\n",
    "            * combined: 是否将参数保存到统一的一个文件中"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79afcba7",
   "metadata": {
    "id": "四-服务部署"
   },
   "source": [
    "## 四、服务部署\n",
    "\n",
    "- PaddleHub Serving可以部署一个在线动物识别服务。\n",
    "\n",
    "- ### 第一步：启动PaddleHub Serving\n",
    "\n",
    "    - 运行启动命令：\n",
    "\n",
    "        - ```shell\n",
    "          $ hub serving start -m resnet50_vd_animals\n",
    "          ```\n",
    "\n",
    "        - 这样就完成了一个在线动物识别服务化API的部署，默认端口号为8866。\n",
    "\n",
    "        - **NOTE:** 如使用GPU预测，则需要在启动服务之前，请设置CUDA\\_VISIBLE\\_DEVICES环境变量，否则不用设置。\n",
    "\n",
    "- ### 第二步：发送预测请求\n",
    "\n",
    "- 配置好服务端，以下数行代码即可实现发送预测请求，获取预测结果\n",
    "\n",
    "    ```python\n",
    "    import requests\n",
    "    import json\n",
    "    import cv2\n",
    "    import base64\n",
    "\n",
    "    def cv2_to_base64(image):\n",
    "        data = cv2.imencode('.jpg', image)[1]\n",
    "        return base64.b64encode(data.tostring()).decode('utf8')\n",
    "\n",
    "    # 发送HTTP请求\n",
    "    data = {'images':[cv2_to_base64(cv2.imread(\"/PATH/TO/IMAGE\"))]}\n",
    "    headers = {\"Content-type\": \"application/json\"}\n",
    "    url = \"http://127.0.0.1:8866/predict/resnet50_vd_animals\"\n",
    "    r = requests.post(url=url, headers=headers, data=json.dumps(data))\n",
    "\n",
    "    # 打印预测结果\n",
    "    print(r.json()[\"results\"])\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca38d0a0",
   "metadata": {
    "id": "五-更新历史"
   },
   "source": [
    "## 五、更新历史\n",
    "\n",
    "* 1.0.0\n",
    "\n",
    "  初始发布\n",
    "\n",
    "* 1.1.0\n",
    "\n",
    "  移除 Fluid API\n",
    "\n",
    "  - ```shell\n",
    "    $ hub install resnet50_vd_animals==1.1.0\n",
    "    ```"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "resnet50_vd_animals",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "python3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
