{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0da6ed73",
   "metadata": {
    "id": "ace2p"
   },
   "source": [
    "# ace2p\n",
    "\n",
    "|Module Name|ace2p|\n",
    "| :--- | :---: |\n",
    "|Category|Image segmentation|\n",
    "|Network|ACE2P|\n",
    "|Dataset|LIP|\n",
    "|Fine-tuning supported or not|No|\n",
    "|Module Size|259MB|\n",
    "|Data indicators|-|\n",
    "|Latest update date |2021-02-26|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d13ab6b",
   "metadata": {
    "id": "i-basic-information"
   },
   "source": [
    "## I. Basic Information\n",
    "\n",
    "- ### Application Effect Display\n",
    "\n",
    "  - Network architecture:\n",
    "      <p align=\"center\">\n",
    "      <img src=\"https://bj.bcebos.com/paddlehub/paddlehub-img/ace2p_network.jpg\" hspace=\"10\"/> <br/>\n",
    "      </p>\n",
    "\n",
    "  - Color palette\n",
    "\n",
    "      <p align=\"left\">\n",
    "      <img src=\"https://bj.bcebos.com/paddlehub/paddlehub-img/ace2p_palette.jpg\" hspace=\"10\"/> <br/>\n",
    "      </p>\n",
    "\n",
    "  - Sample results:\n",
    "      <p align=\"center\">\n",
    "      <img src=\"https://user-images.githubusercontent.com/35907364/130913092-312a5f37-842e-4fd0-8db4-5f853fd8419f.jpg\" width=\"337\" height=\"505\" hspace=\"10\"/> <img src=\"https://user-images.githubusercontent.com/35907364/130913765-c9572c77-c6bf-46ec-9653-04ff356b4b85.png\" width=\"337\" height=\"505\" hspace=\"10\"/>\n",
    "      </p>\n",
    "\n",
    "- ### Module Introduction\n",
    "\n",
    "  - Human Parsing is a fine-grained semantic segmentation task that aims to identify the components (for example, body parts and clothing) of a human image at the pixel level.  The PaddleHub Module uses ResNet101 as the backbone network, and accepts input image sizes of 473x473x3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601c336e",
   "metadata": {
    "id": "ii-installation"
   },
   "source": [
    "## II. Installation\n",
    "\n",
    "- ### 1、Environmental Dependence\n",
    "\n",
    "  - paddlepaddle >= 2.0.0\n",
    "\n",
    "  - paddlehub >= 2.0.0\n",
    "\n",
    "- ### 2、Installation\n",
    "\n",
    "    - ```shell\n",
    "      $ hub install ace2p\n",
    "      ```\n",
    "    - In case of any problems during installation, please refer to:[Windows_Quickstart](../../../../docs/docs_en/get_start/windows_quickstart.md)\n",
    "    | [Linux_Quickstart](../../../../docs/docs_en/get_start/linux_quickstart.md) | [Mac_Quickstart](../../../../docs/docs_en/get_start/mac_quickstart.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ce2065",
   "metadata": {
    "id": "iii-module-api-prediction"
   },
   "source": [
    "## III. Module API Prediction\n",
    "\n",
    "- ### 1、Command line Prediction\n",
    "\n",
    "    - ```shell\n",
    "      $ hub run ace2p --input_path \"/PATH/TO/IMAGE\"\n",
    "      ```\n",
    "\n",
    "    - If you want to call the Hub module through the command line, please refer to: [PaddleHub Command Line Instruction](../../../../docs/docs_en/tutorial/cmd_usage.rst)\n",
    "\n",
    "- ### 2、Prediction Code Example\n",
    "\n",
    "  - ```python\n",
    "    import paddlehub as hub\n",
    "    import cv2\n",
    "\n",
    "    human_parser = hub.Module(name=\"ace2p\")\n",
    "    result = human_parser.segmentation(images=[cv2.imread('/PATH/TO/IMAGE')])\n",
    "    ```\n",
    "\n",
    "- ### 3、API\n",
    "\n",
    "  - ```python\n",
    "    def segmentation(images=None,\n",
    "                    paths=None,\n",
    "                    batch_size=1,\n",
    "                    use_gpu=False,\n",
    "                    output_dir='ace2p_output',\n",
    "                    visualization=False):\n",
    "    ```\n",
    "\n",
    "    - Prediction API, used for human parsing.\n",
    "\n",
    "    - **Parameter**\n",
    "\n",
    "        * images (list\\[numpy.ndarray\\]): Image data, ndarray.shape is in the format [H, W, C], BGR.\n",
    "        * paths (list\\[str\\]): Image path.\n",
    "        * batch\\_size (int): Batch size.\n",
    "        * use\\_gpu (bool): Use GPU or not. **set the CUDA_VISIBLE_DEVICES environment variable first if you are using GPU**\n",
    "        * output\\_dir (str): Save path of output, default is 'ace2p_output'.\n",
    "        * visualization (bool): Whether to save the recognition results as picture files.\n",
    "\n",
    "    - **Return**\n",
    "\n",
    "        * res (list\\[dict\\]): The list of recognition results, where each element is dict and each field is:\n",
    "            * save\\_path (str, optional): Save path of the result.\n",
    "            * data (numpy.ndarray): The result of portrait segmentation.\n",
    "\n",
    "  - ```python\n",
    "    def save_inference_model(dirname)\n",
    "    ```\n",
    "\n",
    "    - Save the model to the specified path.\n",
    "\n",
    "    - **Parameters**\n",
    "      * dirname: Model save path."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc15eb43",
   "metadata": {
    "id": "iv-server-deployment"
   },
   "source": [
    "## IV. Server Deployment\n",
    "\n",
    "- PaddleHub Serving can deploy an online service of  human parsing\n",
    "\n",
    "- ### Step 1: Start PaddleHub Serving\n",
    "\n",
    "  - Run the startup command:\n",
    "\n",
    "    - ```shell\n",
    "      $ hub serving start -m ace2p\n",
    "      ```\n",
    "\n",
    "  - The servitization API is now deployed and the default port number is 8866.\n",
    "\n",
    "  - **NOTE:**  If GPU is used for prediction, set CUDA_VISIBLE_DEVICES environment variable before the service, otherwise it need not be set.\n",
    "\n",
    "- ### Step 2: Send a predictive request\n",
    "\n",
    "  - With a configured server, use the following lines of code to send the prediction request and obtain the result\n",
    "\n",
    "    - ```python\n",
    "      import requests\n",
    "      import json\n",
    "      import cv2\n",
    "      import base64\n",
    "\n",
    "      import numpy as np\n",
    "\n",
    "      def cv2_to_base64(image):\n",
    "          data = cv2.imencode('.jpg', image)[1]\n",
    "          return base64.b64encode(data.tostring()).decode('utf8')\n",
    "\n",
    "      def base64_to_cv2(b64str):\n",
    "          data = base64.b64decode(b64str.encode('utf8'))\n",
    "          data = np.fromstring(data, np.uint8)\n",
    "          data = cv2.imdecode(data, cv2.IMREAD_COLOR)\n",
    "          return data\n",
    "\n",
    "      # Send an HTTP request\n",
    "      data = {'images':[cv2_to_base64(cv2.imread(\"/PATH/TO/IMAGE\"))]}\n",
    "      headers = {\"Content-type\": \"application/json\"}\n",
    "      url = \"http://127.0.0.1:8866/predict/ace2p\"\n",
    "      r = requests.post(url=url, headers=headers, data=json.dumps(data))\n",
    "\n",
    "      # print prediction results\n",
    "      print(base64_to_cv2(r.json()[\"results\"][0]['data']))\n",
    "      ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e4562c",
   "metadata": {
    "id": "五-更新历史"
   },
   "source": [
    "## 五、更新历史\n",
    "\n",
    "- 1.0.0\n",
    "\n",
    "  First release\n",
    "\n",
    "* 1.1.0\n",
    "\n",
    "  Adapt to paddlehub2.0\n",
    "\n",
    "* 1.2.0\n",
    "\n",
    "  Remove Fluid API\n",
    "\n",
    "  ```shell\n",
    "  $ hub install ace2p == 1.2.0\n",
    "  ```"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "ace2p",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "python3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
