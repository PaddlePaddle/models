{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9860ece",
   "metadata": {
    "id": "ernie_gen"
   },
   "source": [
    "# ernie_gen\n",
    "\n",
    "| 模型名称            |   ernie_gen   |\n",
    "| :------------------ | :-----------: |\n",
    "| 类别                | 文本-文本生成 |\n",
    "| 网络                |   ERNIE-GEN   |\n",
    "| 数据集              |       -       |\n",
    "| 是否支持Fine-tuning |      是       |\n",
    "| 模型大小            |      85K      |\n",
    "| 最新更新日期        |  2021-07-20   |\n",
    "| 数据指标            |       -       |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ff4d12",
   "metadata": {
    "id": "一-模型基本信息"
   },
   "source": [
    "## 一、模型基本信息\n",
    "\n",
    "- ### 模型介绍\n",
    "  - ERNIE-GEN 是面向生成任务的预训练-微调框架，首次在预训练阶段加入span-by-span 生成任务，让模型每次能够生成一个语义完整的片段。在预训练和微调中通过填充式生成机制和噪声感知机制来缓解曝光偏差问题。此外, ERNIE-GEN 采样多片段-多粒度目标文本采样策略, 增强源文本和目标文本的关联性，加强了编码器和解码器的交互。\n",
    "  - ernie_gen module是一个具备微调功能的module，可以快速完成特定场景module的制作。\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://user-images.githubusercontent.com/76040149/133191670-8eb1c542-f8e8-4715-adb2-6346b976fab1.png\" width=\"600\" hspace=\"10\"/>\n",
    "</p>\n",
    "\n",
    "- 更多详情请查看：[ERNIE-GEN:An Enhanced Multi-Flow Pre-training and Fine-tuning Framework for Natural Language Generation](https://arxiv.org/abs/2001.11314)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f348a782",
   "metadata": {
    "id": "二-安装"
   },
   "source": [
    "## 二、安装\n",
    "\n",
    "- ### 1、环境依赖\n",
    "\n",
    "  - paddlepaddle >= 2.0.0\n",
    "\n",
    "  - paddlehub >= 2.0.0   | [如何安装paddlehub](../../../../docs/docs_ch/get_start/installation.rst)\n",
    "\n",
    "  - paddlenlp >= 2.0.0\n",
    "\n",
    "- ### 2、安装\n",
    "\n",
    "  - ```shell\n",
    "    $ hub install ernie_gen\n",
    "    ```\n",
    "  - 如您安装时遇到问题，可参考：[零基础windows安装](../../../../docs/docs_ch/get_start/windows_quickstart.md)\n",
    " | [零基础Linux安装](../../../../docs/docs_ch/get_start/linux_quickstart.md) | [零基础MacOS安装](../../../../docs/docs_ch/get_start/mac_quickstart.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3f7820",
   "metadata": {
    "id": "三-模型api预测"
   },
   "source": [
    "## 三、模型API预测\n",
    "\n",
    "- ernie_gen需要**先针对特定数据集fine-tune**，才能使用\n",
    "  - 文本生成任务有很多种，ernie_gen仅提供了生成文本的基本参数，需要针对特定任务的数据集做fine-tune才能使用\n",
    "  - paddlehub提供了简单的fine-tune数据集：[train.txt](./test_data/train.txt), [dev.txt](./test_data/dev.txt)\n",
    "  - paddlehub也提供了多个fine-tune好的预训练模型：[对联生成](../ernie_gen_couplet/)，[情话生成](../ernie_gen_lover_words/)，[诗歌生成](../ernie_gen_poetry/)等"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34892933",
   "metadata": {
    "id": "1-fine-tune并封装"
   },
   "source": [
    "### 1、Fine-tune并封装\n",
    "\n",
    "- #### Fine-tune代码实例\n",
    "\n",
    "  - ```python\n",
    "    import paddlehub as hub\n",
    "\n",
    "    module = hub.Module(name=\"ernie_gen\")\n",
    "\n",
    "    result = module.finetune(\n",
    "        train_path='train.txt',\n",
    "        dev_path='dev.txt',\n",
    "        max_steps=300,\n",
    "        batch_size=2\n",
    "    )\n",
    "\n",
    "    module.export(params_path=result['last_save_path'], module_name=\"ernie_gen_test\", author=\"test\")\n",
    "    ```\n",
    "\n",
    "- #### API说明\n",
    "\n",
    "  - ```python\n",
    "    def finetune(train_path,\n",
    "                 dev_path=None,\n",
    "                 save_dir=\"ernie_gen_result\",\n",
    "                 init_ckpt_path=None,\n",
    "                 use_gpu=True,\n",
    "                 max_steps=500,\n",
    "                 batch_size=8,\n",
    "                 max_encode_len=15,\n",
    "                 max_decode_len=15,\n",
    "                 learning_rate=5e-5,\n",
    "                 warmup_proportion=0.1,\n",
    "                 weight_decay=0.1,\n",
    "                 noise_prob=0,\n",
    "                 label_smooth=0,\n",
    "                 beam_width=5,\n",
    "                 length_penalty=1.0,\n",
    "                 log_interval=100,\n",
    "                 save_interval=200):\n",
    "    ```\n",
    "\n",
    "    - 微调模型参数的API\n",
    "    - **参数**\n",
    "      - train_path(str): 训练集路径。训练集的格式应为：\"序号\\t输入文本\\t标签\"，例如：\"1\\t床前明月光\\t疑是地上霜\"，注意\\t不能使用空格替代\n",
    "      - dev_path(str): 验证集路径。验证集的格式应为：\"序号\\t输入文本\\t标签\"，例如：\"1\\t举头望明月\\t低头思故乡\"，注意\\t不能使用空格替代\n",
    "      - save_dir(str): 模型保存以及验证集预测输出路径。\n",
    "      - init_ckpt_path(str): 模型初始化加载路径，可实现增量训练。\n",
    "      - use_gpu(bool): 是否使用GPU。\n",
    "      - max_steps(int): 最大训练步数。\n",
    "      - batch_size(int): 训练时的batch大小。\n",
    "      - max_encode_len(int): 最长编码长度。\n",
    "      - max_decode_len(int): 最长解码长度。\n",
    "      - learning_rate(float): 学习率大小。\n",
    "      - warmup_proportion(float): 学习率warmup比例。\n",
    "      - weight_decay(float): 权值衰减大小。\n",
    "      - noise_prob(float): 噪声概率，详见ernie gen论文。\n",
    "      - label_smooth(float): 标签平滑权重。\n",
    "      - beam_width(int): 验证集预测时的beam大小。\n",
    "      - length_penalty(float): 验证集预测时的长度惩罚权重。\n",
    "      - log_interval(int): 训练时的日志打印间隔步数。\n",
    "      - save_interval(int): 训练时的模型保存间隔部署。验证集将在模型保存完毕后进行预测。\n",
    "    - **返回**\n",
    "      - result(dict): 运行结果。包含2个键:\n",
    "        - last_save_path(str): 训练结束时的模型保存路径。\n",
    "        - last_ppl(float): 训练结束时的模型困惑度。\n",
    "\n",
    "  - ```python\n",
    "    def export(\n",
    "      params_path,\n",
    "      module_name,\n",
    "      author,\n",
    "      version=\"1.0.0\",\n",
    "      summary=\"\",\n",
    "      author_email=\"\",\n",
    "      export_path=\".\"):\n",
    "    ```\n",
    "\n",
    "    - module导出API，通过此API可以一键将训练参数打包为hub module。\n",
    "    - **参数**\n",
    "      - params_path(str): 模型参数路径。\n",
    "      - module_name(str): module名称，例如\"ernie_gen_couplet\"。\n",
    "      - author(str): 作者名称。\n",
    "      - max_encode_len(int): 最大编码长度。\n",
    "      - max_decode_len(int): 最大解码长度\n",
    "      - version(str): 版本号。\n",
    "      - summary(str): module的英文简介。\n",
    "      - author_email(str): 作者的邮箱地址。\n",
    "      - export_path(str): module的导出路径。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ff921b",
   "metadata": {
    "id": "2-模型预测"
   },
   "source": [
    "### 2、模型预测\n",
    "\n",
    "- **定义`$module_name`为export指定的module_name**\n",
    "\n",
    "- 模型转换完毕之后，通过`hub install $module_name`安装该模型，即可通过以下2种方式调用自制module：\n",
    "\n",
    "- #### 法1：命令行预测\n",
    "\n",
    "  - ```python\n",
    "    $ hub run $module_name --input_text=\"输入文本\" --use_gpu True --beam_width 5\n",
    "    ```\n",
    "\n",
    "  - 通过命令行方式实现hub模型的调用，更多请见 [PaddleHub命令行指令](../../../../docs/docs_ch/tutorial/cmd_usage.rst)\n",
    "\n",
    "- #### 法2：API预测\n",
    "\n",
    "  - ```python\n",
    "    import paddlehub as hub\n",
    "\n",
    "    module = hub.Module(name=\"$module_name\")\n",
    "\n",
    "    test_texts = [\"输入文本1\", \"输入文本2\"]\n",
    "    # generate包含3个参数，texts为输入文本列表，use_gpu指定是否使用gpu，beam_width指定beam search宽度。\n",
    "    results = module.generate(texts=test_texts, use_gpu=True, beam_width=5)\n",
    "    for result in results:\n",
    "        print(result)\n",
    "    ```\n",
    "\n",
    "- 您也可以将`$module_name`文件夹打包为tar.gz压缩包并联系PaddleHub工作人员上传至PaddleHub模型仓库，这样更多的用户可以通过一键安装的方式使用您的模型。PaddleHub非常欢迎您的贡献，共同推动开源社区成长。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2326158c",
   "metadata": {
    "id": "四-服务部署"
   },
   "source": [
    "## 四、服务部署\n",
    "\n",
    "- PaddleHub Serving 可以部署一个文本生成的在线服务。\n",
    "\n",
    "- ### 第一步：启动PaddleHub Serving\n",
    "\n",
    "  - 运行启动命令：\n",
    "  - ```shell\n",
    "    $ hub serving start -m $module_name -p 8866\n",
    "    ```\n",
    "\n",
    "  - 这样就完成了一个目标检测的服务化API的部署，默认端口号为8866。\n",
    "\n",
    "  - **NOTE:** 如使用GPU预测，则需要在启动服务之前，请设置CUDA\\_VISIBLE\\_DEVICES环境变量，否则不用设置。\n",
    "\n",
    "- ### 第二步：发送预测请求\n",
    "\n",
    "  - 客户端通过以下数行代码即可实现发送预测请求，获取预测结果\n",
    "\n",
    "  - ```python\n",
    "    import requests\n",
    "    import json\n",
    "\n",
    "    # 发送HTTP请求\n",
    "\n",
    "    data = {'texts':[\"输入文本1\", \"输入文本2\"],\n",
    "            'use_gpu':True, 'beam_width':5}\n",
    "    headers = {\"Content-type\": \"application/json\"}\n",
    "    url = \"http://127.0.0.1:8866/predict/$module_name\"\n",
    "    r = requests.post(url=url, headers=headers, data=json.dumps(data))\n",
    "\n",
    "    # 保存结果\n",
    "    results = r.json()[\"results\"]\n",
    "    for result in results:\n",
    "        print(result)\n",
    "    ```\n",
    "\n",
    "- **NOTE:** 上述`$module_name`为export指定的module_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b5e524",
   "metadata": {
    "id": "五-更新历史"
   },
   "source": [
    "## 五、更新历史\n",
    "\n",
    "* 1.0.0\n",
    "\n",
    "  初始发布\n",
    "\n",
    "* 1.0.1\n",
    "\n",
    "  修复模型导出bug\n",
    "\n",
    "* 1.0.2\n",
    "\n",
    "   修复windows运行中的bug\n",
    "\n",
    "* 1.1.0\n",
    "\n",
    "   接入PaddleNLP\n",
    "\n",
    "   - ```shell\n",
    "     $ hub install ernie_gen==1.1.0\n",
    "     ```"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "ernie_gen",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "python3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
