{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "109cfb18",
   "metadata": {
    "id": "falsr_b"
   },
   "source": [
    "# falsr_b\n",
    "\n",
    "|模型名称|falsr_b|\n",
    "| :--- | :---: |\n",
    "|类别|图像-图像编辑|\n",
    "|网络|falsr_b|\n",
    "|数据集|DIV2k|\n",
    "|是否支持Fine-tuning|否|\n",
    "|模型大小|4MB|\n",
    "|指标|PSNR37.61|\n",
    "|最新更新日期|2021-02-26|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cf89ac",
   "metadata": {
    "id": "一-模型基本信息"
   },
   "source": [
    "## 一、模型基本信息\n",
    "\n",
    "- ### 应用效果展示\n",
    "\n",
    "  - 样例结果示例(左为原图，右为效果图)：\n",
    "    <p align=\"center\">\n",
    "    <img src=\"https://user-images.githubusercontent.com/35907364/133558583-0b7049db-ed1f-4a16-8676-f2141fcb3dee.png\" width=\"450\" height=\"300\" hspace=\"10\"/> <img src=\"https://user-images.githubusercontent.com/35907364/130899031-a6f8c58a-5cb7-4105-b990-8cca5ae15368.png\" width=\"450\" height=\"300\" hspace=\"10\"/>\n",
    "    </p>\n",
    "\n",
    "- ### 模型介绍\n",
    "\n",
    "  - falsr_b是基于Fast, Accurate and Lightweight Super-Resolution with Neural Architecture Search设计的轻量化超分辨模型。该模型使用多目标方法处理超分问题，同时使用基于混合控制器的弹性搜索策略来提升模型性能。该模型提供的超分倍数为2倍。\n",
    "\n",
    "  - 更多详情请参考：[falsr_b](https://github.com/xiaomi-automl/FALSR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11aefd99",
   "metadata": {
    "id": "二-安装"
   },
   "source": [
    "## 二、安装\n",
    "\n",
    "- ### 1、环境依赖\n",
    "\n",
    "  - paddlepaddle >= 2.0.0\n",
    "\n",
    "  - paddlehub >= 2.0.0\n",
    "\n",
    "- ### 2、安装\n",
    "    - ```shell\n",
    "      $ hub install falsr_b\n",
    "      ```\n",
    "\n",
    "    - 如您安装时遇到问题，可参考：[零基础windows安装](../../../../docs/docs_ch/get_start/windows_quickstart.md)\n",
    "    | [零基础Linux安装](../../../../docs/docs_ch/get_start/linux_quickstart.md) | [零基础MacOS安装](../../../../docs/docs_ch/get_start/mac_quickstart.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8af1443",
   "metadata": {
    "id": "三-模型api预测"
   },
   "source": [
    "## 三、模型API预测\n",
    "\n",
    "- ### 1、命令行预测\n",
    "\n",
    "  - ```\n",
    "    $ hub run falsr_b --input_path \"/PATH/TO/IMAGE\"\n",
    "    ```\n",
    "- ### 2、预测代码示例\n",
    "\n",
    "  ```python\n",
    "  import cv2\n",
    "  import paddlehub as hub\n",
    "\n",
    "  sr_model = hub.Module(name='falsr_b')\n",
    "  im = cv2.imread('/PATH/TO/IMAGE').astype('float32')\n",
    "  #visualization=True可以用于查看超分图片效果，可设置为False提升运行速度。\n",
    "  res = sr_model.reconstruct(images=[im], visualization=True)\n",
    "  print(res[0]['data'])\n",
    "  ```\n",
    "\n",
    "- ### 3、API\n",
    "\n",
    "  - ```python\n",
    "    def reconstruct(images=None,\n",
    "                    paths=None,\n",
    "                    use_gpu=False,\n",
    "                    visualization=False,\n",
    "                    output_dir=\"falsr_b_output\")\n",
    "    ```\n",
    "\n",
    "    - 预测API，用于图像超分辨率。\n",
    "\n",
    "    - **参数**\n",
    "\n",
    "      * images (list\\[numpy.ndarray\\]): 图片数据，ndarray.shape 为 \\[H, W, C\\]，BGR格式；\n",
    "      * paths (list\\[str\\]): 图片的路径；\n",
    "      * use\\_gpu (bool): 是否使用 GPU预测，如果使用GPU预测，则在预测之前，请设置CUDA_VISIBLE_DEVICES环境变量，否则不用设置；\n",
    "      * visualization (bool): 是否将识别结果保存为图片文件；\n",
    "      * output\\_dir (str): 图片的保存路径。\n",
    "\n",
    "    - **返回**\n",
    "\n",
    "      * res (list\\[dict\\]): 识别结果的列表，列表中每一个元素为 dict，关键字有 'save\\_path'， 'data'，对应的取值为：\n",
    "        * save\\_path (str, optional): 可视化图片的保存路径（仅当visualization=True时存在）；\n",
    "        * data (numpy.ndarray): 超分辨后图像。\n",
    "\n",
    "  - ```python\n",
    "    def save_inference_model(dirname)\n",
    "    ```\n",
    "\n",
    "    - 将模型保存到指定路径。\n",
    "\n",
    "    - **参数**\n",
    "\n",
    "      * dirname: 模型保存路径"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d8d6bd",
   "metadata": {
    "id": "四-服务部署"
   },
   "source": [
    "## 四、服务部署\n",
    "\n",
    "- PaddleHub Serving可以部署一个图像超分的在线服务。\n",
    "\n",
    "- ### 第一步：启动PaddleHub Serving\n",
    "\n",
    "    - 运行启动命令：\n",
    "\n",
    "      - ```shell\n",
    "        $ hub serving start -m falsr_b\n",
    "        ```\n",
    "\n",
    "      - 这样就完成了一个超分任务的服务化API的部署，默认端口号为8866。\n",
    "\n",
    "      - **NOTE:** 如使用GPU预测，则需要在启动服务之前，设置CUDA_VISIBLE_DEVICES环境变量，否则不用设置。\n",
    "\n",
    " - ### 第二步：发送预测请求\n",
    "\n",
    "    - 配置好服务端，以下数行代码即可实现发送预测请求，获取预测结果\n",
    "        ```python\n",
    "        import requests\n",
    "        import json\n",
    "        import base64\n",
    "\n",
    "        import cv2\n",
    "        import numpy as np\n",
    "\n",
    "        def cv2_to_base64(image):\n",
    "            data = cv2.imencode('.jpg', image)[1]\n",
    "            return base64.b64encode(data.tostring()).decode('utf8')\n",
    "        def base64_to_cv2(b64str):\n",
    "            data = base64.b64decode(b64str.encode('utf8'))\n",
    "            data = np.fromstring(data, np.uint8)\n",
    "            data = cv2.imdecode(data, cv2.IMREAD_COLOR)\n",
    "            return data\n",
    "\n",
    "        # 发送HTTP请求\n",
    "        org_im = cv2.imread('/PATH/TO/IMAGE')\n",
    "        data = {'images':[cv2_to_base64(org_im)]}\n",
    "        headers = {\"Content-type\": \"application/json\"}\n",
    "        url = \"http://127.0.0.1:8866/predict/falsr_b\"\n",
    "        r = requests.post(url=url, headers=headers, data=json.dumps(data))\n",
    "        sr = base64_to_cv2(r.json()[\"results\"][0]['data'])\n",
    "        cv2.imwrite('falsr_b_X2.png', sr)\n",
    "        print(\"save image as falsr_b_X2.png\")\n",
    "        ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b771f63",
   "metadata": {
    "id": "五-更新历史"
   },
   "source": [
    "## 五、更新历史\n",
    "\n",
    "* 1.0.0\n",
    "\n",
    "  初始发布\n",
    "\n",
    "* 1.1.0\n",
    "\n",
    "  移除 fluid API\n",
    "\n",
    "  ```shell\n",
    "  $ hub install falsr_b == 1.1.0\n",
    "  ```"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "falsr_b",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "python3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
