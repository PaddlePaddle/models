{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32a2ba94",
   "metadata": {
    "id": "ugatit_83w"
   },
   "source": [
    "# UGATIT_83w\n",
    "\n",
    "|Module Name|UGATIT_83w|\n",
    "| :--- | :---: |\n",
    "|Category|Image editing|\n",
    "|Network |U-GAT-IT|\n",
    "|Dataset|selfie2anime|\n",
    "|Fine-tuning supported or not|No|\n",
    "|Module Size|41MB|\n",
    "|Latest update date |2021-02-26|\n",
    "|Data indicators|-|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8272d2c",
   "metadata": {
    "id": "i-basic-information"
   },
   "source": [
    "## I. Basic Information\n",
    "\n",
    "- ### Application Effect Display\n",
    "  - Sample results:\n",
    "    <p align=\"center\">\n",
    "    <img src=\"https://user-images.githubusercontent.com/35907364/136651638-33cac040-edad-41ac-a9ce-7c0e678d8c52.jpg\" width=\"400\" height=\"400\" hspace=\"10\"/> <img src=\"https://user-images.githubusercontent.com/35907364/136651644-dd1d3836-99b3-40f0-8543-37de18f9cfd9.jpg\" width=\"400\" height=\"400\" hspace=\"10\"/>\n",
    "    </p>\n",
    "\n",
    "- ### Module Introduction\n",
    "\n",
    "  - UGATIT  can transfer the input face image into the anime style."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39b4cf8",
   "metadata": {
    "id": "ii-installation"
   },
   "source": [
    "## II. Installation\n",
    "\n",
    "- ### 1、Environmental Dependence\n",
    "\n",
    "  - paddlepaddle >= 1.8.2\n",
    "\n",
    "  - paddlehub >= 1.8.0\n",
    "\n",
    "- ### 2、Installation\n",
    "\n",
    "  - ```shell\n",
    "    $ hub install UGATIT_83w\n",
    "    ```\n",
    "\n",
    "  - In case of any problems during installation, please refer to:[Windows_Quickstart](../../../../docs/docs_en/get_start/windows_quickstart.md)\n",
    "    | [Linux_Quickstart](../../../../docs/docs_en/get_start/linux_quickstart.md) | [Mac_Quickstart](../../../../docs/docs_en/get_start/mac_quickstart.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff08dcff",
   "metadata": {
    "id": "iii-module-api-prediction"
   },
   "source": [
    "## III. Module API Prediction\n",
    "\n",
    "- ### 1、Prediction Code Example\n",
    "\n",
    "  - ```python\n",
    "    import cv2\n",
    "    import paddlehub as hub\n",
    "\n",
    "    model = hub.Module(name='UGATIT_83w', use_gpu=False)\n",
    "    result = model.style_transfer(images=[cv2.imread('/PATH/TO/IMAGE')])\n",
    "    # or\n",
    "    # result = model.style_transfer(paths=['/PATH/TO/IMAGE'])\n",
    "    ```\n",
    "\n",
    "- ### 2、API\n",
    "\n",
    "  - ```python\n",
    "    def style_transfer(\n",
    "        self,\n",
    "        images=None,\n",
    "        paths=None,\n",
    "        batch_size=1,\n",
    "        output_dir='output',\n",
    "        visualization=False\n",
    "    )\n",
    "    ```\n",
    "\n",
    "    - Style transfer API, convert the input face image into anime style.\n",
    "\n",
    "    - **Parameters**\n",
    "        * images (list\\[numpy.ndarray\\]): Image data, ndarray.shape is in the format [H, W, C], BGR.\n",
    "        * paths (list\\[str\\]): image path，default is None；\n",
    "        * batch\\_size (int): Batch size, default is 1；\n",
    "        * visualization (bool): Whether to save the recognition results as picture files, default is False.\n",
    "        * output\\_dir (str): Save path of images, `output` by default.\n",
    "\n",
    "      **NOTE:** Choose one of `paths` and `images` to provide data.\n",
    "\n",
    "    - **Return**\n",
    "\n",
    "      - res (list\\[numpy.ndarray\\]): Result,  ndarray.shape is in the format [H, W, C]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8a84af",
   "metadata": {
    "id": "iv-server-deployment"
   },
   "source": [
    "## IV. Server Deployment\n",
    "\n",
    "- PaddleHub Serving can deploy an online service of Style transfer task.\n",
    "\n",
    "- ### Step 1: Start PaddleHub Serving\n",
    "\n",
    "  - Run the startup command:\n",
    "\n",
    "    - ```shell\n",
    "      $ hub serving start -m UGATIT_83w\n",
    "      ```\n",
    "\n",
    "  - The servitization API is now deployed and the default port number is 8866.\n",
    "\n",
    "  - **NOTE:**  If GPU is used for prediction, set CUDA_VISIBLE_DEVICES environment variable before the service, otherwise it need not be set.\n",
    "\n",
    "- ### Step 2: Send a predictive request\n",
    "\n",
    "  - With a configured server, use the following lines of code to send the prediction request and obtain the result\n",
    "\n",
    "    - ```python\n",
    "      import requests\n",
    "      import json\n",
    "      import cv2\n",
    "      import base64\n",
    "\n",
    "      def cv2_to_base64(image):\n",
    "          data = cv2.imencode('.jpg', image)[1]\n",
    "          return base64.b64encode(data.tostring()).decode('utf8')\n",
    "\n",
    "      # Send an HTTP request\n",
    "      data = {'images':[cv2_to_base64(cv2.imread(\"/PATH/TO/IMAGE\"))]}\n",
    "      headers = {\"Content-type\": \"application/json\"}\n",
    "      url = \"http://127.0.0.1:8866/predict/UGATIT_83w\"\n",
    "      r = requests.post(url=url, headers=headers, data=json.dumps(data))\n",
    "\n",
    "      # print prediction results\n",
    "      print(r.json()[\"results\"])\n",
    "      ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c46270",
   "metadata": {
    "id": "v-release-note"
   },
   "source": [
    "## V. Release Note\n",
    "\n",
    "- 1.0.0\n",
    "\n",
    "  First release"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "UGATIT_83w",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "python3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
