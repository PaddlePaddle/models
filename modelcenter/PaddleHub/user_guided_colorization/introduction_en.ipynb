{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4673c5eb",
   "metadata": {
    "id": "user_guided_colorization"
   },
   "source": [
    "# user_guided_colorization\n",
    "\n",
    "|Module Name|user_guided_colorization|\n",
    "| :--- | :---: |\n",
    "|Category |Image editing|\n",
    "|Network| Local and Global Hints Network |\n",
    "|Dataset|ILSVRC 2012|\n",
    "|Fine-tuning supported or notFine-tuning|Yes|\n",
    "|Module Size|131MB|\n",
    "|Data indicators|-|\n",
    "|Latest update date |2021-02-26|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d64b26",
   "metadata": {
    "id": "i-basic-information"
   },
   "source": [
    "## I. Basic Information\n",
    "\n",
    "- ### Application Effect Display\n",
    "\n",
    "  - Sample results:\n",
    "    <p align=\"center\">\n",
    "    <img src=\"https://user-images.githubusercontent.com/35907364/136653401-6644bd46-d280-4c15-8d48-680b7eb152cb.png\" width=\"300\" height=\"450\" hspace=\"10\"/> <img src=\"https://user-images.githubusercontent.com/35907364/136648959-40493c9c-08ec-46cd-a2a2-5e2038dcbfa7.png\" width=\"300\" height=\"450\" hspace=\"10\"/>\n",
    "    </p>\n",
    "\n",
    "- ### Module Introduction\n",
    "\n",
    "  - User_guided_colorization is a colorization model based on \"Real-Time User-Guided Image Colorization with Learned Deep Priors\"，this model uses pre-supplied coloring blocks to color the gray image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4e77a7",
   "metadata": {
    "id": "ii-installation"
   },
   "source": [
    "## II. Installation\n",
    "\n",
    "- ### 1、Environmental Dependence\n",
    "\n",
    "    - paddlepaddle >= 2.0.0\n",
    "\n",
    "    - paddlehub >= 2.0.0\n",
    "\n",
    "- ### 2、Installation\n",
    "\n",
    "    - ```shell\n",
    "      $ hub install user_guided_colorization\n",
    "      ```\n",
    "\n",
    "    - In case of any problems during installation, please refer to: [Windows_Quickstart](../../../../docs/docs_en/get_start/windows_quickstart.md)\n",
    "    | [Linux_Quickstart](../../../../docs/docs_en/get_start/linux_quickstart.md) | [Mac_Quickstart](../../../../docs/docs_en/get_start/mac_quickstart.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0a4d5f",
   "metadata": {
    "id": "iii-module-api-prediction"
   },
   "source": [
    "## III. Module API Prediction\n",
    "\n",
    "- ### 1、Command line Prediction\n",
    "\n",
    "    ```shell\n",
    "    $ hub run user_guided_colorization --input_path \"/PATH/TO/IMAGE\"\n",
    "    ```\n",
    "\n",
    "     - If you want to call the Hub module through the command line, please refer to: [PaddleHub Command Line Instruction](../../../../docs/docs_en/tutorial/cmd_usage.rst)\n",
    "- ### 2、Prediction Code Example\n",
    "\n",
    "    ```python\n",
    "    import paddle\n",
    "    import paddlehub as hub\n",
    "\n",
    "    if __name__ == '__main__':\n",
    "\n",
    "        model = hub.Module(name='user_guided_colorization')\n",
    "        model.set_config(prob=0.1)\n",
    "        result = model.predict(images=['/PATH/TO/IMAGE'])\n",
    "    ```\n",
    "- ### 3.Fine-tune and Encapsulation\n",
    "\n",
    "    - After completing the installation of PaddlePaddle and PaddleHub, you can start using the user_guided_colorization model to fine-tune datasets such as [Canvas](../../docs/reference/datasets.md#class-hubdatasetsCanvas) by executing `python train.py`.\n",
    "\n",
    "    - Steps:\n",
    "\n",
    "        - Step1: Define the data preprocessing method\n",
    "\n",
    "            - ```python\n",
    "              import paddlehub.vision.transforms as T\n",
    "\n",
    "              transform = T.Compose([T.Resize((256, 256), interpolation='NEAREST'),\n",
    "                       T.RandomPaddingCrop(crop_size=176),\n",
    "                       T.RGB2LAB()], to_rgb=True)\n",
    "              ```\n",
    "\n",
    "              - `transforms`: The data enhancement module defines lots of data preprocessing methods. Users can replace the data preprocessing methods according to their needs.\n",
    "\n",
    "        - Step2: Download the dataset\n",
    "            - ```python\n",
    "              from paddlehub.datasets import Canvas\n",
    "\n",
    "              color_set = Canvas(transform=transform, mode='train')\n",
    "              ```\n",
    "\n",
    "                * `transforms`: Data preprocessing methods.\n",
    "                * `mode`: Select the data mode, the options are `train`, `test`, `val`. Default is `train`.\n",
    "                * `hub.datasets.Canvas()`: The dataset will be automatically downloaded from the network and decompressed to the `$HOME/.paddlehub/dataset` directory under the user directory.\n",
    "\n",
    "        - Step3: Load the pre-trained model\n",
    "\n",
    "            - ```python\n",
    "              model = hub.Module(name='user_guided_colorization', load_checkpoint=None)\n",
    "              model.set_config(classification=True, prob=1)\n",
    "              ```\n",
    "                * `name`: Model name.\n",
    "                * `load_checkpoint`: Whether to load the self-trained model, if it is None, load the provided parameters.\n",
    "                * `classification`: The model is trained by two mode. At the beginning, `classification` is set to True, which is used for shallow network training. In the later stage of training, set `classification` to False, which is used to train the output layer of the network.\n",
    "                * `prob`: The probability that a priori color block is not added to each input image, the default is 1, that is, no prior color block is added. For example, when `prob` is set to 0.9, the probability that there are two a priori color blocks on a picture is(1-0.9)*(1-0.9)*0.9=0.009.\n",
    "\n",
    "        - Step4: Optimization strategy\n",
    "\n",
    "            ```python\n",
    "            optimizer = paddle.optimizer.Adam(learning_rate=0.0001, parameters=model.parameters())\n",
    "            trainer = Trainer(model, optimizer, checkpoint_dir='img_colorization_ckpt_cls_1')\n",
    "            trainer.train(color_set, epochs=201, batch_size=25, eval_dataset=color_set, log_interval=10, save_interval=10)\n",
    "            ```\n",
    "\n",
    "            - Run configuration\n",
    "\n",
    "            - `Trainer` mainly control the training of Fine-tune, including the following controllable parameters:\n",
    "\n",
    "                * `model`: Optimized model.\n",
    "                * `optimizer`: Optimizer selection.\n",
    "                * `use_vdl`: Whether to use vdl to visualize the training process.\n",
    "                * `checkpoint_dir`: The storage address of the model parameters.\n",
    "                * `compare_metrics`: The measurement index of the optimal model.\n",
    "\n",
    "            - `trainer.train` mainly control the specific training process, including the following controllable parameters:\n",
    "\n",
    "                * `train_dataset`: Training dataset.\n",
    "                * `epochs`: Epochs of training process.\n",
    "                * `batch_size`: Batch size.\n",
    "                * `num_workers`: Number of workers.\n",
    "                * `eval_dataset`: Validation dataset.\n",
    "                * `log_interval`:The interval for printing logs.\n",
    "                * `save_interval`: The interval for saving model parameters.\n",
    "\n",
    "    - Model prediction\n",
    "\n",
    "        -   When Fine-tune is completed, the model with the best performance on the verification set will be saved in the `${CHECKPOINT_DIR}/best_model` directory. We use this model to make predictions. The `predict.py` script is as follows:\n",
    "\n",
    "            - ```python\n",
    "              import paddle\n",
    "              import paddlehub as hub\n",
    "\n",
    "              if __name__ == '__main__':\n",
    "                  model = hub.Module(name='user_guided_colorization', load_checkpoint='/PATH/TO/CHECKPOINT')\n",
    "                  model.set_config(prob=0.1)\n",
    "                  result = model.predict(images=['/PATH/TO/IMAGE'])\n",
    "              ```\n",
    "\n",
    "            - **NOTE:** If you want to get the oil painting style, please download the parameter file [Canvas colorization](https://paddlehub.bj.bcebos.com/dygraph/models/canvas_rc.pdparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b44021",
   "metadata": {
    "id": "iv-server-deployment"
   },
   "source": [
    "## IV. Server Deployment\n",
    "\n",
    "- PaddleHub Serving can deploy an online service of colorization.\n",
    "\n",
    "- ### Step 1: Start PaddleHub Serving\n",
    "\n",
    "    - Run the startup command:\n",
    "\n",
    "      - ```shell\n",
    "        $ hub serving start -m user_guided_colorization\n",
    "        ```\n",
    "\n",
    "    - The servitization API is now deployed and the default port number is 8866.\n",
    "\n",
    "    - **NOTE:** If GPU is used for prediction, set CUDA_VISIBLE_DEVICES environment variable before the service, otherwise it need not be set.\n",
    "\n",
    "- ### Step 2: Send a predictive request\n",
    "\n",
    "    - With a configured server, use the following lines of code to send the prediction request and obtain the result\n",
    "      - ```python\n",
    "        import requests\n",
    "        import json\n",
    "        import cv2\n",
    "        import base64\n",
    "        import numpy as np\n",
    "\n",
    "        def cv2_to_base64(image):\n",
    "            data = cv2.imencode('.jpg', image)[1]\n",
    "            return base64.b64encode(data.tostring()).decode('utf8')\n",
    "\n",
    "        def base64_to_cv2(b64str):\n",
    "            data = base64.b64decode(b64str.encode('utf8'))\n",
    "            data = np.fromstring(data, np.uint8)\n",
    "            data = cv2.imdecode(data, cv2.IMREAD_COLOR)\n",
    "            return data\n",
    "\n",
    "        # Send an HTTP request\n",
    "        org_im = cv2.imread('/PATH/TO/IMAGE')\n",
    "        data = {'images':[cv2_to_base64(org_im)]}\n",
    "        headers = {\"Content-type\": \"application/json\"}\n",
    "        url = \"http://127.0.0.1:8866/predict/user_guided_colorization\"\n",
    "        r = requests.post(url=url, headers=headers, data=json.dumps(data))\n",
    "        data = base64_to_cv2(r.json()[\"results\"]['data'][0]['fake_reg'])\n",
    "        cv2.imwrite('color.png', data)\n",
    "        ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b955a707",
   "metadata": {
    "id": "v-release-note"
   },
   "source": [
    "## V. Release Note\n",
    "\n",
    "* 1.0.0\n",
    "\n",
    "  First release\n",
    "\n",
    "  - ```shell\n",
    "    $ hub install user_guided_colorization==1.0.0\n",
    "    ```"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "user_guided_colorization",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "python3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
