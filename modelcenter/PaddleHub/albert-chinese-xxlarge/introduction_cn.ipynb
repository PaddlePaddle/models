{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d49988a",
   "metadata": {
    "id": "albert-chinese-xxlarge"
   },
   "source": [
    "# albert-chinese-xxlarge\n",
    "\n",
    "|模型名称|albert-chinese-xxlarge|\n",
    "| :--- | :---: |\n",
    "|类别|文本-语义模型|\n",
    "|网络|albert-chinese-xxlarge|\n",
    "|数据集|-|\n",
    "|是否支持Fine-tuning|是|\n",
    "|模型大小|1.3GB|\n",
    "|最新更新日期|2022-02-08|\n",
    "|数据指标|-|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131bae7c",
   "metadata": {
    "id": "一-模型基本信息"
   },
   "source": [
    "## 一、模型基本信息\n",
    "\n",
    "- ### 模型介绍\n",
    "\n",
    "  - ALBERT针对当前预训练模型参数量过大的问题，提出了以下改进方案：\n",
    "\n",
    "    - 嵌入向量参数化的因式分解。ALBERT对词嵌入参数进行了因式分解，先将单词映射到一个低维的词嵌入空间E，然后再将其映射到高维的隐藏空间H。\n",
    "\n",
    "    - 跨层参数共享。ALBERT共享了层之间的全部参数。\n",
    "\n",
    "更多详情请参考[ALBERT论文](https://arxiv.org/abs/1909.11942)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82977e2f",
   "metadata": {
    "id": "二-安装"
   },
   "source": [
    "## 二、安装\n",
    "\n",
    "- ### 1、环境依赖\n",
    "\n",
    "  - paddlepaddle >= 2.2.0\n",
    "\n",
    "  - paddlehub >= 2.2.0    | [如何安装PaddleHub](../../../../docs/docs_ch/get_start/installation.rst)\n",
    "\n",
    "- ### 2、安装\n",
    "\n",
    "  - ```shell\n",
    "    $ hub install albert-chinese-xxlarge\n",
    "    ```\n",
    "  - 如您安装时遇到问题，可参考：[零基础windows安装](../../../../docs/docs_ch/get_start/windows_quickstart.md)\n",
    " | [零基础Linux安装](../../../../docs/docs_ch/get_start/linux_quickstart.md) | [零基础MacOS安装](../../../../docs/docs_ch/get_start/mac_quickstart.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2df1ea",
   "metadata": {
    "id": "三-模型api预测"
   },
   "source": [
    "## 三、模型API预测\n",
    "\n",
    "- ### 1、预测代码示例\n",
    "\n",
    "详情可参考PaddleHub示例：\n",
    "- [文本分类](../../../../demo/text_classification)\n",
    "- [序列标注](../../../../demo/sequence_labeling)\n",
    "\n",
    "- ### 2、API\n",
    "\n",
    "  - ```python\n",
    "    def __init__(\n",
    "        task=None,\n",
    "        load_checkpoint=None,\n",
    "        label_map=None,\n",
    "        num_classes=2,\n",
    "        suffix=False,\n",
    "        **kwargs,\n",
    "    )\n",
    "    ```\n",
    "\n",
    "    - 创建Module对象（动态图组网版本）\n",
    "\n",
    "    - **参数**\n",
    "\n",
    "      - `task`： 任务名称，可为`seq-cls`(文本分类任务)或`token-cls`(序列标注任务)。\n",
    "      - `load_checkpoint`：使用PaddleHub Fine-tune api训练保存的模型参数文件路径。\n",
    "      - `label_map`：预测时的类别映射表。\n",
    "      - `num_classes`：分类任务的类别数，如果指定了`label_map`，此参数可不传，默认2分类。\n",
    "      - `suffix`: 序列标注任务的标签格式，如果设定为`True`，标签以'-B', '-I', '-E' 或者 '-S'为结尾，此参数默认为`False`。\n",
    "      - `**kwargs`：用户额外指定的关键字字典类型的参数。\n",
    "\n",
    "  - ```python\n",
    "    def predict(\n",
    "        data,\n",
    "        max_seq_len=128,\n",
    "        batch_size=1,\n",
    "        use_gpu=False\n",
    "    )\n",
    "    ```\n",
    "\n",
    "    - **参数**\n",
    "\n",
    "      - `data`： 待预测数据，格式为\\[\\[sample\\_a\\_text\\_a, sample\\_a\\_text\\_b\\], \\[sample\\_b\\_text\\_a, sample\\_b\\_text\\_b\\],…,\\]，其中每个元素都是一个样例，每个样例可以包含text\\_a与text\\_b。每个样例文本数量（1个或者2个）需和训练时保持一致。\n",
    "      - `max_seq_len`：模型处理文本的最大长度\n",
    "      - `batch_size`：模型批处理大小\n",
    "      - `use_gpu`：是否使用gpu，默认为False。对于GPU用户，建议开启use_gpu。\n",
    "\n",
    "    - **返回**\n",
    "\n",
    "      - `results`：list类型，不同任务类型的返回结果如下\n",
    "        - 文本分类：列表里包含每个句子的预测标签，格式为\\[label\\_1, label\\_2, …,\\]\n",
    "        - 序列标注：列表里包含每个句子每个token的预测标签，格式为\\[\\[token\\_1, token\\_2, …,\\], \\[token\\_1, token\\_2, …,\\], …,\\]\n",
    "\n",
    "  - ```python\n",
    "    def get_embedding(\n",
    "      data,\n",
    "      use_gpu=False\n",
    "    )\n",
    "    ```\n",
    "\n",
    "    - 用于获取输入文本的句子粒度特征与字粒度特征\n",
    "\n",
    "    - **参数**\n",
    "\n",
    "      - `data`：输入文本列表，格式为\\[\\[sample\\_a\\_text\\_a, sample\\_a\\_text\\_b\\], \\[sample\\_b\\_text\\_a, sample\\_b\\_text\\_b\\],…,\\]，其中每个元素都是一个样例，每个样例可以包含text\\_a与text\\_b。\n",
    "      - `use_gpu`：是否使用gpu，默认为False。对于GPU用户，建议开启use_gpu。\n",
    "\n",
    "    - **返回**\n",
    "\n",
    "      - `results`：list类型，格式为\\[\\[sample\\_a\\_pooled\\_feature, sample\\_a\\_seq\\_feature\\], \\[sample\\_b\\_pooled\\_feature, sample\\_b\\_seq\\_feature\\],…,\\]，其中每个元素都是对应样例的特征输出，每个样例都有句子粒度特征pooled\\_feature与字粒度特征seq\\_feature。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733bb93a",
   "metadata": {
    "id": "四-服务部署"
   },
   "source": [
    "## 四、服务部署\n",
    "\n",
    "- PaddleHub Serving可以部署一个在线获取预训练词向量。\n",
    "\n",
    "- ### 第一步：启动PaddleHub Serving\n",
    "\n",
    "  - ```shell\n",
    "    $ hub serving start -m albert-chinese-xxlarge\n",
    "    ```\n",
    "\n",
    "  - 这样就完成了一个获取预训练词向量服务化API的部署，默认端口号为8866。\n",
    "\n",
    "  - **NOTE:** 如使用GPU预测，则需要在启动服务之前，请设置CUDA_VISIBLE_DEVICES环境变量，否则不用设置。\n",
    "\n",
    "- ### 第二步：发送预测请求\n",
    "\n",
    "  - 配置好服务端，以下数行代码即可实现发送预测请求，获取预测结果\n",
    "\n",
    "  - ```python\n",
    "    import requests\n",
    "    import json\n",
    "\n",
    "    # 指定用于获取embedding的文本[[text_1], [text_2], ... ]}\n",
    "    text = [[\"今天是个好日子\"], [\"天气预报说今天要下雨\"]]\n",
    "    # 以key的方式指定text传入预测方法的时的参数，此例中为\"data\"\n",
    "    # 对应本地部署，则为module.get_embedding(data=text)\n",
    "    data = {\"data\": text}\n",
    "    # 发送post请求，content-type类型应指定json方式，url中的ip地址需改为对应机器的ip\n",
    "    url = \"http://127.0.0.1:8866/predict/albert-chinese-xxlarge\"\n",
    "    # 指定post请求的headers为application/json方式\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "    r = requests.post(url=url, headers=headers, data=json.dumps(data))\n",
    "    print(r.json())\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441cb60c",
   "metadata": {
    "id": "五-更新历史"
   },
   "source": [
    "## 五、更新历史\n",
    "\n",
    "* 1.0.0\n",
    "\n",
    "  初始发布"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "albert-chinese-xxlarge",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "python3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
