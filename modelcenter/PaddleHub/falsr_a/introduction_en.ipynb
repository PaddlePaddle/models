{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22e30583",
   "metadata": {
    "id": "falsr_a"
   },
   "source": [
    "# falsr_a\n",
    "\n",
    "|Module Name|falsr_a|\n",
    "| :--- | :---: |\n",
    "|Category |Image editing|\n",
    "|Network |falsr_a|\n",
    "|Dataset|DIV2k|\n",
    "|Fine-tuning supported or not|No|\n",
    "|Module Size |8.9MB|\n",
    "|Data indicators|PSNR37.82|\n",
    "|Latest update date|2021-02-26|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c270c67",
   "metadata": {
    "id": "i-basic-information"
   },
   "source": [
    "## I. Basic Information\n",
    "\n",
    "- ### Application Effect Display\n",
    "\n",
    "  - Sample results:\n",
    "    <p align=\"center\">\n",
    "    <img src=\"https://user-images.githubusercontent.com/35907364/133558583-0b7049db-ed1f-4a16-8676-f2141fcb3dee.png\" width=\"450\" height=\"300\" hspace=\"10\"/> <img src=\"https://user-images.githubusercontent.com/35907364/130899031-a6f8c58a-5cb7-4105-b990-8cca5ae15368.png\" width=\"450\" height=\"300\" hspace=\"10\"/>\n",
    "    </p>\n",
    "\n",
    "- ### Module Introduction\n",
    "\n",
    "  - Falsr_a is a lightweight super-resolution model based on \"Accurate and Lightweight Super-Resolution with Neural Architecture Search\". The model uses a multi-objective approach to deal with the over-segmentation problem, and uses an elastic search strategy based on a hybrid controller to improve the performance of the model. This model provides super resolution result with scale factor x2.\n",
    "\n",
    "  - For more information, please refer to: [falsr_a](https://github.com/xiaomi-automl/FALSR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3eae9c1",
   "metadata": {
    "id": "ii-installation"
   },
   "source": [
    "## II. Installation\n",
    "\n",
    "- ### 1、Environmental Dependence\n",
    "\n",
    "  - paddlepaddle >= 2.0.0\n",
    "\n",
    "  - paddlehub >= 2.0.0\n",
    "\n",
    "- ### 2、Installation\n",
    "\n",
    "    - ```shell\n",
    "      $ hub install falsr_a\n",
    "      ```\n",
    "\n",
    "    - In case of any problems during installation, please refer to:[Windows_Quickstart](../../../../docs/docs_en/get_start/windows_quickstart.md)\n",
    "    | [Linux_Quickstart](../../../../docs/docs_en/get_start/linux_quickstart.md) | [Mac_Quickstart](../../../../docs/docs_en/get_start/mac_quickstart.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2e8fd9",
   "metadata": {
    "id": "iii-module-api-prediction"
   },
   "source": [
    "## III. Module API Prediction\n",
    "\n",
    "- ### 1、Command line Prediction\n",
    "\n",
    "  - ```\n",
    "    $ hub run falsr_a --input_path \"/PATH/TO/IMAGE\"\n",
    "    ```\n",
    "  - If you want to call the Hub module through the command line, please refer to: [PaddleHub Command Line Instruction](../../../../docs/docs_en/tutorial/cmd_usage.rst)\n",
    "\n",
    "- ### 2、Prediction Code Example\n",
    "\n",
    "  - ```python\n",
    "    import cv2\n",
    "    import paddlehub as hub\n",
    "\n",
    "    sr_model = hub.Module(name='falsr_a')\n",
    "    im = cv2.imread('/PATH/TO/IMAGE').astype('float32')\n",
    "    res = sr_model.reconstruct(images=[im], visualization=True)\n",
    "    print(res[0]['data'])\n",
    "    ```\n",
    "\n",
    "- ### 3、API\n",
    "\n",
    "  - ```python\n",
    "    def reconstruct(images=None,\n",
    "                    paths=None,\n",
    "                    use_gpu=False,\n",
    "                    visualization=False,\n",
    "                    output_dir=\"falsr_a_output\")\n",
    "    ```\n",
    "\n",
    "    - Prediction API.\n",
    "\n",
    "    - **Parameter**\n",
    "\n",
    "      * images (list\\[numpy.ndarray\\]): image data，ndarray.shape is in the format \\[H, W, C\\]，BGR.\n",
    "      * paths (list\\[str\\]): image path.\n",
    "      * use\\_gpu (bool): use GPU or not. **set the CUDA_VISIBLE_DEVICES environment variable first if you are using GPU**.\n",
    "      * visualization (bool): Whether to save the recognition results as picture files.\n",
    "      * output\\_dir (str): save path of images, \"dcscn_output\" by default.\n",
    "\n",
    "    - **Return**\n",
    "      * res (list\\[dict\\]): The list of model results, where each element is dict and each field is:\n",
    "        * save\\_path (str, optional): Save path of the result, save_path is '' if no image is saved.\n",
    "        * data (numpy.ndarray): result of super resolution.\n",
    "\n",
    "  - ```python\n",
    "    def save_inference_model(dirname)\n",
    "    ```\n",
    "\n",
    "    - Save the model to the specified path.\n",
    "\n",
    "    - **Parameters**\n",
    "\n",
    "      * dirname: Model save path."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53dd874c",
   "metadata": {
    "id": "iv-server-deployment"
   },
   "source": [
    "## IV. Server Deployment\n",
    "\n",
    "- PaddleHub Serving can deploy an online service of super resolution.\n",
    "\n",
    "- ### Step 1: Start PaddleHub Serving\n",
    "\n",
    "    - Run the startup command:\n",
    "\n",
    "      - ```shell\n",
    "        $ hub serving start -m falsr_a\n",
    "        ```\n",
    "\n",
    "    - The servitization API is now deployed and the default port number is 8866.\n",
    "\n",
    "    - **NOTE:**  If GPU is used for prediction, set CUDA_VISIBLE_DEVICES environment variable before the service, otherwise it need not be set.\n",
    "\n",
    "- ### Step 2: Send a predictive request\n",
    "\n",
    "    - With a configured server, use the following lines of code to send the prediction request and obtain the result\n",
    "\n",
    "      - ```python\n",
    "        import requests\n",
    "        import json\n",
    "        import base64\n",
    "\n",
    "        import cv2\n",
    "        import numpy as np\n",
    "\n",
    "        def cv2_to_base64(image):\n",
    "            data = cv2.imencode('.jpg', image)[1]\n",
    "            return base64.b64encode(data.tostring()).decode('utf8')\n",
    "        def base64_to_cv2(b64str):\n",
    "            data = base64.b64decode(b64str.encode('utf8'))\n",
    "            data = np.fromstring(data, np.uint8)\n",
    "            data = cv2.imdecode(data, cv2.IMREAD_COLOR)\n",
    "            return data\n",
    "\n",
    "        org_im = cv2.imread('/PATH/TO/IMAGE')\n",
    "        data = {'images':[cv2_to_base64(org_im)]}\n",
    "        headers = {\"Content-type\": \"application/json\"}\n",
    "        url = \"http://127.0.0.1:8866/predict/falsr_a\"\n",
    "        r = requests.post(url=url, headers=headers, data=json.dumps(data))\n",
    "        sr = base64_to_cv2(r.json()[\"results\"][0]['data'])\n",
    "        cv2.imwrite('falsr_a_X2.png', sr)\n",
    "        print(\"save image as falsr_a_X2.png\")\n",
    "        ```\n",
    "\n",
    "- ### Gradio APP support\n",
    "  Starting with PaddleHub 2.3.1, the Gradio APP for falsr_a is supported to be accessed in the browser using the link http://127.0.0.1:8866/gradio/falsr_a."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16df63e2",
   "metadata": {
    "id": "v-release-note"
   },
   "source": [
    "## V. Release Note\n",
    "\n",
    "* 1.0.0\n",
    "\n",
    "  First release\n",
    "\n",
    "* 1.1.0\n",
    "\n",
    "  Remove Fluid API\n",
    "\n",
    "* 1.2.0\n",
    "\n",
    "  Add Gradio APP support.\n",
    "\n",
    "  ```shell\n",
    "  $ hub install falsr_a == 1.2.0\n",
    "  ```"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "falsr_a",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "python3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
