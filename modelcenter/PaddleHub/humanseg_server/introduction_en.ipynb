{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d80aab9d",
   "metadata": {
    "id": "humanseg_server"
   },
   "source": [
    "# humanseg_server\n",
    "\n",
    "|Module Name |humanseg_server|\n",
    "| :--- | :---: |\n",
    "|Category |Image segmentation|\n",
    "|Network|hrnet|\n",
    "|Dataset|Baidu self-built dataset|\n",
    "|Fine-tuning supported or not|No|\n",
    "|Module Size|159MB|\n",
    "|Data indicators|-|\n",
    "|Latest update date|2021-02-26|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ac5221",
   "metadata": {
    "id": "i-basic-information"
   },
   "source": [
    "## I. Basic Information\n",
    "\n",
    "- ### Application Effect Display\n",
    "\n",
    "  - Sample results:\n",
    "    <p align=\"center\">\n",
    "    <img src=\"https://user-images.githubusercontent.com/35907364/130913092-312a5f37-842e-4fd0-8db4-5f853fd8419f.jpg\" width=\"337\" height=\"505\" hspace=\"10\"/> <img src=\"https://user-images.githubusercontent.com/35907364/130915531-bd4b2294-47e4-47e1-b9d3-3c1fa8b90f8f.png\" width=\"337\" height=\"505\" hspace=\"10\"/>\n",
    "    </p>\n",
    "\n",
    "- ### Module Introduction\n",
    "\n",
    "    - HumanSeg-server model is trained by Baidu self-built dataset, which can be used for portrait segmentation.\n",
    "\n",
    "    - For more information, please refer to:[humanseg_server](https://github.com/PaddlePaddle/PaddleSeg/tree/release/2.2/contrib/HumanSeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bea37f",
   "metadata": {
    "id": "ii-installation"
   },
   "source": [
    "## II. Installation\n",
    "\n",
    "- ### 1、Environmental Dependence\n",
    "\n",
    "    - paddlepaddle >= 2.0.0\n",
    "\n",
    "    - paddlehub >= 2.0.0\n",
    "\n",
    "- ### 2、Installation\n",
    "\n",
    "    - ```shell\n",
    "      $ hub install humanseg_server\n",
    "      ```\n",
    "\n",
    "    - In case of any problems during installation, please refer to:[Windows_Quickstart](../../../../docs/docs_en/get_start/windows_quickstart.md)\n",
    "    | [Linux_Quickstart](../../../../docs/docs_en/get_start/linux_quickstart.md) | [Mac_Quickstart](../../../../docs/docs_en/get_start/mac_quickstart.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c879b2",
   "metadata": {
    "id": "iii-module-api-prediction"
   },
   "source": [
    "## III. Module API Prediction\n",
    "\n",
    "- ### 1、Command line Prediction\n",
    "\n",
    "    -   ```\n",
    "        hub run humanseg_server --input_path \"/PATH/TO/IMAGE\"\n",
    "        ```\n",
    "    - If you want to call the Hub module through the command line, please refer to: [PaddleHub Command Line Instruction](../../../../docs/docs_en/tutorial/cmd_usage.rst)\n",
    "\n",
    "- ### 2、Prediction Code Example\n",
    "    - Image segmentation and video segmentation example：\n",
    "        ```python\n",
    "        import cv2\n",
    "        import paddlehub as hub\n",
    "\n",
    "        human_seg = hub.Module(name='humanseg_server')\n",
    "        im = cv2.imread('/PATH/TO/IMAGE')\n",
    "        res = human_seg.segment(images=[im],visualization=True)\n",
    "        print(res[0]['data'])\n",
    "        human_seg.video_segment('/PATH/TO/VIDEO')\n",
    "        ```\n",
    "    - Video prediction example:\n",
    "\n",
    "        ```python\n",
    "        import cv2\n",
    "        import numpy as np\n",
    "        import paddlehub as hub\n",
    "\n",
    "        human_seg = hub.Module('humanseg_server')\n",
    "        cap_video = cv2.VideoCapture('\\PATH\\TO\\VIDEO')\n",
    "        fps = cap_video.get(cv2.CAP_PROP_FPS)\n",
    "        save_path = 'humanseg_server_video.avi'\n",
    "        width = int(cap_video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(cap_video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        cap_out = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc('M', 'J', 'P', 'G'), fps, (width, height))\n",
    "        prev_gray = None\n",
    "        prev_cfd = None\n",
    "        while cap_video.isOpened():\n",
    "            ret, frame_org = cap_video.read()\n",
    "            if ret:\n",
    "                [img_matting, prev_gray, prev_cfd] = human_seg.video_stream_segment(frame_org=frame_org, frame_id=cap_video.get(1), prev_gray=prev_gray, prev_cfd=prev_cfd)\n",
    "                img_matting = np.repeat(img_matting[:, :, np.newaxis], 3, axis=2)\n",
    "                bg_im = np.ones_like(img_matting) * 255\n",
    "                comb = (img_matting * frame_org + (1 - img_matting) * bg_im).astype(np.uint8)\n",
    "                cap_out.write(comb)\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        cap_video.release()\n",
    "        cap_out.release()\n",
    "\n",
    "        ```\n",
    "\n",
    "- ### 3、API\n",
    "\n",
    "    ```python\n",
    "    def segment(images=None,\n",
    "                paths=None,\n",
    "                batch_size=1,\n",
    "                use_gpu=False,\n",
    "                visualization=False,\n",
    "                output_dir='humanseg_server_output')\n",
    "    ```\n",
    "\n",
    "    - Prediction API, generating segmentation result.\n",
    "\n",
    "    - **Parameter**\n",
    "\n",
    "        * images (list\\[numpy.ndarray\\]): Image data, ndarray.shape is in the format [H, W, C], BGR.\n",
    "        * paths (list\\[str\\]): Image path.\n",
    "        * batch\\_size (int): Batch size.\n",
    "        * use\\_gpu (bool): Use GPU or not. **set the CUDA_VISIBLE_DEVICES environment variable first if you are using GPU**\n",
    "        * visualization (bool): Whether to save the results as picture files.\n",
    "        * output\\_dir (str): Save path of images, humanseg_server_output by default.\n",
    "\n",
    "    - **Return**\n",
    "\n",
    "        * res (list\\[dict\\]): The list of recognition results, where each element is dict and each field is:\n",
    "            * save\\_path (str, optional): Save path of the result.\n",
    "            * data (numpy.ndarray): The result of portrait segmentation.\n",
    "\n",
    "    ```python\n",
    "    def video_stream_segment(self,\n",
    "                            frame_org,\n",
    "                            frame_id,\n",
    "                            prev_gray,\n",
    "                            prev_cfd,\n",
    "                            use_gpu=False):\n",
    "    ```\n",
    "\n",
    "    -  Prediction API, used to segment video portraits frame by frame.\n",
    "\n",
    "    - **Parameter**\n",
    "\n",
    "        * frame_org (numpy.ndarray): Single frame for prediction，ndarray.shape is in the format [H, W, C], BGR.\n",
    "        * frame_id (int): The number of the current frame.\n",
    "        * prev_gray (numpy.ndarray): Grayscale image of the previous network input.\n",
    "        * prev_cfd (numpy.ndarray): The fusion image from optical flow and the prediction result from previous frame.\n",
    "        * use\\_gpu (bool): Use GPU or not. **set the CUDA_VISIBLE_DEVICES environment variable first if you are using GPU**\n",
    "\n",
    "    - **Return**\n",
    "\n",
    "        * img_matting (numpy.ndarray): The result of portrait segmentation.\n",
    "        * cur_gray (numpy.ndarray): Grayscale image of the current network input.\n",
    "        * optflow_map (numpy.ndarray): The fusion image from optical flow and the prediction result from current frame.\n",
    "\n",
    "    ```python\n",
    "    def video_segment(self,\n",
    "                      video_path=None,\n",
    "                      use_gpu=False,\n",
    "                      save_dir='humanseg_server_video_result'):\n",
    "    ```\n",
    "\n",
    "    -  Prediction API to produce video segmentation result.\n",
    "\n",
    "    - **Parameter**\n",
    "\n",
    "        * video\\_path (str): Video path for segmentation。If None, the video will be obtained from the local camera, and a window will display the online segmentation result.\n",
    "        * use\\_gpu (bool): Use GPU or not. **set the CUDA_VISIBLE_DEVICES environment variable first if you are using GPU**\n",
    "        * save\\_dir (str): Save path of video.\n",
    "\n",
    "    ```python\n",
    "    def save_inference_model(dirname)\n",
    "    ```\n",
    "\n",
    "    - Save the model to the specified path.\n",
    "\n",
    "    - **Parameters**\n",
    "\n",
    "      * dirname: Model save path."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d70e524",
   "metadata": {
    "id": "iv-server-deployment"
   },
   "source": [
    "## IV. Server Deployment\n",
    "\n",
    "- PaddleHub Serving can deploy an online service of for human segmentation.\n",
    "\n",
    "- ### Step 1: Start PaddleHub Serving\n",
    "\n",
    "    - Run the startup command:\n",
    "\n",
    "        - ```shell\n",
    "          $ hub serving start -m humanseg_server\n",
    "          ```\n",
    "\n",
    "    - The servitization API is now deployed and the default port number is 8866.\n",
    "\n",
    "    - **NOTE:**  If GPU is used for prediction, set CUDA_VISIBLE_DEVICES environment variable before the service, otherwise it need not be set.\n",
    "\n",
    "- ### Step 2: Send a predictive request\n",
    "\n",
    "    - With a configured server, use the following lines of code to send the prediction request and obtain the result\n",
    "\n",
    "     -  ```python\n",
    "        import requests\n",
    "        import json\n",
    "        import base64\n",
    "\n",
    "        import cv2\n",
    "        import numpy as np\n",
    "\n",
    "        def cv2_to_base64(image):\n",
    "            data = cv2.imencode('.jpg', image)[1]\n",
    "            return base64.b64encode(data.tostring()).decode('utf8')\n",
    "        def base64_to_cv2(b64str):\n",
    "            data = base64.b64decode(b64str.encode('utf8'))\n",
    "            data = np.fromstring(data, np.uint8)\n",
    "            data = cv2.imdecode(data, cv2.IMREAD_COLOR)\n",
    "            return data\n",
    "\n",
    "        # Send an HTTP request\n",
    "        org_im = cv2.imread('/PATH/TO/IMAGE')\n",
    "        data = {'images':[cv2_to_base64(org_im)]}\n",
    "        headers = {\"Content-type\": \"application/json\"}\n",
    "        url = \"http://127.0.0.1:8866/predict/humanseg_server\"\n",
    "        r = requests.post(url=url, headers=headers, data=json.dumps(data))\n",
    "\n",
    "        mask =cv2.cvtColor(base64_to_cv2(r.json()[\"results\"][0]['data']), cv2.COLOR_BGR2GRAY)\n",
    "        rgba = np.concatenate((org_im, np.expand_dims(mask, axis=2)), axis=2)\n",
    "        cv2.imwrite(\"segment_human_server.png\", rgba)\n",
    "        ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea89e107",
   "metadata": {
    "id": "v-release-note"
   },
   "source": [
    "## V. Release Note\n",
    "\n",
    "- 1.0.0\n",
    "\n",
    "    First release\n",
    "\n",
    "- 1.1.0\n",
    "\n",
    "    Added video portrait segmentation interface\n",
    "\n",
    "    Added video stream portrait segmentation interface\n",
    "\n",
    "* 1.1.1\n",
    "\n",
    "    Fix memory leakage problem of on cudnn 8.0.4\n",
    "\n",
    "* 1.2.0\n",
    "\n",
    "    Remove Fluid API\n",
    "\n",
    "    ```shell\n",
    "    $ hub install humanseg_server == 1.2.0\n",
    "    ```"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "humanseg_server",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "python3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
