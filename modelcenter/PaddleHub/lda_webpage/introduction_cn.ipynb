{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4904aad1",
   "metadata": {
    "id": "lda_webpage"
   },
   "source": [
    "# lda_webpage\n",
    "\n",
    "|模型名称|lda_webpage|\n",
    "| :--- | :---: |\n",
    "|类别|文本-主题模型|\n",
    "|网络|LDA|\n",
    "|数据集|百度自建网页领域数据集|\n",
    "|是否支持Fine-tuning|否|\n",
    "|模型大小|31MB|\n",
    "|最新更新日期|2021-02-26|\n",
    "|数据指标|-|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9eabd51",
   "metadata": {
    "id": "一-模型基本信息"
   },
   "source": [
    "## 一、模型基本信息\n",
    "\n",
    "- ### 模型介绍\n",
    "\n",
    "  - 主题模型(Topic Model)是以无监督学习的方式对文档的隐含语义结构进行聚类的统计模型，其中LDA(Latent Dirichlet Allocation)算法是主题模型的一种。LDA根据对词的共现信息的分析，拟合出词-文档-主题的分布，从而将词、文本映射到一个语义空间中。\n",
    "\n",
    "  <p align=\"center\">\n",
    "  <img src=\"https://bj.bcebos.com/paddlehub/model/nlp/semantic_model/lda.png\" hspace=\"10\"/> <br/>\n",
    "  </p>\n",
    "\n",
    "  更多详情请参考[LDA论文](http://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf)。\n",
    "\n",
    "  注：该Module由第三方开发者DesmonDay贡献。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0859510",
   "metadata": {
    "id": "二-安装"
   },
   "source": [
    "## 二、安装\n",
    "\n",
    "- ### 1、环境依赖\n",
    "\n",
    "  - paddlepaddle >= 1.8.2\n",
    "\n",
    "  - paddlehub >= 1.8.0    | [如何安装PaddleHub](../../../../docs/docs_ch/get_start/installation.rst)\n",
    "\n",
    "- ### 2、安装\n",
    "\n",
    "  - ```shell\n",
    "    $ hub install lda_webpage\n",
    "    ```\n",
    "  - 如您安装时遇到问题，可参考：[零基础windows安装](../../../../docs/docs_ch/get_start/windows_quickstart.md)\n",
    " | [零基础Linux安装](../../../../docs/docs_ch/get_start/linux_quickstart.md) | [零基础MacOS安装](../../../../docs/docs_ch/get_start/mac_quickstart.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4004057c",
   "metadata": {
    "id": "三-模型api预测"
   },
   "source": [
    "## 三、模型API预测\n",
    "\n",
    "- ### 1、预测代码示例\n",
    "\n",
    "  - #### 查看代码\n",
    "  https://github.com/baidu/Familia\n",
    "\n",
    "- ### 2、API\n",
    "\n",
    "  - ```python\n",
    "    cal_doc_distance(doc_text1, doc_text2)\n",
    "    ```\n",
    "\n",
    "    - 用于计算两个输入文档之间的距离，包括Jensen-Shannon divergence(JS散度)、Hellinger Distance(海林格距离)。\n",
    "\n",
    "    - **参数**\n",
    "\n",
    "      - doc_text1(str): 输入的第一个文档。\n",
    "      - doc_text2(str): 输入的第二个文档。\n",
    "\n",
    "    - **返回**\n",
    "\n",
    "      - jsd(float): 两个文档之间的JS散度([Jensen-Shannon divergence](https://blog.csdn.net/FrankieHello/article/details/80614422?utm_source=copy))。\n",
    "      - hd(float): 两个文档之间的海林格距离([Hellinger Distance](http://blog.sina.com.cn/s/blog_85f1ffb70101e65d.html))。\n",
    "\n",
    "  - ```python\n",
    "    cal_doc_keywords_similarity(document, top_k=10)\n",
    "    ```\n",
    "\n",
    "    - 用于查找输入文档的前k个关键词及对应的与原文档的相似度。\n",
    "\n",
    "    - **参数**\n",
    "\n",
    "      - document(str): 输入文档。\n",
    "      - top_k(int): 查找输入文档的前k个关键词。\n",
    "\n",
    "    - **返回**\n",
    "\n",
    "      - results(list): 包含每个关键词以及对应的与原文档的相似度。其中，list的基本元素为dict，dict的key为关键词，value为对应的与原文档的相似度。\n",
    "\n",
    "  - ```python\n",
    "    cal_query_doc_similarity(query, document)\n",
    "    ```\n",
    "\n",
    "    - 用于计算短文档与长文档之间的相似度。\n",
    "\n",
    "    -  **参数**\n",
    "\n",
    "      - query(str): 输入的短文档。\n",
    "      - document(str): 输入的长文档。\n",
    "\n",
    "    -  **返回**\n",
    "\n",
    "      - lda_sim(float): 返回短文档与长文档之间的相似度。\n",
    "\n",
    "  - ```python\n",
    "    infer_doc_topic_distribution(document)\n",
    "    ```\n",
    "\n",
    "    - 用于推理出文档的主题分布。\n",
    "\n",
    "      - **参数**\n",
    "\n",
    "        - document(str): 输入文档。\n",
    "\n",
    "      - **返回**\n",
    "\n",
    "        - results(list): 包含主题分布下各个主题ID和对应的概率分布。其中，list的基本元素为dict，dict的key为主题ID，value为各个主题ID对应的概率。\n",
    "\n",
    "  - ```python\n",
    "    show_topic_keywords(topic_id, k=10)\n",
    "    ```\n",
    "\n",
    "    - 用于展示出每个主题下对应的关键词，可配合推理主题分布的API使用。\n",
    "\n",
    "      - **参数**\n",
    "\n",
    "        - topic_id(int): 主题ID。\n",
    "        - k(int): 需要知道对应主题的前k个关键词。\n",
    "\n",
    "      - **返回**\n",
    "\n",
    "        - results(dict): 返回对应文档的前k个关键词，以及各个关键词在文档中的出现概率。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7477af39",
   "metadata": {
    "id": "四-更新历史"
   },
   "source": [
    "## 四、更新历史\n",
    "\n",
    "* 1.0.0\n",
    "\n",
    "  初始发布\n",
    "\n",
    "* 1.0.1\n",
    "\n",
    "  修复因为return的bug导致的NoneType错误\n",
    "\n",
    "* 1.0.2\n",
    "\n",
    "  修复由于Windows`gbk`编码导致的问题"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "lda_webpage",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "python3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
