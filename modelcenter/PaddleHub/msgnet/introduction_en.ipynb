{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13898304",
   "metadata": {
    "id": "msgnet"
   },
   "source": [
    "# msgnet\n",
    "\n",
    "|Module Name|msgnet|\n",
    "| :--- | :---: |\n",
    "|Category|Image editing|\n",
    "|Network|msgnet|\n",
    "|Dataset|COCO2014|\n",
    "|Fine-tuning supported or not|Yes|\n",
    "|Module Size|68MB|\n",
    "|Data indicators|-|\n",
    "|Latest update date|2021-07-29|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2675e7",
   "metadata": {
    "id": "i-basic-information"
   },
   "source": [
    "## I. Basic Information\n",
    "\n",
    "- ### Application Effect Display\n",
    "    - Sample results:\n",
    "    <p align=\"center\">\n",
    "    <img src=\"https://user-images.githubusercontent.com/35907364/130910325-d72f34b2-d567-4e77-bb60-35148864301e.jpg\" width=\"450\" height=\"300\" hspace=\"10\"/> <img src=\"https://user-images.githubusercontent.com/35907364/130910195-9433e4a7-3596-4677-85d2-2ffc16939597.png\" width=\"450\" height=\"300\" hspace=\"10\"/>\n",
    "    </p>\n",
    "\n",
    "- ### Module Introduction\n",
    "\n",
    "    - Msgnet is a style transfer model. We will show how to use PaddleHub to finetune the pre-trained model and complete the prediction.\n",
    "    - For more information, please refer to [msgnet](https://github.com/zhanghang1989/PyTorch-Multi-Style-Transfer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd76be5",
   "metadata": {
    "id": "ii-installation"
   },
   "source": [
    "## II. Installation\n",
    "\n",
    "- ### 1、Environmental Dependence\n",
    "\n",
    "    - paddlepaddle >= 2.0.0\n",
    "\n",
    "    - paddlehub >= 2.0.0\n",
    "\n",
    "- ### 2、Installation\n",
    "\n",
    "    - ```shell\n",
    "      $ hub install msgnet\n",
    "      ```\n",
    "\n",
    "    - In case of any problems during installation, please refer to:[Windows_Quickstart](../../../../docs/docs_en/get_start/windows_quickstart.md)\n",
    "    | [Linux_Quickstart](../../../../docs/docs_en/get_start/linux_quickstart.md) | [Mac_Quickstart](../../../../docs/docs_en/get_start/mac_quickstart.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5365582",
   "metadata": {
    "id": "iii-module-api-prediction"
   },
   "source": [
    "## III. Module API Prediction\n",
    "\n",
    "- ### 1、Command line Prediction\n",
    "\n",
    "  - ```\n",
    "    $ hub run msgnet --input_path \"/PATH/TO/ORIGIN/IMAGE\" --style_path \"/PATH/TO/STYLE/IMAGE\"\n",
    "    ```\n",
    "  - If you want to call the Hub module through the command line, please refer to: [PaddleHub Command Line Instruction](../../../../docs/docs_en/tutorial/cmd_usage.rst)\n",
    "\n",
    "- ### 2、Prediction Code Example\n",
    "\n",
    "    -  ```python\n",
    "        import paddle\n",
    "        import paddlehub as hub\n",
    "\n",
    "        if __name__ == '__main__':\n",
    "            model = hub.Module(name='msgnet')\n",
    "            result = model.predict(origin=[\"/PATH/TO/ORIGIN/IMAGE\"], style=\"/PATH/TO/STYLE/IMAGE\", visualization=True, save_path =\"/PATH/TO/SAVE/IMAGE\")\n",
    "        ```\n",
    "\n",
    "- ### 3.Fine-tune and Encapsulation\n",
    "\n",
    "    - After completing the installation of PaddlePaddle and PaddleHub, you can start using the msgnet model to fine-tune datasets such as [MiniCOCO](../../docs/reference/datasets.md#class-hubdatasetsMiniCOCO) by executing `python train.py`.\n",
    "\n",
    "    - Steps:\n",
    "\n",
    "        - Step1: Define the data preprocessing method\n",
    "\n",
    "            - ```python\n",
    "              import paddlehub.vision.transforms as T\n",
    "\n",
    "              transform = T.Compose([T.Resize((256, 256), interpolation='LINEAR')])\n",
    "              ```\n",
    "\n",
    "            - `transforms` The data enhancement module defines lots of data preprocessing methods. Users can replace the data preprocessing methods according to their needs.\n",
    "\n",
    "        - Step2: Download the dataset\n",
    "            - ```python\n",
    "              from paddlehub.datasets.minicoco import MiniCOCO\n",
    "\n",
    "              styledata = MiniCOCO(transform=transform, mode='train')\n",
    "\n",
    "              ```\n",
    "                * `transforms`: data preprocessing methods.\n",
    "                * `mode`: Select the data mode, the options are `train`, `test`, `val`. Default is `train`.\n",
    "\n",
    "                - Dataset preparation can be referred to [minicoco.py](../../paddlehub/datasets/minicoco.py). `hub.datasets.MiniCOCO()` will be automatically downloaded from the network and decompressed to the `$HOME/.paddlehub/dataset` directory under the user directory.\n",
    "\n",
    "        - Step3: Load the pre-trained model\n",
    "\n",
    "            - ```python\n",
    "              model = hub.Module(name='msgnet', load_checkpoint=None)\n",
    "              ```\n",
    "                * `name`: model name.\n",
    "                * `load_checkpoint`: Whether to load the self-trained model, if it is None, load the provided parameters.\n",
    "\n",
    "        - Step4: Optimization strategy\n",
    "\n",
    "            - ```python\n",
    "              optimizer = paddle.optimizer.Adam(learning_rate=0.0001, parameters=model.parameters())\n",
    "              trainer = Trainer(model, optimizer, checkpoint_dir='test_style_ckpt')\n",
    "              trainer.train(styledata, epochs=101, batch_size=4, eval_dataset=styledata, log_interval=10, save_interval=10)\n",
    "              ```\n",
    "\n",
    "    - Model prediction\n",
    "\n",
    "        -   When Fine-tune is completed, the model with the best performance on the verification set will be saved in the `${CHECKPOINT_DIR}/best_model` directory. We use this model to make predictions. The `predict.py` script is as follows:\n",
    "            -   ```python\n",
    "                import paddle\n",
    "                import paddlehub as hub\n",
    "\n",
    "                if __name__ == '__main__':\n",
    "                    model = hub.Module(name='msgnet', load_checkpoint=\"/PATH/TO/CHECKPOINT\")\n",
    "                    result = model.predict(origin=[\"/PATH/TO/ORIGIN/IMAGE\"], style=\"/PATH/TO/STYLE/IMAGE\", visualization=True, save_path =\"/PATH/TO/SAVE/IMAGE\")\n",
    "                ```\n",
    "\n",
    "                - **Parameters**\n",
    "                    * `origin`: Image path or ndarray data with format [H, W, C], BGR.\n",
    "                    * `style`: Style image path.\n",
    "                    * `visualization`: Whether to save the recognition results as picture files.\n",
    "                    * `save_path`: Save path of the result, default is 'style_tranfer'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90966f6",
   "metadata": {
    "id": "iv-server-deployment"
   },
   "source": [
    "## IV. Server Deployment\n",
    "\n",
    "- PaddleHub Serving can deploy an online service of style transfer.\n",
    "\n",
    "- ### Step 1: Start PaddleHub Serving\n",
    "\n",
    "    - Run the startup command:\n",
    "\n",
    "        - ```shell\n",
    "        $ hub serving start -m msgnet\n",
    "        ```\n",
    "\n",
    "    - The servitization API is now deployed and the default port number is 8866.\n",
    "\n",
    "    - **NOTE:**  If GPU is used for prediction, set CUDA_VISIBLE_DEVICES environment variable before the service, otherwise it need not be set.\n",
    "\n",
    "- ### Step 2: Send a predictive request\n",
    "\n",
    "    - With a configured server, use the following lines of code to send the prediction request and obtain the result:\n",
    "\n",
    "        -   ```python\n",
    "            import requests\n",
    "            import json\n",
    "            import cv2\n",
    "            import base64\n",
    "\n",
    "            import numpy as np\n",
    "\n",
    "            def cv2_to_base64(image):\n",
    "                data = cv2.imencode('.jpg', image)[1]\n",
    "                return base64.b64encode(data.tostring()).decode('utf8')\n",
    "\n",
    "            def base64_to_cv2(b64str):\n",
    "                data = base64.b64decode(b64str.encode('utf8'))\n",
    "                data = np.fromstring(data, np.uint8)\n",
    "                data = cv2.imdecode(data, cv2.IMREAD_COLOR)\n",
    "                return data\n",
    "\n",
    "            # Send an HTTP request\n",
    "            org_im = cv2.imread('/PATH/TO/ORIGIN/IMAGE')\n",
    "            style_im = cv2.imread('/PATH/TO/STYLE/IMAGE')\n",
    "            data = {'images':[[cv2_to_base64(org_im)], cv2_to_base64(style_im)]}\n",
    "            headers = {\"Content-type\": \"application/json\"}\n",
    "            url = \"http://127.0.0.1:8866/predict/msgnet\"\n",
    "            r = requests.post(url=url, headers=headers, data=json.dumps(data))\n",
    "            data = base64_to_cv2(r.json()[\"results\"]['data'][0])\n",
    "            cv2.imwrite('style.png', data)\n",
    "            ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a54086",
   "metadata": {
    "id": "v-release-note"
   },
   "source": [
    "## V. Release Note\n",
    "\n",
    "- 1.0.0\n",
    "\n",
    "  First release"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "msgnet",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "python3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
