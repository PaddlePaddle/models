{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1e516e9",
   "metadata": {
    "id": "transformer_en-de"
   },
   "source": [
    "# transformer_en-de\n",
    "\n",
    "|模型名称|transformer_en-de|\n",
    "| :--- | :---: |\n",
    "|类别|文本-机器翻译|\n",
    "|网络|Transformer|\n",
    "|数据集|WMT14 EN-DE|\n",
    "|是否支持Fine-tuning|否|\n",
    "|模型大小|481MB|\n",
    "|最新更新日期|2021-07-21|\n",
    "|数据指标|-|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d039db",
   "metadata": {
    "id": "一-模型基本信息"
   },
   "source": [
    "## 一、模型基本信息\n",
    "\n",
    "- ### 模型介绍\n",
    "\n",
    "  - 2017 年，Google机器翻译团队在其发表的论文[Attention Is All You Need](https://arxiv.org/abs/1706.03762)中，提出了用于完成机器翻译（Machine Translation）等序列到序列（Seq2Seq）学习任务的一种全新网络结构——Transformer。Tranformer网络完全使用注意力（Attention）机制来实现序列到序列的建模，并且取得了很好的效果。\n",
    "\n",
    "  - transformer_en-de包含6层的transformer结构，头数为8，隐藏层参数为512，参数量为64M。该模型在[WMT'14 EN-DE数据集](http://www.statmt.org/wmt14/translation-task.html)进行了预训练，加载后可直接用于预测，提供了英文翻译为德文的能力。\n",
    "\n",
    "  - 关于机器翻译的Transformer模型训练方式和详情，可查看[Machine Translation using Transformer](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/examples/machine_translation/transformer)。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9228a1af",
   "metadata": {
    "id": "二-安装"
   },
   "source": [
    "## 二、安装\n",
    "\n",
    "- ### 1、环境依赖\n",
    "\n",
    "  - paddlepaddle >= 2.1.0\n",
    "\n",
    "  - paddlehub >= 2.1.0    | [如何安装PaddleHub](../../../../docs/docs_ch/get_start/installation.rst)\n",
    "\n",
    "- ### 2、安装\n",
    "\n",
    "  - ```shell\n",
    "    $ hub install transformer_en-de\n",
    "    ```\n",
    "  - 如您安装时遇到问题，可参考：[零基础windows安装](../../../../docs/docs_ch/get_start/windows_quickstart.md)\n",
    " | [零基础Linux安装](../../../../docs/docs_ch/get_start/linux_quickstart.md) | [零基础MacOS安装](../../../../docs/docs_ch/get_start/mac_quickstart.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129986a8",
   "metadata": {
    "id": "三-模型api预测"
   },
   "source": [
    "## 三、模型API预测\n",
    "\n",
    "- ### 1、预测代码示例\n",
    "\n",
    "  - ```python\n",
    "    import paddlehub as hub\n",
    "\n",
    "    model = hub.Module(name='transformer_en-de', beam_size=5)\n",
    "    src_texts = [\n",
    "        'What are you doing now?',\n",
    "        'The change was for the better; I eat well, I exercise, I take my drugs.',\n",
    "        'Such experiments are not conducted for ethical reasons.',\n",
    "    ]\n",
    "\n",
    "    n_best = 3  # 每个输入样本的输出候选句子数量\n",
    "    trg_texts = model.predict(src_texts, n_best=n_best)\n",
    "    for idx, st in enumerate(src_texts):\n",
    "        print('-'*30)\n",
    "        print(f'src: {st}')\n",
    "        for i in range(n_best):\n",
    "            print(f'trg[{i+1}]: {trg_texts[idx*n_best+i]}')\n",
    "    ```\n",
    "\n",
    "- ### 2、API\n",
    "\n",
    "  - ```python\n",
    "    def __init__(max_length: int = 256,\n",
    "             max_out_len: int = 256,\n",
    "             beam_size: int = 5):\n",
    "    ```\n",
    "\n",
    "    - 初始化module，可配置模型的输入输出文本的最大长度和解码时beam search的宽度。\n",
    "\n",
    "    - **参数**\n",
    "\n",
    "      - `max_length`(int): 输入文本的最大长度，默认值为256。\n",
    "      - `max_out_len`(int): 输出文本的最大解码长度，默认值为256。\n",
    "      - `beam_size`(int): beam search方式解码的beam宽度，默认为5。\n",
    "\n",
    "  - ```python\n",
    "    def predict(data: List[str],\n",
    "            batch_size: int = 1,\n",
    "            n_best: int = 1,\n",
    "            use_gpu: bool = False):\n",
    "    ```\n",
    "\n",
    "    - 预测API，输入源语言的文本句子，解码后输出翻译后的目标语言的文本候选句子。\n",
    "\n",
    "    - **参数**\n",
    "\n",
    "      - `data`(List[str]): 源语言的文本列表，数据类型为List[str]\n",
    "      - `batch_size`(int): 进行预测的batch_size，默认为1\n",
    "      - `n_best`(int): 每个输入文本经过模型解码后，输出的得分最高的候选句子的数量，必须小于beam_size，默认为1\n",
    "      - `use_gpu`(bool): 是否使用gpu执行预测，默认为False\n",
    "\n",
    "    - **返回**\n",
    "\n",
    "      - `results`(List[str]): 翻译后的目标语言的候选句子，长度为`len(data)*n_best`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4496355f",
   "metadata": {
    "id": "四-服务部署"
   },
   "source": [
    "## 四、服务部署\n",
    "\n",
    "- 通过启动PaddleHub Serving，可以加载模型部署在线翻译服务。\n",
    "\n",
    "- ### 第一步：启动PaddleHub Serving\n",
    "\n",
    "  - 运行启动命令：\n",
    "\n",
    "  - ```shell\n",
    "    $ hub serving start -m transformer_en-de\n",
    "    ```\n",
    "\n",
    "  - 通过以上命令可完成一个英德机器翻译API的部署，默认端口号为8866。\n",
    "\n",
    "  - **NOTE:** 如使用GPU预测，则需要在启动服务之前，请设置CUDA_VISIBLE_DEVICES环境变量，否则不用设置。\n",
    "\n",
    "- ## 第二步：发送预测请求\n",
    "\n",
    "  - 配置好服务端，以下数行代码即可实现发送预测请求，获取预测结果\n",
    "\n",
    "  - ```python\n",
    "    import requests\n",
    "    import json\n",
    "\n",
    "    texts = [\n",
    "        'What are you doing now?',\n",
    "        'The change was for the better; I eat well, I exercise, I take my drugs.',\n",
    "        'Such experiments are not conducted for ethical reasons.',\n",
    "    ]\n",
    "    data = {\"data\": texts}\n",
    "    # 发送post请求，content-type类型应指定json方式，url中的ip地址需改为对应机器的ip\n",
    "    url = \"http://127.0.0.1:8866/predict/transformer_en-de\"\n",
    "    # 指定post请求的headers为application/json方式\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "    r = requests.post(url=url, headers=headers, data=json.dumps(data))\n",
    "    print(r.json())\n",
    "    ```\n",
    "\n",
    "  - 关于PaddleHub Serving更多信息参考：[服务部署](../../../../docs/docs_ch/tutorial/serving.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a45bbe",
   "metadata": {
    "id": "五-更新历史"
   },
   "source": [
    "## 五、更新历史\n",
    "\n",
    "* 1.0.0\n",
    "\n",
    "  初始发布\n",
    "\n",
    "* 1.0.1\n",
    "\n",
    "  修复模型初始化的兼容性问题\n",
    "  - ```shell\n",
    "    $ hub install transformer_en-de==1.0.1\n",
    "    ```"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "transformer_en-de",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "python3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
