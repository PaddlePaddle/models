{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31a999bb",
   "metadata": {
    "id": "deepspeech2_aishell"
   },
   "source": [
    "# deepspeech2_aishell\n",
    "\n",
    "|模型名称|deepspeech2_aishell|\n",
    "| :--- | :---: |\n",
    "|类别|语音-语音识别|\n",
    "|网络|DeepSpeech2|\n",
    "|数据集|AISHELL-1|\n",
    "|是否支持Fine-tuning|否|\n",
    "|模型大小|306MB|\n",
    "|最新更新日期|2021-10-20|\n",
    "|数据指标|中文CER 0.065|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37819987",
   "metadata": {
    "id": "一-模型基本信息"
   },
   "source": [
    "## 一、模型基本信息"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f969d76",
   "metadata": {
    "id": "模型介绍"
   },
   "source": [
    "### 模型介绍\n",
    "\n",
    "DeepSpeech2是百度于2015年提出的适用于英文和中文的end-to-end语音识别模型。deepspeech2_aishell使用了DeepSpeech2离线模型的结构，模型主要由2层卷积网络和3层GRU组成，并在中文普通话开源语音数据集[AISHELL-1](http://www.aishelltech.com/kysjcp)进行了预训练，该模型在其测试集上的CER指标是0.065。\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://raw.githubusercontent.com/PaddlePaddle/DeepSpeech/Hub/docs/images/ds2offlineModel.png\" hspace=\"10\"/> <br/>\n",
    "</p>\n",
    "\n",
    "更多详情请参考[Deep Speech 2: End-to-End Speech Recognition in English and Mandarin](https://arxiv.org/abs/1512.02595)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372be869",
   "metadata": {
    "id": "二-安装"
   },
   "source": [
    "## 二、安装\n",
    "\n",
    "- ### 1、系统依赖\n",
    "\n",
    "  - libsndfile, swig >= 3.0\n",
    "    - Linux\n",
    "      ```shell\n",
    "      $ sudo apt-get install libsndfile swig\n",
    "      or\n",
    "      $ sudo yum install libsndfile swig\n",
    "      ```\n",
    "    - MacOs\n",
    "      ```\n",
    "      $ brew install libsndfile swig\n",
    "      ```\n",
    "\n",
    "- ### 2、环境依赖\n",
    "  - swig_decoder:\n",
    "    ```\n",
    "    git clone https://github.com/PaddlePaddle/DeepSpeech.git &amp;&amp; cd DeepSpeech &amp;&amp; git reset --hard b53171694e7b87abe7ea96870b2f4d8e0e2b1485 &amp;&amp; cd deepspeech/decoders/ctcdecoder/swig &amp;&amp; sh setup.sh\n",
    "    ```\n",
    "\n",
    "  - paddlepaddle >= 2.1.0\n",
    "\n",
    "  - paddlehub >= 2.1.0    | [如何安装PaddleHub](../../../../docs/docs_ch/get_start/installation.rst)\n",
    "\n",
    "- ### 3、安装\n",
    "\n",
    "  - ```shell\n",
    "    $ hub install deepspeech2_aishell\n",
    "    ```\n",
    "  - 如您安装时遇到问题，可参考：[零基础windows安装](../../../../docs/docs_ch/get_start/windows_quickstart.md)\n",
    " | [零基础Linux安装](../../../../docs/docs_ch/get_start/linux_quickstart.md) | [零基础MacOS安装](../../../../docs/docs_ch/get_start/mac_quickstart.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c5a01d",
   "metadata": {
    "id": "三-模型api预测"
   },
   "source": [
    "## 三、模型API预测\n",
    "\n",
    "- ### 1、预测代码示例\n",
    "\n",
    "    ```python\n",
    "    import paddlehub as hub\n",
    "\n",
    "    # 采样率为16k，格式为wav的中文语音音频\n",
    "    wav_file = '/PATH/TO/AUDIO'\n",
    "\n",
    "    model = hub.Module(\n",
    "        name='deepspeech2_aishell',\n",
    "        version='1.0.0')\n",
    "    text = model.speech_recognize(wav_file)\n",
    "\n",
    "    print(text)\n",
    "    ```\n",
    "\n",
    "- ### 2、API\n",
    "  - ```python\n",
    "    def check_audio(audio_file)\n",
    "    ```\n",
    "    - 检查输入音频格式和采样率是否满足为16000\n",
    "\n",
    "    - **参数**\n",
    "\n",
    "      - `audio_file`：本地音频文件(*.wav)的路径，如`/path/to/input.wav`\n",
    "\n",
    "  - ```python\n",
    "    def speech_recognize(\n",
    "        audio_file,\n",
    "        device='cpu',\n",
    "    )\n",
    "    ```\n",
    "    - 将输入的音频识别成文字\n",
    "\n",
    "    - **参数**\n",
    "\n",
    "      - `audio_file`：本地音频文件(*.wav)的路径，如`/path/to/input.wav`\n",
    "      - `device`：预测时使用的设备，默认为`cpu`，如需使用gpu预测，请设置为`gpu`。\n",
    "\n",
    "    - **返回**\n",
    "\n",
    "      - `text`：str类型，返回输入音频的识别文字结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9e574a",
   "metadata": {
    "id": "四-服务部署"
   },
   "source": [
    "## 四、服务部署\n",
    "\n",
    "- PaddleHub Serving可以部署一个在线的语音识别服务。\n",
    "\n",
    "- ### 第一步：启动PaddleHub Serving\n",
    "\n",
    "  - ```shell\n",
    "    $ hub serving start -m deepspeech2_aishell\n",
    "    ```\n",
    "\n",
    "  - 这样就完成了一个语音识别服务化API的部署，默认端口号为8866。\n",
    "\n",
    "  - **NOTE:** 如使用GPU预测，则需要在启动服务之前，请设置CUDA_VISIBLE_DEVICES环境变量，否则不用设置。\n",
    "\n",
    "- ### 第二步：发送预测请求\n",
    "\n",
    "  - 配置好服务端，以下数行代码即可实现发送预测请求，获取预测结果\n",
    "\n",
    "  - ```python\n",
    "    import requests\n",
    "    import json\n",
    "\n",
    "    # 需要识别的音频的存放路径，确保部署服务的机器可访问\n",
    "    file = '/path/to/input.wav'\n",
    "\n",
    "    # 以key的方式指定text传入预测方法的时的参数，此例中为\"audio_file\"\n",
    "    data = {\"audio_file\": file}\n",
    "\n",
    "    # 发送post请求，content-type类型应指定json方式，url中的ip地址需改为对应机器的ip\n",
    "    url = \"http://127.0.0.1:8866/predict/deepspeech2_aishell\"\n",
    "\n",
    "    # 指定post请求的headers为application/json方式\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "    r = requests.post(url=url, headers=headers, data=json.dumps(data))\n",
    "    print(r.json())\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b9de78",
   "metadata": {
    "id": "五-更新历史"
   },
   "source": [
    "## 五、更新历史\n",
    "\n",
    "* 1.0.0\n",
    "\n",
    "  初始发布\n",
    "\n",
    "  ```shell\n",
    "  $ hub install deepspeech2_aishell\n",
    "  ```"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "deepspeech2_aishell",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "python3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
