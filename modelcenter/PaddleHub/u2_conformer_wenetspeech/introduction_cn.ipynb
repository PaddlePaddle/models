{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b2538d0",
   "metadata": {
    "id": "u2_conformer_wenetspeech"
   },
   "source": [
    "# u2_conformer_wenetspeech\n",
    "\n",
    "|模型名称|u2_conformer_wenetspeech|\n",
    "| :--- | :---: |\n",
    "|类别|语音-语音识别|\n",
    "|网络|Conformer|\n",
    "|数据集|WenetSpeech|\n",
    "|是否支持Fine-tuning|否|\n",
    "|模型大小|494MB|\n",
    "|最新更新日期|2021-12-10|\n",
    "|数据指标|中文CER 0.087 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8e624d",
   "metadata": {
    "id": "一-模型基本信息"
   },
   "source": [
    "## 一、模型基本信息"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adf9a9f",
   "metadata": {
    "id": "模型介绍"
   },
   "source": [
    "### 模型介绍\n",
    "\n",
    "U2 Conformer模型是一种适用于英文和中文的end-to-end语音识别模型。u2_conformer_wenetspeech采用了conformer的encoder和transformer的decoder的模型结构，并且使用了ctc-prefix beam search的方式进行一遍打分，再利用attention decoder进行二次打分的方式进行解码来得到最终结果。\n",
    "\n",
    "u2_conformer_wenetspeech在中文普通话开源语音数据集[WenetSpeech](https://wenet-e2e.github.io/WenetSpeech/)进行了预训练，该模型在其DEV测试集上的CER指标是0.087。\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://paddlehub.bj.bcebos.com/paddlehub-img/conformer.png\" hspace=\"10\"/> <br/>\n",
    "</p>\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://paddlehub.bj.bcebos.com/paddlehub-img/u2_conformer.png\" hspace=\"10\"/> <br/>\n",
    "</p>\n",
    "\n",
    "更多详情请参考:\n",
    "- [Unified Streaming and Non-streaming Two-pass End-to-end Model for Speech Recognition](https://arxiv.org/abs/2012.05481)\n",
    "- [Conformer: Convolution-augmented Transformer for Speech Recognition](https://arxiv.org/abs/2005.08100)\n",
    "- [WenetSpeech: A 10000+ Hours Multi-domain Mandarin Corpus for Speech Recognition](https://arxiv.org/abs/2110.03370)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40627adc",
   "metadata": {
    "id": "二-安装"
   },
   "source": [
    "## 二、安装\n",
    "\n",
    "- ### 1、系统依赖\n",
    "\n",
    "  - libsndfile\n",
    "    - Linux\n",
    "      ```shell\n",
    "      $ sudo apt-get install libsndfile\n",
    "      or\n",
    "      $ sudo yum install libsndfile\n",
    "      ```\n",
    "    - MacOs\n",
    "      ```\n",
    "      $ brew install libsndfile\n",
    "      ```\n",
    "\n",
    "- ### 2、环境依赖\n",
    "\n",
    "  - paddlepaddle >= 2.2.0\n",
    "\n",
    "  - paddlehub >= 2.1.0    | [如何安装PaddleHub](../../../../docs/docs_ch/get_start/installation.rst)\n",
    "\n",
    "- ### 3、安装\n",
    "\n",
    "  - ```shell\n",
    "    $ hub install u2_conformer_wenetspeech\n",
    "    ```\n",
    "  - 如您安装时遇到问题，可参考：[零基础windows安装](../../../../docs/docs_ch/get_start/windows_quickstart.md)\n",
    " | [零基础Linux安装](../../../../docs/docs_ch/get_start/linux_quickstart.md) | [零基础MacOS安装](../../../../docs/docs_ch/get_start/mac_quickstart.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2998f3db",
   "metadata": {
    "id": "三-模型api预测"
   },
   "source": [
    "## 三、模型API预测\n",
    "\n",
    "- ### 1、预测代码示例\n",
    "\n",
    "    ```python\n",
    "    import paddlehub as hub\n",
    "\n",
    "    # 采样率为16k，格式为wav的中文语音音频\n",
    "    wav_file = '/PATH/TO/AUDIO'\n",
    "\n",
    "    model = hub.Module(\n",
    "        name='u2_conformer_wenetspeech',\n",
    "        version='1.0.0')\n",
    "    text = model.speech_recognize(wav_file)\n",
    "\n",
    "    print(text)\n",
    "    ```\n",
    "\n",
    "- ### 2、API\n",
    "  - ```python\n",
    "    def check_audio(audio_file)\n",
    "    ```\n",
    "    - 检查输入音频格式和采样率是否满足为16000，如果不满足，则重新采样至16000并将新的音频文件保存至相同目录。\n",
    "\n",
    "    - **参数**\n",
    "\n",
    "      - `audio_file`：本地音频文件(*.wav)的路径，如`/path/to/input.wav`\n",
    "\n",
    "  - ```python\n",
    "    def speech_recognize(\n",
    "        audio_file,\n",
    "        device='cpu',\n",
    "    )\n",
    "    ```\n",
    "    - 将输入的音频识别成文字\n",
    "\n",
    "    - **参数**\n",
    "\n",
    "      - `audio_file`：本地音频文件(*.wav)的路径，如`/path/to/input.wav`\n",
    "      - `device`：预测时使用的设备，默认为`cpu`，如需使用gpu预测，请设置为`gpu`。\n",
    "\n",
    "    - **返回**\n",
    "\n",
    "      - `text`：str类型，返回输入音频的识别文字结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd340000",
   "metadata": {
    "id": "四-服务部署"
   },
   "source": [
    "## 四、服务部署\n",
    "\n",
    "- PaddleHub Serving可以部署一个在线的语音识别服务。\n",
    "\n",
    "- ### 第一步：启动PaddleHub Serving\n",
    "\n",
    "  - ```shell\n",
    "    $ hub serving start -m u2_conformer_wenetspeech\n",
    "    ```\n",
    "\n",
    "  - 这样就完成了一个语音识别服务化API的部署，默认端口号为8866。\n",
    "\n",
    "  - **NOTE:** 如使用GPU预测，则需要在启动服务之前，请设置CUDA_VISIBLE_DEVICES环境变量，否则不用设置。\n",
    "\n",
    "- ### 第二步：发送预测请求\n",
    "\n",
    "  - 配置好服务端，以下数行代码即可实现发送预测请求，获取预测结果\n",
    "\n",
    "  - ```python\n",
    "    import requests\n",
    "    import json\n",
    "\n",
    "    # 需要识别的音频的存放路径，确保部署服务的机器可访问\n",
    "    file = '/path/to/input.wav'\n",
    "\n",
    "    # 以key的方式指定text传入预测方法的时的参数，此例中为\"audio_file\"\n",
    "    data = {\"audio_file\": file}\n",
    "\n",
    "    # 发送post请求，content-type类型应指定json方式，url中的ip地址需改为对应机器的ip\n",
    "    url = \"http://127.0.0.1:8866/predict/u2_conformer_wenetspeech\"\n",
    "\n",
    "    # 指定post请求的headers为application/json方式\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "    r = requests.post(url=url, headers=headers, data=json.dumps(data))\n",
    "    print(r.json())\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbe92a5",
   "metadata": {
    "id": "五-更新历史"
   },
   "source": [
    "## 五、更新历史\n",
    "\n",
    "* 1.0.0\n",
    "\n",
    "  初始发布\n",
    "\n",
    "  ```shell\n",
    "  $ hub install u2_conformer_wenetspeech\n",
    "  ```"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "u2_conformer_wenetspeech",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "python3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
