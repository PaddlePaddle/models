{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55903e0e-3e6d-430f-91b7-d270a953ffd7",
   "metadata": {},
   "source": [
    "## 1. PP-HumanSegV2模型简介\n",
    "\n",
    "将人物和背景在像素级别进行区分，是一个图像分割的经典任务，具有广泛的应用。 一般而言，该任务可以分为两类：针对半身人像的分割，简称肖像分割；针对全身和半身人像的分割，简称通用人像分割。\n",
    "\n",
    "对于肖像分割和通用人像分割，PaddleSeg发布了PP-HumanSeg系列模型，具有分割精度高、推理速度快、通用型强的优点。而且PP-HumanSeg系列模型可以开箱即用，零成本部署到产品中，也支持针对特定场景数据进行微调，实现更佳分割效果。\n",
    "\n",
    "2022年7月，PaddleSeg重磅升级的PP-HumanSegV2人像分割方案，以96.63%的mIoU精度， 63FPS的手机端推理速度，再次刷新开源人像分割算法SOTA指标。相比PP-HumanSegV1方案，推理速度提升87.15%，分割精度提升3.03%，可视化效果更佳。V2方案可与商业收费方案媲美，而且支持零成本、开箱即用！\n",
    "\n",
    "PP-HumanSeg由飞桨官方出品，是PaddleSeg团队推出的模型和方案。 更多关于PaddleSeg可以点击 https://github.com/PaddlePaddle/PaddleSeg 进行了解。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba317a85-c8a1-49bd-afa3-59bfad7e86c3",
   "metadata": {},
   "source": [
    "## 2. 模型效果及应用场景\n",
    "### 2.1 肖像分割和通用人像分割任务\n",
    "\n",
    "#### 2.1.1 数据集\n",
    "\n",
    "数据集以PP-HumanSeg14k为主，分为训练集和测试集。\n",
    "\n",
    "#### 2.1.2 模型效果速览\n",
    "\n",
    "PP-HumanSegV2在图片上的分割效果如下。\n",
    "\n",
    "原图：\n",
    "<div align=\"center\">\n",
    "<img src=\"https://user-images.githubusercontent.com/48357642/200734740-72e98c73-5b41-47c4-b208-7fd9c10d8b8a.jpeg\"  width = \"60%\"  />\n",
    "</div>\n",
    "\n",
    "\n",
    "分割后的图：\n",
    "<div align=\"center\">\n",
    "<img src=\"https://user-images.githubusercontent.com/48357642/200735017-eb8a2b22-7ef9-4e4f-acc2-1ea538672f75.jpeg\"  width = \"60%\"  />\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9668da-d14a-4491-ab01-7b039399bff6",
   "metadata": {},
   "source": [
    "## 3. 模型如何使用\n",
    "\n",
    "### 3.1 模型推理\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e98dbf-a3ba-4d6c-8bde-b1abb469c7b2",
   "metadata": {},
   "source": [
    "* 安装PaddlePaddle\n",
    "\n",
    "安装PaddlePaddle，要求PaddlePaddle >= 2.2.0。由于图像分割模型计算开销大，推荐在GPU版本的PaddlePaddle下使用。\n",
    "\n",
    "在AIStudio中，大家选择可以直接选择安装好PaddlePaddle的环境。\n",
    "如果需要执行安装PaddlePaddle，请参考[PaddlePaddle官网](https://www.paddlepaddle.org.cn/install/quick?docurl=/documentation/docs/zh/install/pip/linux-pip.html)。\n",
    "\n",
    "本教程在PaddlePaddle 2.3.2版本下进行了验证。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2e25c6-6943-4d6a-b809-5f49158a5619",
   "metadata": {},
   "source": [
    "* 下载PaddleSeg \n",
    "\n",
    "（不在Jupyter Notebook上运行时需要将\"！\"或者\"%\"去掉。）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c587ea0-52d6-48c2-b2cc-beae58b3262d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T09:33:52.497346Z",
     "iopub.status.busy": "2022-11-09T09:33:52.496728Z",
     "iopub.status.idle": "2022-11-09T09:37:21.171565Z",
     "shell.execute_reply": "2022-11-09T09:37:21.170520Z",
     "shell.execute_reply.started": "2022-11-09T09:33:52.497310Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio\n",
      "正克隆到 'PaddleSeg'...\n",
      "remote: Enumerating objects: 20171, done.\u001b[K\n",
      "remote: Counting objects: 100% (5140/5140), done.\u001b[K\n",
      "remote: Compressing objects: 100% (2425/2425), done.\u001b[K\n",
      "remote: Total 20171 (delta 3243), reused 4335 (delta 2647), pack-reused 15031\u001b[K\n",
      "接收对象中: 100% (20171/20171), 345.54 MiB | 1.46 MiB/s, 完成.\n",
      "处理 delta 中: 100% (13103/13103), 完成.\n",
      "检查连接... 完成。\n"
     ]
    }
   ],
   "source": [
    "%cd ~\n",
    "\n",
    "!git clone https://gitee.com/PaddlePaddle/PaddleSeg.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc9e04c-070f-48c3-bd6f-1fcacafb4e1f",
   "metadata": {},
   "source": [
    "* 安装PaddleSeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f7a0af6-4968-4966-b27e-130d70c94886",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T09:37:31.743869Z",
     "iopub.status.busy": "2022-11-09T09:37:31.742765Z",
     "iopub.status.idle": "2022-11-09T09:37:39.709050Z",
     "shell.execute_reply": "2022-11-09T09:37:39.708035Z",
     "shell.execute_reply.started": "2022-11-09T09:37:31.743831Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio/PaddleSeg\n",
      "Using pip 22.1.2 from /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/pip (python 3.7)\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Obtaining file:///home/aistudio/PaddleSeg\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l  Running command python setup.py egg_info\n",
      "  /home/aistudio/PaddleSeg/paddleseg/models/losses/rmi_loss.py:78: DeprecationWarning: invalid escape sequence \\i\n",
      "    \"\"\"\n",
      "  running egg_info\n",
      "  creating /tmp/pip-pip-egg-info-gc0tcpql/paddleseg.egg-info\n",
      "  writing /tmp/pip-pip-egg-info-gc0tcpql/paddleseg.egg-info/PKG-INFO\n",
      "  writing dependency_links to /tmp/pip-pip-egg-info-gc0tcpql/paddleseg.egg-info/dependency_links.txt\n",
      "  writing requirements to /tmp/pip-pip-egg-info-gc0tcpql/paddleseg.egg-info/requires.txt\n",
      "  writing top-level names to /tmp/pip-pip-egg-info-gc0tcpql/paddleseg.egg-info/top_level.txt\n",
      "  writing manifest file '/tmp/pip-pip-egg-info-gc0tcpql/paddleseg.egg-info/SOURCES.txt'\n",
      "  adding license file 'LICENSE' (matched pattern 'LICEN[CS]E*')\n",
      "  reading manifest file '/tmp/pip-pip-egg-info-gc0tcpql/paddleseg.egg-info/SOURCES.txt'\n",
      "  writing manifest file '/tmp/pip-pip-egg-info-gc0tcpql/paddleseg.egg-info/SOURCES.txt'\n",
      "\u001b[?25hdone\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddleseg==2.6.0) (5.1.2)\n",
      "Requirement already satisfied: visualdl>=2.2.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddleseg==2.6.0) (2.4.0)\n",
      "Requirement already satisfied: opencv-python in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddleseg==2.6.0) (4.1.1.26)\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddleseg==2.6.0) (4.27.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddleseg==2.6.0) (3.0.12)\n",
      "Requirement already satisfied: scipy in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddleseg==2.6.0) (1.6.3)\n",
      "Requirement already satisfied: prettytable in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddleseg==2.6.0) (0.7.2)\n",
      "Requirement already satisfied: sklearn in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddleseg==2.6.0) (0.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.2.0->paddleseg==2.6.0) (1.1.5)\n",
      "Requirement already satisfied: flask>=1.1.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.2.0->paddleseg==2.6.0) (1.1.1)\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.2.0->paddleseg==2.6.0) (1.16.0)\n",
      "Requirement already satisfied: Flask-Babel>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.2.0->paddleseg==2.6.0) (1.0.0)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.2.0->paddleseg==2.6.0) (2.2.3)\n",
      "Requirement already satisfied: bce-python-sdk in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.2.0->paddleseg==2.6.0) (0.8.53)\n",
      "Requirement already satisfied: Pillow>=7.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.2.0->paddleseg==2.6.0) (8.2.0)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.2.0->paddleseg==2.6.0) (2.24.0)\n",
      "Requirement already satisfied: protobuf>=3.11.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.2.0->paddleseg==2.6.0) (3.20.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.2.0->paddleseg==2.6.0) (1.19.5)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from sklearn->paddleseg==2.6.0) (0.24.2)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl>=2.2.0->paddleseg==2.6.0) (0.16.0)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl>=2.2.0->paddleseg==2.6.0) (1.1.0)\n",
      "Requirement already satisfied: click>=5.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl>=2.2.0->paddleseg==2.6.0) (7.0)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl>=2.2.0->paddleseg==2.6.0) (3.0.0)\n",
      "Requirement already satisfied: pytz in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl>=2.2.0->paddleseg==2.6.0) (2019.3)\n",
      "Requirement already satisfied: Babel>=2.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl>=2.2.0->paddleseg==2.6.0) (2.8.0)\n",
      "Requirement already satisfied: pycryptodome>=3.8.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl>=2.2.0->paddleseg==2.6.0) (3.9.9)\n",
      "Requirement already satisfied: future>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl>=2.2.0->paddleseg==2.6.0) (0.18.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl>=2.2.0->paddleseg==2.6.0) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl>=2.2.0->paddleseg==2.6.0) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl>=2.2.0->paddleseg==2.6.0) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl>=2.2.0->paddleseg==2.6.0) (1.1.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.2.0->paddleseg==2.6.0) (1.25.6)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.2.0->paddleseg==2.6.0) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.2.0->paddleseg==2.6.0) (2019.9.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.2.0->paddleseg==2.6.0) (2.8)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn->sklearn->paddleseg==2.6.0) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn->sklearn->paddleseg==2.6.0) (0.14.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0.0rc2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Jinja2>=2.10.1->flask>=1.1.1->visualdl>=2.2.0->paddleseg==2.6.0) (2.0.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->visualdl>=2.2.0->paddleseg==2.6.0) (56.2.0)\n",
      "Installing collected packages: paddleseg\n",
      "  Running setup.py develop for paddleseg\n",
      "    Running command python setup.py develop\n",
      "    running develop\n",
      "    running egg_info\n",
      "    creating paddleseg.egg-info\n",
      "    writing paddleseg.egg-info/PKG-INFO\n",
      "    writing dependency_links to paddleseg.egg-info/dependency_links.txt\n",
      "    writing requirements to paddleseg.egg-info/requires.txt\n",
      "    writing top-level names to paddleseg.egg-info/top_level.txt\n",
      "    writing manifest file 'paddleseg.egg-info/SOURCES.txt'\n",
      "    adding license file 'LICENSE' (matched pattern 'LICEN[CS]E*')\n",
      "    reading manifest file 'paddleseg.egg-info/SOURCES.txt'\n",
      "    writing manifest file 'paddleseg.egg-info/SOURCES.txt'\n",
      "    running build_ext\n",
      "    Creating /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddleseg.egg-link (link to .)\n",
      "    Adding paddleseg 2.6.0 to easy-install.pth file\n",
      "\n",
      "    Installed /home/aistudio/PaddleSeg\n",
      "Successfully installed paddleseg-2.6.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 安装PaddleSeg\n",
    "%cd ~/PaddleSeg\n",
    "!pip install -v -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96376cd0-99d1-4f28-8521-94e541e065e2",
   "metadata": {},
   "source": [
    "* 下载数据和模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d7f3c8f-bf9b-4a4a-b7dd-9374c4fd2c9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T09:37:45.234871Z",
     "iopub.status.busy": "2022-11-09T09:37:45.234258Z",
     "iopub.status.idle": "2022-11-09T09:38:23.575189Z",
     "shell.execute_reply": "2022-11-09T09:38:23.574161Z",
     "shell.execute_reply.started": "2022-11-09T09:37:45.234834Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio/PaddleSeg/contrib/PP-HumanSeg\n",
      "Connecting to https://paddleseg.bj.bcebos.com/dygraph/pp_humanseg_v2/portrait_pp_humansegv1_lite_398x224_inference_model_with_softmax.zip\n",
      "Downloading portrait_pp_humansegv1_lite_398x224_inference_model_with_softmax.zip\n",
      "[==================================================] 100.00%\n",
      "Uncompress portrait_pp_humansegv1_lite_398x224_inference_model_with_softmax.zip\n",
      "[==================================================] 100.00%\n",
      "Connecting to https://paddleseg.bj.bcebos.com/dygraph/pp_humanseg_v2/portrait_pp_humansegv2_lite_256x144_smaller/portrait_pp_humansegv2_lite_256x144_inference_model_with_softmax.zip\n",
      "Downloading portrait_pp_humansegv2_lite_256x144_inference_model_with_softmax.zip\n",
      "[==================================================] 100.00%\n",
      "Uncompress portrait_pp_humansegv2_lite_256x144_inference_model_with_softmax.zip\n",
      "[==================================================] 100.00%\n",
      "Connecting to https://paddleseg.bj.bcebos.com/dygraph/pp_humanseg_v2/human_pp_humansegv1_lite_192x192_inference_model_with_softmax.zip\n",
      "Downloading human_pp_humansegv1_lite_192x192_inference_model_with_softmax.zip\n",
      "[==================================================] 100.00%\n",
      "Uncompress human_pp_humansegv1_lite_192x192_inference_model_with_softmax.zip\n",
      "[==================================================] 100.00%\n",
      "Connecting to https://paddleseg.bj.bcebos.com/dygraph/pp_humanseg_v2/human_pp_humansegv2_lite_192x192_inference_model_with_softmax.zip\n",
      "Downloading human_pp_humansegv2_lite_192x192_inference_model_with_softmax.zip\n",
      "[==================================================] 100.00%\n",
      "Uncompress human_pp_humansegv2_lite_192x192_inference_model_with_softmax.zip\n",
      "[==================================================] 100.00%\n",
      "Connecting to https://paddleseg.bj.bcebos.com/dygraph/pp_humanseg_v2/human_pp_humansegv1_mobile_192x192_inference_model_with_softmax.zip\n",
      "Downloading human_pp_humansegv1_mobile_192x192_inference_model_with_softmax.zip\n",
      "[==================================================] 100.00%\n",
      "Uncompress human_pp_humansegv1_mobile_192x192_inference_model_with_softmax.zip\n",
      "[==================================================] 100.00%\n",
      "Connecting to https://paddleseg.bj.bcebos.com/dygraph/pp_humanseg_v2/human_pp_humansegv2_mobile_192x192_inference_model_with_softmax.zip\n",
      "Downloading human_pp_humansegv2_mobile_192x192_inference_model_with_softmax.zip\n",
      "[==================================================] 100.00%\n",
      "Uncompress human_pp_humansegv2_mobile_192x192_inference_model_with_softmax.zip\n",
      "[==================================================] 100.00%\n",
      "Download inference models finished.\n",
      "Connecting to https://paddleseg.bj.bcebos.com/humanseg/data/mini_supervisely.zip\n",
      "Downloading mini_supervisely.zip\n",
      "[==================================================] 100.00%\n",
      "Uncompress mini_supervisely.zip\n",
      "[==================================================] 100.00%\n",
      "Connecting to https://paddleseg.bj.bcebos.com/dygraph/pp_humanseg_v2/videos.zip\n",
      "Downloading videos.zip\n",
      "[==================================================] 100.00%\n",
      "Uncompress videos.zip\n",
      "[==================================================] 100.00%\n",
      "Connecting to https://paddleseg.bj.bcebos.com/dygraph/pp_humanseg_v2/images.zip\n",
      "Downloading images.zip\n",
      "[==================================================] 100.00%\n",
      "Uncompress images.zip\n",
      "[==================================================] 100.00%\n",
      "Data download finished!\n"
     ]
    }
   ],
   "source": [
    "%cd ~/PaddleSeg/contrib/PP-HumanSeg\n",
    "!python src/download_inference_models.py\n",
    "!python src/download_data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c67ff4a-bf96-4bf2-87c2-992b8d3bacd7",
   "metadata": {},
   "source": [
    "* 快速体验\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a96627b-2b2c-40eb-b13a-e1eb82a707df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T09:38:25.866583Z",
     "iopub.status.busy": "2022-11-09T09:38:25.865497Z",
     "iopub.status.idle": "2022-11-09T09:38:37.607074Z",
     "shell.execute_reply": "2022-11-09T09:38:37.606028Z",
     "shell.execute_reply.started": "2022-11-09T09:38:25.866534Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-09 17:38:28 [INFO]\tInput: image\n",
      "2022-11-09 17:38:28 [INFO]\tCreate predictor...\n",
      "2022-11-09 17:38:29 [INFO]\tStart predicting...\n",
      "2022-11-09 17:38:33 [INFO]\tInput: image\n",
      "2022-11-09 17:38:33 [INFO]\tCreate predictor...\n",
      "2022-11-09 17:38:35 [INFO]\tStart predicting...\n"
     ]
    }
   ],
   "source": [
    "!python src/seg_demo.py \\\n",
    "  --config inference_models/portrait_pp_humansegv2_lite_256x144_inference_model_with_softmax/deploy.yaml \\\n",
    "  --img_path data/images/portrait_heng.jpg \\\n",
    "  --bg_img_path data/images/bg_2.jpg \\\n",
    "  --save_dir data/images_result/portrait_heng_v2_withbg.jpg\n",
    "\n",
    "!python src/seg_demo.py \\\n",
    "  --config inference_models/portrait_pp_humansegv2_lite_256x144_inference_model_with_softmax/deploy.yaml \\\n",
    "  --img_path data/images/portrait_shu.jpg \\\n",
    "  --bg_img_path data/images/bg_1.jpg \\\n",
    "  --save_dir data/images_result/portrait_shu_v2_withbg.jpg \\\n",
    "  --vertical_screen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5a6d38-a18d-4bb2-ae0d-9397ba7c172e",
   "metadata": {},
   "source": [
    "结果保存在`data/images_result/portrait_heng_v2.jpg`（如下图）。\n",
    "\n",
    "<img src=\"https://user-images.githubusercontent.com/52520497/188776878-130f4f6a-6379-4fb0-87e4-9a7ee4707c1d.jpg\" width=\"200\"> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6aeb78d-63ff-4e01-aa50-da37522e0b08",
   "metadata": {},
   "source": [
    "### 3.2 模型训练\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da9e355-e99a-4821-9fa2-1571a7b84f97",
   "metadata": {},
   "source": [
    "* 准备\n",
    "\n",
    "参考前文，安装PaddleSeg、下载数据集，然后下载预训练权重。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5945d193-bae0-4c5f-bd43-59e205b0484a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T09:42:05.729753Z",
     "iopub.status.busy": "2022-11-09T09:42:05.728678Z",
     "iopub.status.idle": "2022-11-09T09:42:44.312577Z",
     "shell.execute_reply": "2022-11-09T09:42:44.311508Z",
     "shell.execute_reply.started": "2022-11-09T09:42:05.729708Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data download finished!\n",
      "Connecting to https://paddleseg.bj.bcebos.com/dygraph/pp_humanseg_v2/human_pp_humansegv1_lite_192x192_pretrained.zip\n",
      "Downloading human_pp_humansegv1_lite_192x192_pretrained.zip\n",
      "[==================================================] 100.00%\n",
      "Uncompress human_pp_humansegv1_lite_192x192_pretrained.zip\n",
      "[==================================================] 100.00%\n",
      "Connecting to https://paddleseg.bj.bcebos.com/dygraph/pp_humanseg_v2/human_pp_humansegv2_lite_192x192_pretrained.zip\n",
      "Downloading human_pp_humansegv2_lite_192x192_pretrained.zip\n",
      "[==================================================] 100.00%\n",
      "Uncompress human_pp_humansegv2_lite_192x192_pretrained.zip\n",
      "[==================================================] 100.00%\n",
      "Connecting to https://paddleseg.bj.bcebos.com/dygraph/pp_humanseg_v2/human_pp_humansegv1_mobile_192x192_pretrained.zip\n",
      "Downloading human_pp_humansegv1_mobile_192x192_pretrained.zip\n",
      "[==================================================] 100.00%\n",
      "Uncompress human_pp_humansegv1_mobile_192x192_pretrained.zip\n",
      "[==================================================] 100.00%\n",
      "Connecting to https://paddleseg.bj.bcebos.com/dygraph/pp_humanseg_v2/human_pp_humansegv2_mobile_192x192_pretrained.zip\n",
      "Downloading human_pp_humansegv2_mobile_192x192_pretrained.zip\n",
      "[==================================================] 100.00%\n",
      "Uncompress human_pp_humansegv2_mobile_192x192_pretrained.zip\n",
      "[==================================================] 100.00%\n",
      "Connecting to https://paddleseg.bj.bcebos.com/dygraph/pp_humanseg_v2/human_pp_humansegv1_server_512x512_pretrained.zip\n",
      "Downloading human_pp_humansegv1_server_512x512_pretrained.zip\n",
      "[==================================================] 100.00%\n",
      "Uncompress human_pp_humansegv1_server_512x512_pretrained.zip\n",
      "[==================================================] 100.00%\n",
      "Connecting to https://paddleseg.bj.bcebos.com/dygraph/pp_humanseg_v2/portrait_pp_humansegv1_lite_398x224_pretrained.zip\n",
      "Downloading portrait_pp_humansegv1_lite_398x224_pretrained.zip\n",
      "[==================================================] 100.00%\n",
      "Uncompress portrait_pp_humansegv1_lite_398x224_pretrained.zip\n",
      "[==================================================] 100.00%\n",
      "Connecting to https://paddleseg.bj.bcebos.com/dygraph/pp_humanseg_v2/portrait_pp_humansegv2_lite_256x144_smaller/portrait_pp_humansegv2_lite_256x144_pretrained.zip\n",
      "Downloading portrait_pp_humansegv2_lite_256x144_pretrained.zip\n",
      "[==================================================] 100.00%\n",
      "Uncompress portrait_pp_humansegv2_lite_256x144_pretrained.zip\n",
      "[==================================================] 100.00%\n",
      "Download pretrained models finished.\n"
     ]
    }
   ],
   "source": [
    "!python src/download_pretrained_models.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ba1500-8475-40e0-a257-9ddad436c14d",
   "metadata": {},
   "source": [
    "* 训练\n",
    "\n",
    "配置文件保存在`./configs`目录下，如下。配置文件中，已经通过`pretrained`设置好预训练权重的路径。\n",
    "```\n",
    "configs\n",
    "├── human_pp_humansegv1_lite.yml\n",
    "├── human_pp_humansegv2_lite.yml\n",
    "├── human_pp_humansegv1_mobile.yml\n",
    "├── human_pp_humansegv2_mobile.yml\n",
    "├── human_pp_humansegv1_server.yml\n",
    "├── portrait_pp_humansegv1_lite.yml\n",
    "├── portrait_pp_humansegv2_lite.yml\n",
    "```\n",
    "\n",
    "执行如下命令，进行模型微调（大家需要根据实际情况修改配置文件中的超参）。模型训练的详细文档，请参考[链接](https://github.com/PaddlePaddle/PaddleSeg/blob/release/2.6/docs/train/train_cn.md)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14461b15-5c88-453a-b877-739ddf0062ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T09:42:51.859811Z",
     "iopub.status.busy": "2022-11-09T09:42:51.859009Z",
     "iopub.status.idle": "2022-11-09T09:43:19.809770Z",
     "shell.execute_reply": "2022-11-09T09:43:19.808060Z",
     "shell.execute_reply.started": "2022-11-09T09:42:51.859770Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-09 17:42:54 [INFO]\t\n",
      "------------Environment Information-------------\n",
      "platform: Linux-4.15.0-140-generic-x86_64-with-debian-stretch-sid\n",
      "Python: 3.7.4 (default, Aug 13 2019, 20:35:49) [GCC 7.3.0]\n",
      "Paddle compiled with cuda: True\n",
      "NVCC: Build cuda_11.2.r11.2/compiler.29618528_0\n",
      "cudnn: 8.2\n",
      "GPUs used: 1\n",
      "CUDA_VISIBLE_DEVICES: None\n",
      "GPU: ['GPU 0: Tesla V100-SXM2-16GB']\n",
      "GCC: gcc (Ubuntu 7.5.0-3ubuntu1~16.04) 7.5.0\n",
      "PaddleSeg: 2.6.0\n",
      "PaddlePaddle: 2.3.2\n",
      "OpenCV: 4.1.1\n",
      "------------------------------------------------\n",
      "2022-11-09 17:42:54 [INFO]\t\n",
      "---------------Config Information---------------\n",
      "batch_size: 8\n",
      "export:\n",
      "  transforms:\n",
      "  - target_size:\n",
      "    - 192\n",
      "    - 192\n",
      "    type: Resize\n",
      "  - type: Normalize\n",
      "iters: 1000\n",
      "loss:\n",
      "  coef:\n",
      "  - 1\n",
      "  - 1\n",
      "  - 1\n",
      "  - 1\n",
      "  types:\n",
      "  - coef:\n",
      "    - 0.8\n",
      "    - 0.2\n",
      "    losses:\n",
      "    - type: CrossEntropyLoss\n",
      "    - type: LovaszSoftmaxLoss\n",
      "    type: MixedLoss\n",
      "lr_scheduler:\n",
      "  end_lr: 0\n",
      "  learning_rate: 0.0001\n",
      "  power: 0.9\n",
      "  type: PolynomialDecay\n",
      "model:\n",
      "  arm_out_chs:\n",
      "  - 32\n",
      "  - 64\n",
      "  - 96\n",
      "  - 128\n",
      "  backbone:\n",
      "    pretrained: https://paddleseg.bj.bcebos.com/dygraph/backbone/mobilenetv3_large_x1_0_ssld.tar.gz\n",
      "    type: MobileNetV3_large_x1_0\n",
      "  backbone_indices:\n",
      "  - 0\n",
      "  - 1\n",
      "  - 2\n",
      "  - 3\n",
      "  cm_bin_sizes:\n",
      "  - 1\n",
      "  - 2\n",
      "  - 4\n",
      "  cm_out_ch: 128\n",
      "  num_classes: 2\n",
      "  pretrained: pretrained_models/human_pp_humansegv2_lite_192x192_pretrained/model.pdparams\n",
      "  seg_head_inter_chs:\n",
      "  - 16\n",
      "  - 32\n",
      "  - 32\n",
      "  - 32\n",
      "  type: MobileSeg\n",
      "  use_last_fuse: true\n",
      "optimizer:\n",
      "  momentum: 0.9\n",
      "  type: sgd\n",
      "  weight_decay: 0.0005\n",
      "train_dataset:\n",
      "  dataset_root: data/mini_supervisely\n",
      "  mode: train\n",
      "  num_classes: 2\n",
      "  train_path: data/mini_supervisely/train.txt\n",
      "  transforms:\n",
      "  - target_size:\n",
      "    - 192\n",
      "    - 192\n",
      "    type: Resize\n",
      "  - scale_step_size: 0\n",
      "    type: ResizeStepScaling\n",
      "  - type: RandomRotation\n",
      "  - crop_size:\n",
      "    - 192\n",
      "    - 192\n",
      "    type: RandomPaddingCrop\n",
      "  - type: RandomHorizontalFlip\n",
      "  - type: RandomDistort\n",
      "  - prob: 0.3\n",
      "    type: RandomBlur\n",
      "  - type: Normalize\n",
      "  type: Dataset\n",
      "val_dataset:\n",
      "  dataset_root: data/mini_supervisely\n",
      "  mode: val\n",
      "  num_classes: 2\n",
      "  transforms:\n",
      "  - target_size:\n",
      "    - 192\n",
      "    - 192\n",
      "    type: Resize\n",
      "  - type: Normalize\n",
      "  type: Dataset\n",
      "  val_path: data/mini_supervisely/val.txt\n",
      "------------------------------------------------\n",
      "W1109 17:42:54.396687  8478 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.2, Runtime API Version: 11.2\n",
      "W1109 17:42:54.396740  8478 gpu_resources.cc:91] device: 0, cuDNN Version: 8.2.\n",
      "2022-11-09 17:42:55 [INFO]\tLoading pretrained model from https://paddleseg.bj.bcebos.com/dygraph/backbone/mobilenetv3_large_x1_0_ssld.tar.gz\n",
      "Connecting to https://paddleseg.bj.bcebos.com/dygraph/backbone/mobilenetv3_large_x1_0_ssld.tar.gz\n",
      "Downloading mobilenetv3_large_x1_0_ssld.tar.gz\n",
      "[==================================================] 100.00%\n",
      "Uncompress mobilenetv3_large_x1_0_ssld.tar.gz\n",
      "[==================================================] 100.00%\n",
      "2022-11-09 17:42:58 [INFO]\tThere are 262/262 variables loaded into MobileNetV3.\n",
      "2022-11-09 17:42:59 [INFO]\tLoading pretrained model from pretrained_models/human_pp_humansegv2_lite_192x192_pretrained/model.pdparams\n",
      "2022-11-09 17:42:59 [INFO]\tThere are 471/471 variables loaded into MobileSeg.\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:654: UserWarning: When training, we now always track global mean and variance.\n",
      "  \"When training, we now always track global mean and variance.\")\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/math_op_patch.py:278: UserWarning: The dtype of left and right variables are not the same, left dtype is paddle.float32, but right dtype is paddle.int64, the right dtype will convert to paddle.float32\n",
      "  format(lhs_dtype, rhs_dtype, lhs_dtype))\n",
      "2022-11-09 17:43:04 [INFO]\t[TRAIN] epoch: 1, iter: 10/1000, loss: 0.5793, lr: 0.000099, batch_cost: 0.5289, reader_cost: 0.03797, ips: 15.1265 samples/sec | ETA 00:08:43\n",
      "2022-11-09 17:43:07 [INFO]\t[TRAIN] epoch: 1, iter: 20/1000, loss: 0.6167, lr: 0.000098, batch_cost: 0.2635, reader_cost: 0.07728, ips: 30.3607 samples/sec | ETA 00:04:18\n",
      "2022-11-09 17:43:10 [INFO]\t[TRAIN] epoch: 2, iter: 30/1000, loss: 0.5226, lr: 0.000097, batch_cost: 0.2793, reader_cost: 0.11362, ips: 28.6383 samples/sec | ETA 00:04:30\n",
      "2022-11-09 17:43:12 [INFO]\t[TRAIN] epoch: 2, iter: 40/1000, loss: 0.5418, lr: 0.000096, batch_cost: 0.2750, reader_cost: 0.06545, ips: 29.0919 samples/sec | ETA 00:04:23\n",
      "2022-11-09 17:43:15 [INFO]\t[TRAIN] epoch: 2, iter: 50/1000, loss: 0.5143, lr: 0.000096, batch_cost: 0.2540, reader_cost: 0.02557, ips: 31.5006 samples/sec | ETA 00:04:01\n",
      "2022-11-09 17:43:17 [INFO]\t[TRAIN] epoch: 3, iter: 60/1000, loss: 0.5124, lr: 0.000095, batch_cost: 0.2645, reader_cost: 0.08801, ips: 30.2493 samples/sec | ETA 00:04:08\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"../../train.py\", line 230, in <module>\n",
      "    main(args)\n",
      "  File \"../../train.py\", line 225, in main\n",
      "    to_static_training=cfg.to_static_training)\n",
      "  File \"/home/aistudio/PaddleSeg/paddleseg/core/train.py\", line 206, in train\n",
      "    logits_list = ddp_model(images) if nranks > 1 else model(images)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 930, in __call__\n",
      "    return self._dygraph_call_func(*inputs, **kwargs)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 915, in _dygraph_call_func\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/home/aistudio/PaddleSeg/paddleseg/models/mobileseg.py\", line 102, in forward\n",
      "    feats_backbone = self.backbone(x)  # [x4, x8, x16, x32]\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 930, in __call__\n",
      "    return self._dygraph_call_func(*inputs, **kwargs)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 915, in _dygraph_call_func\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/home/aistudio/PaddleSeg/paddleseg/models/backbones/mobilenetv3.py\", line 226, in forward\n",
      "    x = block(x)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 930, in __call__\n",
      "    return self._dygraph_call_func(*inputs, **kwargs)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 915, in _dygraph_call_func\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/home/aistudio/PaddleSeg/paddleseg/models/backbones/mobilenetv3.py\", line 316, in forward\n",
      "    x = self.expand_conv(x)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 930, in __call__\n",
      "    return self._dygraph_call_func(*inputs, **kwargs)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 915, in _dygraph_call_func\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/home/aistudio/PaddleSeg/paddleseg/models/backbones/mobilenetv3.py\", line 264, in forward\n",
      "    x = self.conv(x)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 930, in __call__\n",
      "    return self._dygraph_call_func(*inputs, **kwargs)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 915, in _dygraph_call_func\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/conv.py\", line 678, in forward\n",
      "    use_cudnn=self._use_cudnn)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/functional/conv.py\", line 144, in _conv_nd\n",
      "    pre_bias = getattr(_C_ops, op_type)(x, weight, *attrs)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=0 # Linux下设置1张可用的卡\n",
    "# set CUDA_VISIBLE_DEVICES=0  # Windows下设置1张可用的卡\n",
    "!python ../../train.py \\\n",
    "  --config configs/human_pp_humansegv2_lite.yml \\\n",
    "  --save_dir output/human_pp_humansegv2_lite \\\n",
    "  --save_interval 100 --do_eval --use_vdl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c44f772-2104-4379-bd66-d6f9b8d72414",
   "metadata": {},
   "source": [
    "* 评估\n",
    "\n",
    "执行如下命令，加载模型和训练好的权重，进行模型评估，输出验证集上的评估精度。模型评估的详细文档，请参考[链接](https://github.com/PaddlePaddle/PaddleSeg/blob/release/2.6/docs/evaluation/evaluate/evaluate_cn.md)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ff7c87f-62b4-4377-a7fd-260b8278e6c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T09:43:24.408843Z",
     "iopub.status.busy": "2022-11-09T09:43:24.408212Z",
     "iopub.status.idle": "2022-11-09T09:43:35.093786Z",
     "shell.execute_reply": "2022-11-09T09:43:35.092469Z",
     "shell.execute_reply.started": "2022-11-09T09:43:24.408796Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-09 17:43:26 [INFO]\t\n",
      "---------------Config Information---------------\n",
      "batch_size: 8\n",
      "export:\n",
      "  transforms:\n",
      "  - target_size:\n",
      "    - 192\n",
      "    - 192\n",
      "    type: Resize\n",
      "  - type: Normalize\n",
      "iters: 1000\n",
      "loss:\n",
      "  coef:\n",
      "  - 1\n",
      "  - 1\n",
      "  - 1\n",
      "  - 1\n",
      "  types:\n",
      "  - coef:\n",
      "    - 0.8\n",
      "    - 0.2\n",
      "    losses:\n",
      "    - type: CrossEntropyLoss\n",
      "    - type: LovaszSoftmaxLoss\n",
      "    type: MixedLoss\n",
      "lr_scheduler:\n",
      "  end_lr: 0\n",
      "  learning_rate: 0.0001\n",
      "  power: 0.9\n",
      "  type: PolynomialDecay\n",
      "model:\n",
      "  arm_out_chs:\n",
      "  - 32\n",
      "  - 64\n",
      "  - 96\n",
      "  - 128\n",
      "  backbone:\n",
      "    pretrained: https://paddleseg.bj.bcebos.com/dygraph/backbone/mobilenetv3_large_x1_0_ssld.tar.gz\n",
      "    type: MobileNetV3_large_x1_0\n",
      "  backbone_indices:\n",
      "  - 0\n",
      "  - 1\n",
      "  - 2\n",
      "  - 3\n",
      "  cm_bin_sizes:\n",
      "  - 1\n",
      "  - 2\n",
      "  - 4\n",
      "  cm_out_ch: 128\n",
      "  num_classes: 2\n",
      "  pretrained: pretrained_models/human_pp_humansegv2_lite_192x192_pretrained/model.pdparams\n",
      "  seg_head_inter_chs:\n",
      "  - 16\n",
      "  - 32\n",
      "  - 32\n",
      "  - 32\n",
      "  type: MobileSeg\n",
      "  use_last_fuse: true\n",
      "optimizer:\n",
      "  momentum: 0.9\n",
      "  type: sgd\n",
      "  weight_decay: 0.0005\n",
      "train_dataset:\n",
      "  dataset_root: data/mini_supervisely\n",
      "  mode: train\n",
      "  num_classes: 2\n",
      "  train_path: data/mini_supervisely/train.txt\n",
      "  transforms:\n",
      "  - target_size:\n",
      "    - 192\n",
      "    - 192\n",
      "    type: Resize\n",
      "  - scale_step_size: 0\n",
      "    type: ResizeStepScaling\n",
      "  - type: RandomRotation\n",
      "  - crop_size:\n",
      "    - 192\n",
      "    - 192\n",
      "    type: RandomPaddingCrop\n",
      "  - type: RandomHorizontalFlip\n",
      "  - type: RandomDistort\n",
      "  - prob: 0.3\n",
      "    type: RandomBlur\n",
      "  - type: Normalize\n",
      "  type: Dataset\n",
      "val_dataset:\n",
      "  dataset_root: data/mini_supervisely\n",
      "  mode: val\n",
      "  num_classes: 2\n",
      "  transforms:\n",
      "  - target_size:\n",
      "    - 192\n",
      "    - 192\n",
      "    type: Resize\n",
      "  - type: Normalize\n",
      "  type: Dataset\n",
      "  val_path: data/mini_supervisely/val.txt\n",
      "------------------------------------------------\n",
      "W1109 17:43:26.517529  8623 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.2, Runtime API Version: 11.2\n",
      "W1109 17:43:26.517674  8623 gpu_resources.cc:91] device: 0, cuDNN Version: 8.2.\n",
      "2022-11-09 17:43:27 [INFO]\tLoading pretrained model from https://paddleseg.bj.bcebos.com/dygraph/backbone/mobilenetv3_large_x1_0_ssld.tar.gz\n",
      "2022-11-09 17:43:27 [INFO]\tThere are 262/262 variables loaded into MobileNetV3.\n",
      "2022-11-09 17:43:27 [INFO]\tLoading pretrained model from pretrained_models/human_pp_humansegv2_lite_192x192_pretrained/model.pdparams\n",
      "2022-11-09 17:43:28 [INFO]\tThere are 471/471 variables loaded into MobileSeg.\n",
      "2022-11-09 17:43:28 [INFO]\tLoading pretrained model from pretrained_models/human_pp_humansegv2_lite_192x192_pretrained/model.pdparams\n",
      "2022-11-09 17:43:28 [INFO]\tThere are 471/471 variables loaded into MobileSeg.\n",
      "2022-11-09 17:43:28 [INFO]\tLoaded trained params of model successfully\n",
      "2022-11-09 17:43:28 [INFO]\tStart evaluating (total_samples: 100, total_iters: 100)...\n",
      "100/100 [==============================] - ETA: 0s - batch_cost: 0.0585 - reader cost: 0.002 - 6s 58ms/step - batch_cost: 0.0582 - reader cost: 0.0021\n",
      "2022-11-09 17:43:33 [INFO]\t[EVAL] #Images: 100 mIoU: 0.9252 Acc: 0.9691 Kappa: 0.9216 Dice: 0.9608\n",
      "2022-11-09 17:43:33 [INFO]\t[EVAL] Class IoU: \n",
      "[0.9585 0.8919]\n",
      "2022-11-09 17:43:33 [INFO]\t[EVAL] Class Precision: \n",
      "[0.9776 0.9459]\n",
      "2022-11-09 17:43:33 [INFO]\t[EVAL] Class Recall: \n",
      "[0.98   0.9399]\n"
     ]
    }
   ],
   "source": [
    "!python ../../val.py \\\n",
    "  --config configs/human_pp_humansegv2_lite.yml \\\n",
    "  --model_path pretrained_models/human_pp_humansegv2_lite_192x192_pretrained/model.pdparams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e346d381-15df-421f-8473-9e96e39bbd0c",
   "metadata": {},
   "source": [
    "* 预测\n",
    "\n",
    "执行如下命令，加载模型和训练好的权重，对单张图像进行预测，预测结果保存在`./data/images_result`目录下的`added_prediction`和`pseudo_color_prediction`文件夹中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5b53557-9dbe-472d-8406-c60c2c58927d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T09:43:41.466469Z",
     "iopub.status.busy": "2022-11-09T09:43:41.465358Z",
     "iopub.status.idle": "2022-11-09T09:43:47.490289Z",
     "shell.execute_reply": "2022-11-09T09:43:47.489090Z",
     "shell.execute_reply.started": "2022-11-09T09:43:41.466420Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-09 17:43:43 [INFO]\t\n",
      "---------------Config Information---------------\n",
      "batch_size: 8\n",
      "export:\n",
      "  transforms:\n",
      "  - target_size:\n",
      "    - 192\n",
      "    - 192\n",
      "    type: Resize\n",
      "  - type: Normalize\n",
      "iters: 1000\n",
      "loss:\n",
      "  coef:\n",
      "  - 1\n",
      "  - 1\n",
      "  - 1\n",
      "  - 1\n",
      "  types:\n",
      "  - coef:\n",
      "    - 0.8\n",
      "    - 0.2\n",
      "    losses:\n",
      "    - type: CrossEntropyLoss\n",
      "    - type: LovaszSoftmaxLoss\n",
      "    type: MixedLoss\n",
      "lr_scheduler:\n",
      "  end_lr: 0\n",
      "  learning_rate: 0.0001\n",
      "  power: 0.9\n",
      "  type: PolynomialDecay\n",
      "model:\n",
      "  arm_out_chs:\n",
      "  - 32\n",
      "  - 64\n",
      "  - 96\n",
      "  - 128\n",
      "  backbone:\n",
      "    pretrained: https://paddleseg.bj.bcebos.com/dygraph/backbone/mobilenetv3_large_x1_0_ssld.tar.gz\n",
      "    type: MobileNetV3_large_x1_0\n",
      "  backbone_indices:\n",
      "  - 0\n",
      "  - 1\n",
      "  - 2\n",
      "  - 3\n",
      "  cm_bin_sizes:\n",
      "  - 1\n",
      "  - 2\n",
      "  - 4\n",
      "  cm_out_ch: 128\n",
      "  num_classes: 2\n",
      "  pretrained: pretrained_models/human_pp_humansegv2_lite_192x192_pretrained/model.pdparams\n",
      "  seg_head_inter_chs:\n",
      "  - 16\n",
      "  - 32\n",
      "  - 32\n",
      "  - 32\n",
      "  type: MobileSeg\n",
      "  use_last_fuse: true\n",
      "optimizer:\n",
      "  momentum: 0.9\n",
      "  type: sgd\n",
      "  weight_decay: 0.0005\n",
      "train_dataset:\n",
      "  dataset_root: data/mini_supervisely\n",
      "  mode: train\n",
      "  num_classes: 2\n",
      "  train_path: data/mini_supervisely/train.txt\n",
      "  transforms:\n",
      "  - target_size:\n",
      "    - 192\n",
      "    - 192\n",
      "    type: Resize\n",
      "  - scale_step_size: 0\n",
      "    type: ResizeStepScaling\n",
      "  - type: RandomRotation\n",
      "  - crop_size:\n",
      "    - 192\n",
      "    - 192\n",
      "    type: RandomPaddingCrop\n",
      "  - type: RandomHorizontalFlip\n",
      "  - type: RandomDistort\n",
      "  - prob: 0.3\n",
      "    type: RandomBlur\n",
      "  - type: Normalize\n",
      "  type: Dataset\n",
      "val_dataset:\n",
      "  dataset_root: data/mini_supervisely\n",
      "  mode: val\n",
      "  num_classes: 2\n",
      "  transforms:\n",
      "  - target_size:\n",
      "    - 192\n",
      "    - 192\n",
      "    type: Resize\n",
      "  - type: Normalize\n",
      "  type: Dataset\n",
      "  val_path: data/mini_supervisely/val.txt\n",
      "------------------------------------------------\n",
      "W1109 17:43:43.732460  8710 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.2, Runtime API Version: 11.2\n",
      "W1109 17:43:43.732515  8710 gpu_resources.cc:91] device: 0, cuDNN Version: 8.2.\n",
      "2022-11-09 17:43:44 [INFO]\tLoading pretrained model from https://paddleseg.bj.bcebos.com/dygraph/backbone/mobilenetv3_large_x1_0_ssld.tar.gz\n",
      "2022-11-09 17:43:45 [INFO]\tThere are 262/262 variables loaded into MobileNetV3.\n",
      "2022-11-09 17:43:45 [INFO]\tLoading pretrained model from pretrained_models/human_pp_humansegv2_lite_192x192_pretrained/model.pdparams\n",
      "2022-11-09 17:43:45 [INFO]\tThere are 471/471 variables loaded into MobileSeg.\n",
      "2022-11-09 17:43:45 [INFO]\tNumber of predict images = 1\n",
      "2022-11-09 17:43:45 [INFO]\tLoading pretrained model from pretrained_models/human_pp_humansegv2_lite_192x192_pretrained/model.pdparams\n",
      "2022-11-09 17:43:45 [INFO]\tThere are 471/471 variables loaded into MobileSeg.\n",
      "2022-11-09 17:43:45 [INFO]\tStart to predict...\n",
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    }
   ],
   "source": [
    "!python ../../predict.py \\\n",
    "  --config configs/human_pp_humansegv2_lite.yml \\\n",
    "  --model_path pretrained_models/human_pp_humansegv2_lite_192x192_pretrained/model.pdparams \\\n",
    "  --image_path data/images/human.jpg \\\n",
    "  --save_dir ./data/images_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98d8455-6e84-493a-b823-428aab76e932",
   "metadata": {},
   "source": [
    "* 导出\n",
    "\n",
    "执行如下命令，加载模型和训练好的权重，导出预测模型。模型导出的详细文档，请参考[链接](https://github.com/PaddlePaddle/PaddleSeg/blob/release/2.6/docs/model_export_cn.md)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fe76c54-aafe-43e0-a0cc-b8feb49bb770",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T09:43:58.392571Z",
     "iopub.status.busy": "2022-11-09T09:43:58.391777Z",
     "iopub.status.idle": "2022-11-09T09:44:06.747405Z",
     "shell.execute_reply": "2022-11-09T09:44:06.746288Z",
     "shell.execute_reply.started": "2022-11-09T09:43:58.392522Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1109 17:44:01.011113  8827 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.2, Runtime API Version: 11.2\n",
      "W1109 17:44:01.015580  8827 gpu_resources.cc:91] device: 0, cuDNN Version: 8.2.\n",
      "2022-11-09 17:44:02 [INFO]\tLoading pretrained model from https://paddleseg.bj.bcebos.com/dygraph/backbone/mobilenetv3_large_x1_0_ssld.tar.gz\n",
      "2022-11-09 17:44:02 [INFO]\tThere are 262/262 variables loaded into MobileNetV3.\n",
      "2022-11-09 17:44:02 [INFO]\tLoading pretrained model from pretrained_models/human_pp_humansegv2_lite_192x192_pretrained/model.pdparams\n",
      "2022-11-09 17:44:02 [INFO]\tThere are 471/471 variables loaded into MobileSeg.\n",
      "2022-11-09 17:44:02 [INFO]\tLoaded trained params of model successfully.\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/math_op_patch.py:341: UserWarning: /tmp/tmp2axz6dfp.py:26\n",
      "The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.\n",
      "  op_type, op_type, EXPRESSION_MAP[method_name]))\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/math_op_patch.py:341: UserWarning: /tmp/tmpwelc89pm.py:7\n",
      "The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.\n",
      "  op_type, op_type, EXPRESSION_MAP[method_name]))\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/math_op_patch.py:341: UserWarning: /tmp/tmp82bepc8w.py:7\n",
      "The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.\n",
      "  op_type, op_type, EXPRESSION_MAP[method_name]))\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/math_op_patch.py:341: UserWarning: /tmp/tmp3z4gzn8f.py:7\n",
      "The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.\n",
      "  op_type, op_type, EXPRESSION_MAP[method_name]))\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/math_op_patch.py:341: UserWarning: /tmp/tmpkb085h_s.py:7\n",
      "The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.\n",
      "  op_type, op_type, EXPRESSION_MAP[method_name]))\n",
      "2022-11-09 17:44:05 [INFO]\tModel is saved in output/human_pp_humansegv2_lite.\n"
     ]
    }
   ],
   "source": [
    "!python ../../export.py \\\n",
    "  --config configs/human_pp_humansegv2_lite.yml \\\n",
    "  --model_path pretrained_models/human_pp_humansegv2_lite_192x192_pretrained/model.pdparams \\\n",
    "  --save_dir output/human_pp_humansegv2_lite \\\n",
    "  --without_argmax \\\n",
    "  --with_softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629a50ee-3e33-42a5-b505-aacc4ccd220f",
   "metadata": {},
   "source": [
    "注意，使用--without_argmax --with_softmax参数，则模型导出的时候，模型最后面不会添加Argmax算子，而是添加Softmax算子。 所以，输出是浮点数类型，表示前景的概率，使得图像融合的边缘更为平滑。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6fd1d6-a7a5-4388-b225-86b62ab72d67",
   "metadata": {},
   "source": [
    "## 4. 模型原理\n",
    "\n",
    "模型结构如下图。\n",
    "<div align=\"center\">\n",
    "<img src=\"https://user-images.githubusercontent.com/48357642/200757494-1e63215e-4cd1-4c39-8dd9-a0e37f8719f2.png\"  width = \"60%\"  />\n",
    "</div>\n",
    "\n",
    "* 模型算量大幅减小\n",
    "\n",
    "对于模型Encoder部分，我们选用MobileNetV3作为骨干网络提取多层特征，分析发现MobileNetV3的参数主要集中在最后一个Stage，在不影响分割精度的前提下，我们只保留MobileNetV3的前四个Stage，成功减少了68.6%的参数量。对于上下文部分，我们使用PP-LiteSeg模型中提出的轻量级SPPM模块，而且其中的普通卷积都替换为可分离卷积，进一步减小计算量。对于Decoder部分，我们设计三个Fusion融合模块，多次融合深层语义特征和浅层细节特征，最后一个Fusion融合模块再次汇集不同层次的特征图，输出分割结果。\n",
    "\n",
    "多层次特征融合模块图：\n",
    "<div align=\"center\">\n",
    "<img src=\"https://user-images.githubusercontent.com/48357642/200758284-a8d5e6f9-1a66-414b-804c-57c6b6fcd698.png\"  width = \"30%\"  />\n",
    "</div>\n",
    "\n",
    "* 使用两阶段训练方式，提升分割精度\n",
    "\n",
    "两阶段训练是基于迁移学习的思想，首先在大规模混合人像数据集（数据量100k+）上训练，然后使用该预训练权重，在PP-HumanSeg14k数据集（数据量14k）上训练，最终得到训练好的模型。使用两阶段训练方式，可以充分利用其他数据集，提高模型的分割精度和泛化能力。\n",
    "\n",
    "* 调整图像分辨率，提升推理速度\n",
    "\n",
    "调整图像分辨率也直接影响模型的推理速度，我们使用多种图像分辨率进行训练和测试，在PP-HumanSeg v2方案中选择最佳图像分辨率，进一步提升了模型推理速度。\n",
    "\n",
    "* 使用形态学后处理，提升可视化效果\n",
    "\n",
    "首先获取原始预测图像I，然后使用阈值处理、图像腐蚀、图像膨胀等操作得到掩码图像M，最后预测图像I和掩码图像M相乘，输出最终预测图像O。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc360fb0-fb54-4266-a4e3-4ae385d43a76",
   "metadata": {},
   "source": [
    "## 5. 相关论文以及引用信息\n",
    "如果我们的项目在学术上帮助到你，请考虑以下引用：\n",
    "\n",
    "```\n",
    "@InProceedings{Chu_2022_WACV,\n",
    "    author    = {Chu, Lutao and Liu, Yi and Wu, Zewu and Tang, Shiyu and Chen, Guowei and Hao, Yuying and Peng, Juncai and Yu, Zhiliang and Chen, Zeyu and Lai, Baohua and Xiong, Haoyi},\n",
    "    title     = {PP-HumanSeg: Connectivity-Aware Portrait Segmentation With a Large-Scale Teleconferencing Video Dataset},\n",
    "    booktitle = {Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) Workshops},\n",
    "    month     = {January},\n",
    "    year      = {2022},\n",
    "    pages     = {202-209}\n",
    "}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
