{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# sentence-transformers/msmarco-roberta-base-ance-firstp\n", "\n", "This is a port of the [ANCE FirstP Model](https://github.com/microsoft/ANCE/) to [sentence-transformers](https://www.SBERT.net) model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search.\n", "\n", "\n", "\n", "## Usage (Sentence-Transformers)\n", "\n", "Using this model becomes easy when you have [sentence-transformers](https://www.SBERT.net) installed:\n"]}, {"cell_type": "code", "metadata": {}, "source": "import paddle\nfrom paddlenlp.transformers import AutoModel\n\nmodel = AutoModel.from_pretrained(\"sentence-transformers/msmarco-roberta-base-ance-firstp\")\ninput_ids = paddle.randint(100, 200, shape=[1, 20])\nprint(model(input_ids))"}, {"cell_type": "code", "metadata": {}, "source": ["SentenceTransformer(\n", "(0): Transformer({'max_seq_length': 512, 'do_lower_case': True}) with Transformer model: RobertaModel\n", "(1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': True, 'pooling_mode_mean_tokens': False, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n", "(2): Dense({'in_features': 768, 'out_features': 768, 'bias': True, 'activation_function': 'torch.nn.modules.linear.Identity'})\n", "(3): LayerNorm(\n", "(norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n", ")\n", ")\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Citing & Authors\n", "\n", "Have a look at: [ANCE Model](https://github.com/microsoft/ANCE/)\n", "> 此模型来源于：[https://huggingface.co/sentence-transformers/msmarco-roberta-base-ance-firstp](https://huggingface.co/https://huggingface.co/sentence-transformers/msmarco-roberta-base-ance-firstp)"]}, {"cell_type": "markdown", "metadata": {}, "source": "> this model is from [sentence-transformers/msmarco-roberta-base-ance-firstp](https://huggingface.co/sentence-transformers/msmarco-roberta-base-ance-firstp)"}], "metadata": {"language_info": {"name": "python"}, "orig_nbformat": 4}, "nbformat": 4, "nbformat_minor": 2}