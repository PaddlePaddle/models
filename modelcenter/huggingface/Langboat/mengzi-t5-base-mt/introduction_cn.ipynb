{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Mengzi-T5-MT model\n", "This is a Multi-Task model trained on the multitask mixture of 27 datasets and 301 prompts, based on [Mengzi-T5-base](https://huggingface.co/Langboat/mengzi-t5-base).\n", "\n", "[Mengzi: Towards Lightweight yet Ingenious Pre-trained Models for Chinese](https://arxiv.org/abs/2110.06696)\n", "\n", "## Usage\n"]}, {"cell_type": "code", "metadata": {}, "source": ["from transformers import T5Tokenizer, T5ForConditionalGeneration\n", "tokenizer = T5Tokenizer.from_pretrained(\"Langboat/mengzi-t5-base-mt\")\n", "model = T5ForConditionalGeneration.from_pretrained(\"Langboat/mengzi-t5-base-mt\")\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Citation\n", "If you find the technical report or resource is useful, please cite the following technical report in your paper.\n"]}, {"cell_type": "code", "metadata": {}, "source": ["@misc{zhang2021mengzi,\n", "title={Mengzi: Towards Lightweight yet Ingenious Pre-trained Models for Chinese},\n", "author={Zhuosheng Zhang and Hanqing Zhang and Keming Chen and Yuhang Guo and Jingyun Hua and Yulong Wang and Ming Zhou},\n", "year={2021},\n", "eprint={2110.06696},\n", "archivePrefix={arXiv},\n", "primaryClass={cs.CL}\n", "}\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["> 此模型来源于：[https://huggingface.co/Langboat/mengzi-t5-base-mt](https://huggingface.co/https://huggingface.co/Langboat/mengzi-t5-base-mt)"]}, {"cell_type": "markdown", "metadata": {}, "source": "> this model is from [Langboat/mengzi-t5-base-mt](https://huggingface.co/Langboat/mengzi-t5-base-mt)"}], "metadata": {"language_info": {"name": "python"}, "orig_nbformat": 4}, "nbformat": 4, "nbformat_minor": 2}