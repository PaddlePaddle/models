{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Portuguese BERT large cased QA (Question Answering), finetuned on SQUAD v1.1\n", "\n", "![Exemple of what can do the Portuguese BERT large cased QA (Question Answering), finetuned on SQUAD v1.1](https://miro.medium.com/max/5256/1*QxyeAjT2V1OfE2B6nEcs3w.png)\n", "\n", "## Introduction\n", "\n", "The model was trained on the dataset SQUAD v1.1 in portuguese from the [Deep Learning Brasil group](http://www.deeplearningbrasil.com.br/).\n", "\n", "The language model used is the [BERTimbau Large](https://huggingface.co/neuralmind/bert-large-portuguese-cased) (aka \"bert-large-portuguese-cased\") from [Neuralmind.ai](https://neuralmind.ai/): BERTimbau is a pretrained BERT model for Brazilian Portuguese that achieves state-of-the-art performances on three downstream NLP tasks: Named Entity Recognition, Sentence Textual Similarity and Recognizing Textual Entailment. It is available in two sizes: Base and Large.\n", "\n", "## Informations on the method used\n", "\n", "All the informations are in the blog post : [NLP | Como treinar um modelo de Question Answering em qualquer linguagem baseado no BERT large, melhorando o desempenho do modelo utilizando o BERT base? (estudo de caso em português)](https://medium.com/@pierre_guillou/nlp-como-treinar-um-modelo-de-question-answering-em-qualquer-linguagem-baseado-no-bert-large-1c899262dd96)\n", "\n", "## Notebook in GitHub\n", "\n", "[question_answering_BERT_large_cased_squad_v11_pt.ipynb](https://github.com/piegu/language-models/blob/master/question_answering_BERT_large_cased_squad_v11_pt.ipynb) ([nbviewer version](https://nbviewer.jupyter.org/github/piegu/language-models/blob/master/question_answering_BERT_large_cased_squad_v11_pt.ipynb))\n", "\n", "## Performance\n", "\n", "The results obtained are the following:\n"]}, {"cell_type": "code", "metadata": {}, "source": ["f1 = 84.43 (against 82.50 for the base model)\n", "exact match = 72.68 (against 70.49 for the base model)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## How to use the model... with Pipeline\n"]}, {"cell_type": "code", "metadata": {}, "source": ["import transformers\n", "from transformers import pipeline\n", "\n", "# source: https://pt.wikipedia.org/wiki/Pandemia_de_COVID-19\n", "context = r\"\"\"\n", "A pandemia de COVID-19, também conhecida como pandemia de coronavírus, é uma pandemia em curso de COVID-19,\n", "uma doença respiratória causada pelo coronavírus da síndrome respiratória aguda grave 2 (SARS-CoV-2).\n", "O vírus tem origem zoonótica e o primeiro caso conhecido da doença remonta a dezembro de 2019 em Wuhan, na China.\n", "Em 20 de janeiro de 2020, a Organização Mundial da Saúde (OMS) classificou o surto\n", "como Emergência de Saúde Pública de Âmbito Internacional e, em 11 de março de 2020, como pandemia.\n", "Em 18 de junho de 2021, 177 349 274 casos foram confirmados em 192 países e territórios,\n", "com 3 840 181 mortes atribuídas à doença, tornando-se uma das pandemias mais mortais da história.\n", "Os sintomas de COVID-19 são altamente variáveis, variando de nenhum a doenças com risco de morte.\n", "O vírus se espalha principalmente pelo ar quando as pessoas estão perto umas das outras.\n", "Ele deixa uma pessoa infectada quando ela respira, tosse, espirra ou fala e entra em outra pessoa pela boca, nariz ou olhos.\n", "Ele também pode se espalhar através de superfícies contaminadas.\n", "As pessoas permanecem contagiosas por até duas semanas e podem espalhar o vírus mesmo se forem assintomáticas.\n", "\"\"\"\n", "\n", "model_name = 'pierreguillou/bert-large-cased-squad-v1.1-portuguese'\n", "nlp = pipeline(\"question-answering\", model=model_name)\n", "\n", "question = \"Quando começou a pandemia de Covid-19 no mundo?\"\n", "\n", "result = nlp(question=question, context=context)\n", "\n", "print(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\")\n", "\n", "# Answer: 'dezembro de 2019', score: 0.5087, start: 290, end: 306\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## How to use the model... with the Auto classes\n"]}, {"cell_type": "code", "metadata": {}, "source": ["from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n", "\n", "tokenizer = AutoTokenizer.from_pretrained(\"pierreguillou/bert-large-cased-squad-v1.1-portuguese\")\n", "model = AutoModelForQuestionAnswering.from_pretrained(\"pierreguillou/bert-large-cased-squad-v1.1-portuguese\")\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Or just clone the model repo:\n"]}, {"cell_type": "code", "metadata": {}, "source": ["git lfs install\n", "git clone https://huggingface.co/pierreguillou/bert-large-cased-squad-v1.1-portuguese\n", "\n", "# if you want to clone without large files – just their pointers\n", "# prepend your git clone with the following env var:\n", "\n", "GIT_LFS_SKIP_SMUDGE=1\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Limitations and bias\n", "\n", "The training data used for this model come from Portuguese SQUAD. It could contain a lot of unfiltered content, which is far from neutral, and biases.\n", "\n", "## Author\n", "\n", "Portuguese BERT large cased QA (Question Answering), finetuned on SQUAD v1.1 was trained and evaluated by [Pierre GUILLOU](https://www.linkedin.com/in/pierreguillou/) thanks to the Open Source code, platforms and advices of many organizations ([link to the list](https://medium.com/@pierre_guillou/nlp-como-treinar-um-modelo-de-question-answering-em-qualquer-linguagem-baseado-no-bert-large-1c899262dd96#c2f5)). In particular: [Hugging Face](https://huggingface.co/), [Neuralmind.ai](https://neuralmind.ai/), [Deep Learning Brasil group](http://www.deeplearningbrasil.com.br/) and [AI Lab](https://ailab.unb.br/).\n", "\n", "## Citation\n", "If you use our work, please cite:\n"]}, {"cell_type": "code", "metadata": {}, "source": ["@inproceedings{pierreguillou2021bertlargecasedsquadv11portuguese,\n", "title={Portuguese BERT large cased QA (Question Answering), finetuned on SQUAD v1.1},\n", "author={Pierre Guillou},\n", "year={2021}\n", "}\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["> 此模型来源于：[https://huggingface.co/pierreguillou/bert-large-cased-squad-v1.1-portuguese](https://huggingface.co/https://huggingface.co/pierreguillou/bert-large-cased-squad-v1.1-portuguese)"]}, {"cell_type": "markdown", "metadata": {}, "source": "> this model is from [pierreguillou/bert-large-cased-squad-v1.1-portuguese](https://huggingface.co/pierreguillou/bert-large-cased-squad-v1.1-portuguese)"}], "metadata": {"language_info": {"name": "python"}, "orig_nbformat": 4}, "nbformat": 4, "nbformat_minor": 2}