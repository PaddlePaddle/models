{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# NT5, a T5 model trained to perform numerical reasoning\n", "\n", "T5-small model pre-trained on 3 million (partly synthetic) texts and fine-tuned on [DROP](https://allennlp.org/drop.html). It was introduced in the paper [NT5?! Training T5 to Perform Numerical Reasoning](https://arxiv.org/abs/2104.07307) by Yang et al. and first released in [this repository](https://github.com/lesterpjy/numeric-t5). As the original implementation was in Tensorflow 2, I've converted the weigths to PyTorch. This model corresponds to RC Experiment 1 (see the paper), their best performing model.\n", "\n", "Disclaimer: The team releasing NT5 did not write a model card for this model so this model card has been written by me.\n", "\n", "## Model description\n", "\n", "The NT5 model is a T5 model, in other words, an encoder-decoder Transformer. In order to encourage numerical reasoning, the model was further pre-trained on three datasets designed to strengthen skills necessary for numerical reasoning over text (NRoT) and general reading comprehension before being fine-tuned on the Discrete Reasoning over Text (DROP) dataset.\n", "\n", "## Intended uses & limitations\n", "\n", "You can use the model for numerical reasoning over text.\n", "\n", "### How to use\n", "\n", "Here is how to use this model:\n"]}, {"cell_type": "code", "metadata": {}, "source": ["from transformers import T5Tokenizer, T5ForConditionalGeneration\n", "\n", "context = \"\"\"Saint Jean de Brébeuf was a French Jesuit missionary who\n", "travelled to New France in 1625. There he worked primarily with the Huron\n", "for the rest of his life, except for a few years in France from 1629 to\n", "1633. He learned their language and culture, writing extensively about\n", "each to aid other missionaries. In 1649, Br´ebeuf and another missionary\n", "were captured when an Iroquois raid took over a Huron village . Together\n", "with Huron captives, the missionaries were ritually tortured and killed\n", "on March 16, 1649. Br´ebeuf was beatified in 1925 and among eight Jesuit\n", "missionaries canonized as saints in the Roman Catholic Church in 1930.\"\"\"\n", "\n", "question = \"How many years did Saint Jean de Brébeuf stay in New France\n", "before he went back to France for a few years?\"\n", "\n", "tokenizer = T5Tokenizer.from_pretrained(\"nielsr/nt5-small-rc1\")\n", "model = T5ForConditionalGeneration.from_pretrained(\"nielsr/nt5-small-rc1\")\n", "\n", "# encode context & question\n", "input_text = f\"answer_me: {question} context: {context}\"\n", "encoded_query = tokenizer(\n", "input_text,\n", "return_tensors='pt',\n", "padding='max_length',\n", "truncation=True,\n", "max_length=512)\n", "\n", "# generate answer\n", "generated_answer = model.generate(input_ids=encoded_query[\"input_ids\"],\n", "attention_mask=encoded_query[\"attention_mask\"],\n", "max_length=54)\n", "\n", "decoded_answer = tokenizer.decode(generated_answer.numpy()[0])\n", "print(\"T5 Answer: \", decoded_answer)\n", "T5 Answer: 4\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Evaluation results\n", "\n", "This model achieves an F1 score of 0.7031 and exact match of 0.6687 on the development set of DROP.\n", "\n", "\n", "### BibTeX entry and citation info\n"]}, {"cell_type": "code", "metadata": {}, "source": ["@misc{yang2021nt5,\n", "title={NT5?! Training T5 to Perform Numerical Reasoning},\n", "author={Peng-Jian Yang and Ying Ting Chen and Yuechan Chen and Daniel Cer},\n", "year={2021},\n", "eprint={2104.07307},\n", "archivePrefix={arXiv},\n", "primaryClass={cs.CL}\n", "}\n"]}, {"cell_type": "code", "metadata": {}, "source": ["@article{DBLP:journals/corr/abs-1903-00161,\n", "author    = {Dheeru Dua and\n", "Yizhong Wang and\n", "Pradeep Dasigi and\n", "Gabriel Stanovsky and\n", "Sameer Singh and\n", "Matt Gardner},\n", "title     = {{DROP:} {A} Reading Comprehension Benchmark Requiring Discrete Reasoning\n", "Over Paragraphs},\n", "journal   = {CoRR},\n", "volume    = {abs/1903.00161},\n", "year      = {2019},\n", "url       = {http://arxiv.org/abs/1903.00161},\n", "archivePrefix = {arXiv},\n", "eprint    = {1903.00161},\n", "timestamp = {Wed, 03 Jul 2019 07:17:04 +0200},\n", "biburl    = {https://dblp.org/rec/journals/corr/abs-1903-00161.bib},\n", "bibsource = {dblp computer science bibliography, https://dblp.org}\n", "}\n", "a service of Schloss Dagstuhl - Leibniz Center for Informatics\\\\\\\\thomebrowsesearchabout\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["> 此模型来源于：[https://huggingface.co/nielsr/nt5-small-rc1](https://huggingface.co/https://huggingface.co/nielsr/nt5-small-rc1)"]}, {"cell_type": "markdown", "metadata": {}, "source": "> this model is from [nielsr/nt5-small-rc1](https://huggingface.co/nielsr/nt5-small-rc1)"}], "metadata": {"language_info": {"name": "python"}, "orig_nbformat": 4}, "nbformat": 4, "nbformat_minor": 2}