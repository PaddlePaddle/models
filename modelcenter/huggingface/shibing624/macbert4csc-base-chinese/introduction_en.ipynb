{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# MacBERT for Chinese Spelling Correction(macbert4csc) Model\n", "中文拼写纠错模型\n", "\n", "`macbert4csc-base-chinese` evaluate SIGHAN2015 test data：\n", "\n", "- Char Level:     precision:0.9372, recall:0.8640, f1:0.8991\n", "- Sentence Level: precision:0.8264, recall:0.7366, f1:0.7789\n", "\n", "由于训练使用的数据使用了SIGHAN2015的训练集（复现paper），在SIGHAN2015的测试集上达到SOTA水平。\n", "\n", "模型结构，魔改于softmaskedbert：\n", "\n", "![arch](arch1.png)\n", "\n", "## Usage\n", "\n", "本项目开源在中文文本纠错项目：[pycorrector](https://github.com/shibing624/pycorrector)，可支持macbert4csc模型，通过如下命令调用：\n"]}, {"cell_type": "code", "metadata": {}, "source": ["from pycorrector.macbert.macbert_corrector import MacBertCorrector\n", "\n", "nlp = MacBertCorrector(\"shibing624/macbert4csc-base-chinese\").macbert_correct\n", "\n", "i = nlp('今天新情很好')\n", "print(i)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["当然，你也可使用官方的huggingface/transformers调用：\n", "\n", "*Please use 'Bert' related functions to load this model!*\n"]}, {"cell_type": "code", "metadata": {}, "source": ["import operator\n", "import torch\n", "from transformers import BertTokenizer, BertForMaskedLM\n", "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n", "\n", "tokenizer = BertTokenizer.from_pretrained(\"shibing624/macbert4csc-base-chinese\")\n", "model = BertForMaskedLM.from_pretrained(\"shibing624/macbert4csc-base-chinese\")\n", "model.to(device)\n", "\n", "texts = [\"今天新情很好\", \"你找到你最喜欢的工作，我也很高心。\"]\n", "with torch.no_grad():\n", "outputs = model(**tokenizer(texts, padding=True, return_tensors='pt').to(device))\n", "\n", "def get_errors(corrected_text, origin_text):\n", "sub_details = []\n", "for i, ori_char in enumerate(origin_text):\n", "if ori_char in [' ', '“', '”', '‘', '’', '琊', '\\n', '…', '—', '擤']:\n", "# add unk word\n", "corrected_text = corrected_text[:i] + ori_char + corrected_text[i:]\n", "continue\n", "if i >= len(corrected_text):\n", "continue\n", "if ori_char != corrected_text[i]:\n", "if ori_char.lower() == corrected_text[i]:\n", "# pass english upper char\n", "corrected_text = corrected_text[:i] + ori_char + corrected_text[i + 1:]\n", "continue\n", "sub_details.append((ori_char, corrected_text[i], i, i + 1))\n", "sub_details = sorted(sub_details, key=operator.itemgetter(2))\n", "return corrected_text, sub_details\n", "\n", "result = []\n", "for ids, text in zip(outputs.logits, texts):\n", "_text = tokenizer.decode(torch.argmax(ids, dim=-1), skip_special_tokens=True).replace(' ', '')\n", "corrected_text = _text[:len(text)]\n", "corrected_text, details = get_errors(corrected_text, text)\n", "print(text, ' => ', corrected_text, details)\n", "result.append((corrected_text, details))\n", "print(result)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["output:\n"]}, {"cell_type": "code", "metadata": {}, "source": ["今天新情很好  =>  今天心情很好 [('新', '心', 2, 3)]\n", "你找到你最喜欢的工作，我也很高心。  =>  你找到你最喜欢的工作，我也很高兴。 [('心', '兴', 15, 16)]\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["模型文件组成：\n"]}, {"cell_type": "code", "metadata": {}, "source": ["macbert4csc-base-chinese\n", "├── config.json\n", "├── added_tokens.json\n", "├── pytorch_model.bin\n", "├── special_tokens_map.json\n", "├── tokenizer_config.json\n", "└── vocab.txt\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 训练数据集\n", "#### SIGHAN+Wang271K中文纠错数据集\n", "\n", "\n", "| 数据集 | 语料 | 下载链接 | 压缩包大小 |\n", "| :------- | :--------- | :---------: | :---------: |\n", "| **`SIGHAN+Wang271K中文纠错数据集`** | SIGHAN+Wang271K(27万条) | [百度网盘（密码01b9）](https://pan.baidu.com/s/1BV5tr9eONZCI0wERFvr0gQ)| 106M |\n", "| **`原始SIGHAN数据集`** | SIGHAN13 14 15 | [官方csc.html](http://nlp.ee.ncu.edu.tw/resource/csc.html)| 339K |\n", "| **`原始Wang271K数据集`** | Wang271K | [Automatic-Corpus-Generation dimmywang提供](https://github.com/wdimmy/Automatic-Corpus-Generation/blob/master/corpus/train.sgml)| 93M |\n", "\n", "\n", "SIGHAN+Wang271K中文纠错数据集，数据格式：\n"]}, {"cell_type": "code", "metadata": {}, "source": ["[\n", "{\n", "\"id\": \"B2-4029-3\",\n", "\"original_text\": \"晚间会听到嗓音，白天的时候大家都不会太在意，但是在睡觉的时候这嗓音成为大家的恶梦。\",\n", "\"wrong_ids\": [\n", "5,\n", "31\n", "],\n", "\"correct_text\": \"晚间会听到噪音，白天的时候大家都不会太在意，但是在睡觉的时候这噪音成为大家的恶梦。\"\n", "},\n", "]\n"]}, {"cell_type": "code", "metadata": {}, "source": ["macbert4csc\n", "├── config.json\n", "├── pytorch_model.bin\n", "├── special_tokens_map.json\n", "├── tokenizer_config.json\n", "└── vocab.txt\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["如果需要训练macbert4csc，请参考[https://github.com/shibing624/pycorrector/tree/master/pycorrector/macbert](https://github.com/shibing624/pycorrector/tree/master/pycorrector/macbert)\n", "\n", "\n", "### About MacBERT\n", "**MacBERT** is an improved BERT with novel **M**LM **a**s **c**orrection pre-training task, which mitigates the discrepancy of pre-training and fine-tuning.\n", "\n", "Here is an example of our pre-training task.\n", "\n", "| task  | Example       |\n", "| -------------- | ----------------- |\n", "| **Original Sentence**  | we use a language model to predict the probability of the next word. |\n", "|  **MLM** | we use a language [M] to [M] ##di ##ct the pro [M] ##bility of the next word . |\n", "| **Whole word masking**   | we use a language [M] to [M] [M] [M] the [M] [M] [M] of the next word . |\n", "| **N-gram masking** | we use a [M] [M] to [M] [M] [M] the [M] [M] [M] [M] [M] next word . |\n", "| **MLM as correction** | we use a text system to ca ##lc ##ulate the po ##si ##bility of the next word . |\n", "\n", "Except for the new pre-training task, we also incorporate the following techniques.\n", "\n", "- Whole Word Masking (WWM)\n", "- N-gram masking\n", "- Sentence-Order Prediction (SOP)\n", "\n", "**Note that our MacBERT can be directly replaced with the original BERT as there is no differences in the main neural architecture.**\n", "\n", "For more technical details, please check our paper: [Revisiting Pre-trained Models for Chinese Natural Language Processing](https://arxiv.org/abs/2004.13922)\n", "\n", "\n", "## Citation\n"]}, {"cell_type": "code", "metadata": {}, "source": ["@software{pycorrector,\n", "author = {Xu Ming},\n", "title = {pycorrector: Text Error Correction Tool},\n", "year = {2021},\n", "url = {https://github.com/shibing624/pycorrector},\n", "}\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["> 此模型来源于：[https://huggingface.co/shibing624/macbert4csc-base-chinese](https://huggingface.co/https://huggingface.co/shibing624/macbert4csc-base-chinese)"]}, {"cell_type": "markdown", "metadata": {}, "source": "> this model is from [shibing624/macbert4csc-base-chinese](https://huggingface.co/shibing624/macbert4csc-base-chinese)"}], "metadata": {"language_info": {"name": "python"}, "orig_nbformat": 4}, "nbformat": 4, "nbformat_minor": 2}