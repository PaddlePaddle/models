{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# ✨ bert-restore-punctuation\n", "[![forthebadge](https://forthebadge.com/images/badges/gluten-free.svg)]()\n", "\n", "This a bert-base-uncased model finetuned for punctuation restoration on [Yelp Reviews](https://www.tensorflow.org/datasets/catalog/yelp_polarity_reviews).\n", "\n", "The model predicts the punctuation and upper-casing of plain, lower-cased text. An example use case can be ASR output. Or other cases when text has lost punctuation.\n", "\n", "This model is intended for direct use as a punctuation restoration model for the general English language. Alternatively, you can use this for further fine-tuning on domain-specific texts for punctuation restoration tasks.\n", "\n", "Model restores the following punctuations -- **[! ? . , - : ; ' ]**\n", "\n", "The model also restores the upper-casing of words.\n", "\n", "-----------------------------------------------\n", "## 🚋 Usage\n", "**Below is a quick way to get up and running with the model.**\n", "1. First, install the package.\n"]}, {"cell_type": "code", "metadata": {}, "source": "import paddle\nfrom paddlenlp.transformers import AutoModel\n\nmodel = AutoModel.from_pretrained(\"felflare/bert-restore-punctuation\")\ninput_ids = paddle.randint(100, 200, shape=[1, 20])\nprint(model(input_ids))"}, {"cell_type": "markdown", "metadata": {}, "source": ["**This model works on arbitrarily large text in English language and uses GPU if available.**\n", "\n", "-----------------------------------------------\n", "## 📡 Training data\n", "\n", "Here is the number of product reviews we used for finetuning the model:\n", "\n", "| Language | Number of text samples|\n", "| -------- | ----------------- |\n", "| English  | 560,000           |\n", "\n", "We found the best convergence around _**3 epochs**_, which is what presented here and available via a download.\n", "\n", "-----------------------------------------------\n", "## 🎯 Accuracy\n", "The fine-tuned model obtained the following accuracy on 45,990 held-out text samples:\n", "\n", "| Accuracy | Overall F1 | Eval Support |\n", "| -------- | ---------------------- | ------------------- |\n", "| 91%  | 90%                 | 45,990\n", "\n", "Below is a breakdown of the performance of the model by each label:\n", "\n", "|  label    |   precision  |  recall | f1-score  | support|\n", "| --------- | -------------|-------- | ----------|--------|\n", "|     **!**    |   0.45       | 0.17    |  0.24     |  424\n", "|     **!+Upper**    |   0.43       | 0.34    |  0.38     |   98\n", "|     **'**    |   0.60       | 0.27    |  0.37     |   11\n", "|    **,**    |   0.59       | 0.51    |  0.55     | 1522\n", "|     **,+Upper**    |   0.52       | 0.50    |  0.51     |  239\n", "|     **-**    |   0.00       | 0.00    |  0.00     |   18\n", "|     **.**    |   0.69       | 0.84    |  0.75     | 2488\n", "|     **.+Upper**    |   0.65       | 0.52    |  0.57     |  274\n", "|     **:**    |   0.52       | 0.31    |  0.39     |   39\n", "|     **:+Upper**    |   0.36       | 0.62    |  0.45     |   16\n", "|     **;**    |   0.00       | 0.00    |  0.00     |   17\n", "|     **?**    |   0.54       | 0.48    |  0.51     |   46\n", "|     **?+Upper**    |   0.40       | 0.50    |  0.44     |    4\n", "|     **none**    |   0.96       | 0.96    |  0.96     |35352\n", "|     **Upper**    |   0.84       | 0.82    |  0.83     | 5442\n", "\n", "-----------------------------------------------\n", "## ☕ Contact\n", "Contact [Daulet Nurmanbetov](daulet.nurmanbetov@gmail.com) for questions, feedback and/or requests for similar models.\n", "\n", "-----------------------------------------------\n", "> 此模型来源于：[https://huggingface.co/felflare/bert-restore-punctuation](https://huggingface.co/https://huggingface.co/felflare/bert-restore-punctuation)"]}, {"cell_type": "markdown", "metadata": {}, "source": "> this model is from [felflare/bert-restore-punctuation](https://huggingface.co/felflare/bert-restore-punctuation)"}], "metadata": {"language_info": {"name": "python"}, "orig_nbformat": 4}, "nbformat": 4, "nbformat_minor": 2}