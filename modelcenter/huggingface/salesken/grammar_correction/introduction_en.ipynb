{"cells": [{"cell_type": "markdown", "metadata": {}, "source": []}, {"cell_type": "code", "metadata": {}, "source": ["from transformers import AutoTokenizer, AutoModelWithLMHead, AutoModelForCausalLM\n", "import torch\n", "if torch.cuda.is_available():\n", "device = torch.device(\"cuda\")\n", "else :\n", "device = \"cpu\"\n", "\n", "\n", "tokenizer = AutoTokenizer.from_pretrained(\"salesken/grammar_correction\")\n", "model = AutoModelForCausalLM.from_pretrained(\"salesken/grammar_correction\").to(device)\n", "\n", "input_query=\"what be the reason for everyone leave the company\"\n", "query= \"<|startoftext|> \" + input_query + \" ~~~\"\n", "\n", "\n", "input_ids = tokenizer.encode(query.lower(), return_tensors='pt').to(device)\n", "sample_outputs = model.generate(input_ids,\n", "do_sample=True,\n", "num_beams=1,\n", "max_length=128,\n", "temperature=0.9,\n", "top_p= 0.7,\n", "top_k = 5,\n", "num_return_sequences=3)\n", "corrected_sentences = []\n", "for i in range(len(sample_outputs)):\n", "r = tokenizer.decode(sample_outputs[i], skip_special_tokens=True).split('||')[0]\n", "r = r.split('~~~')[1]\n", "if r not in corrected_sentences:\n", "corrected_sentences.append(r)\n", "\n", "print(corrected_sentences)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["> 此模型来源于：[https://huggingface.co/salesken/grammar_correction](https://huggingface.co/https://huggingface.co/salesken/grammar_correction)"]}, {"cell_type": "markdown", "metadata": {}, "source": "> this model is from [salesken/grammar_correction](https://huggingface.co/salesken/grammar_correction)"}], "metadata": {"language_info": {"name": "python"}, "orig_nbformat": 4}, "nbformat": 4, "nbformat_minor": 2}