{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# T5 One Line Summary\n", "A T5 model trained on 370,000 research papers, to generate one line summary based on description/abstract of the papers. It is trained using [simpleT5](https://github.com/Shivanandroy/simpleT5) library - A python package built on top of pytorch lightningâš¡ï¸ & transformersðŸ¤— to quickly train T5 models\n", "\n", "## Usage:[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1HrfT8IKLXvZzPFpl1EhZ3s_iiXG3O2VY?usp=sharing)\n"]}, {"cell_type": "code", "metadata": {}, "source": ["abstract = \"\"\"We describe a system called Overton, whose main design goal is to support engineers in building, monitoring, and improving production\n", "machine learning systems. Key challenges engineers face are monitoring fine-grained quality, diagnosing errors in sophisticated applications, and\n", "handling contradictory or incomplete supervision data. Overton automates the life cycle of model construction, deployment, and monitoring by providing a\n", "set of novel high-level, declarative abstractions. Overton's vision is to shift developers to these higher-level tasks instead of lower-level machine learning tasks.\n", "In fact, using Overton, engineers can build deep-learning-based applications without writing any code in frameworks like TensorFlow. For over a year,\n", "Overton has been used in production to support multiple applications in both near-real-time applications and back-of-house processing. In that time,\n", "Overton-based applications have answered billions of queries in multiple languages and processed trillions of records reducing errors 1.7-2.9 times versus production systems.\n", "\"\"\"\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Using TransformersðŸ¤—\n"]}, {"cell_type": "code", "metadata": {}, "source": ["model_name = \"snrspeaks/t5-one-line-summary\"\n", "\n", "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n", "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n", "tokenizer = AutoTokenizer.from_pretrained(model_name)\n", "input_ids = tokenizer.encode(\"summarize: \" + abstract, return_tensors=\"pt\", add_special_tokens=True)\n", "generated_ids = model.generate(input_ids=input_ids,num_beams=5,max_length=50,repetition_penalty=2.5,length_penalty=1,early_stopping=True,num_return_sequences=3)\n", "preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_ids]\n", "print(preds)\n", "\n", "# output\n", "[\"Overton: Building, Deploying, and Monitoring Machine Learning Systems for Engineers\",\n", "\"Overton: A System for Building, Monitoring, and Improving Production Machine Learning Systems\",\n", "\"Overton: Building, Monitoring, and Improving Production Machine Learning Systems\"]\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Using simpleT5âš¡ï¸\n"]}, {"cell_type": "code", "metadata": {}, "source": ["# pip install --upgrade simplet5\n", "from simplet5 import SimpleT5\n", "model = SimpleT5()\n", "model.load_model(\"t5\",\"snrspeaks/t5-one-line-summary\")\n", "model.predict(abstract)\n", "\n", "# output\n", "\"Overton: Building, Deploying, and Monitoring Machine Learning Systems for Engineers\"\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["> æ­¤æ¨¡åž‹æ¥æºäºŽï¼š[https://huggingface.co/snrspeaks/t5-one-line-summary](https://huggingface.co/https://huggingface.co/snrspeaks/t5-one-line-summary)"]}, {"cell_type": "markdown", "metadata": {}, "source": "> this model is from [snrspeaks/t5-one-line-summary](https://huggingface.co/snrspeaks/t5-one-line-summary)"}], "metadata": {"language_info": {"name": "python"}, "orig_nbformat": 4}, "nbformat": 4, "nbformat_minor": 2}