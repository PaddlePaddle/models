{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["This is a version of the [cointegrated/rut5-small](https://huggingface.co/cointegrated/rut5-small) model fine-tuned on some Russian dialogue data. It is not very smart and creative, but it is small and fast, and can serve as a fallback response generator for some chatbot or can be fine-tuned to imitate the style of someone.\n", "\n", "The input of the model is the previous dialogue utterances separated by `'\\n\\n'`, and the output is the next utterance.\n", "\n", "The model can be used as follows:\n"]}, {"cell_type": "code", "metadata": {}, "source": ["# !pip install transformers sentencepiece\n", "import torch\n", "from transformers import T5ForConditionalGeneration, T5Tokenizer\n", "\n", "tokenizer = T5Tokenizer.from_pretrained(\"cointegrated/rut5-small-chitchat\")\n", "model = T5ForConditionalGeneration.from_pretrained(\"cointegrated/rut5-small-chitchat\")\n", "\n", "text = 'Привет! Расскажи, как твои дела?'\n", "inputs = tokenizer(text, return_tensors='pt')\n", "with torch.no_grad():\n", "hypotheses = model.generate(\n", "**inputs,\n", "do_sample=True, top_p=0.5, num_return_sequences=3,\n", "repetition_penalty=2.5,\n", "max_length=32,\n", ")\n", "for h in hypotheses:\n", "print(tokenizer.decode(h, skip_special_tokens=True))\n", "# Как обычно.\n", "# Сейчас - в порядке.\n", "# Хорошо.\n", "# Wall time: 363 ms\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["> 此模型来源于：[https://huggingface.co/cointegrated/rut5-small-chitchat](https://huggingface.co/https://huggingface.co/cointegrated/rut5-small-chitchat)"]}, {"cell_type": "markdown", "metadata": {}, "source": "> this model is from [cointegrated/rut5-small-chitchat](https://huggingface.co/cointegrated/rut5-small-chitchat)"}], "metadata": {"language_info": {"name": "python"}, "orig_nbformat": 4}, "nbformat": 4, "nbformat_minor": 2}