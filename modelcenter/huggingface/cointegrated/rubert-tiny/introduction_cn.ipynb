{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["This is a very small distilled version of the [bert-base-multilingual-cased](https://huggingface.co/bert-base-multilingual-cased) model for Russian and English (45 MB, 12M parameters). There is also an **updated version of this model**, [rubert-tiny2](https://huggingface.co/cointegrated/rubert-tiny2), with a larger vocabulary and better quality on practically all Russian NLU tasks.\n", "\n", "This model is useful if you want to fine-tune it for a relatively simple Russian task (e.g. NER or sentiment classification), and you care more about speed and size than about accuracy. It is approximately x10 smaller and faster than a base-sized BERT. Its `[CLS]` embeddings can be used as a sentence representation aligned between Russian and English.\n", "\n", "It was trained on the [Yandex Translate corpus](https://translate.yandex.ru/corpus), [OPUS-100](https://huggingface.co/datasets/opus100) and [Tatoeba](https://huggingface.co/datasets/tatoeba), using MLM loss (distilled from [bert-base-multilingual-cased](https://huggingface.co/bert-base-multilingual-cased)), translation ranking loss, and `[CLS]` embeddings distilled from [LaBSE](https://huggingface.co/sentence-transformers/LaBSE), [rubert-base-cased-sentence](https://huggingface.co/DeepPavlov/rubert-base-cased-sentence), Laser and USE.\n", "\n", "There is a more detailed [description in Russian](https://habr.com/ru/post/562064/).\n", "\n", "Sentence embeddings can be produced as follows:\n"]}, {"cell_type": "code", "metadata": {}, "source": ["# pip install transformers sentencepiece\n", "import torch\n", "from transformers import AutoTokenizer, AutoModel\n", "tokenizer = AutoTokenizer.from_pretrained(\"cointegrated/rubert-tiny\")\n", "model = AutoModel.from_pretrained(\"cointegrated/rubert-tiny\")\n", "# model.cuda()  # uncomment it if you have a GPU\n", "\n", "def embed_bert_cls(text, model, tokenizer):\n", "t = tokenizer(text, padding=True, truncation=True, return_tensors='pt')\n", "with torch.no_grad():\n", "model_output = model(**{k: v.to(model.device) for k, v in t.items()})\n", "embeddings = model_output.last_hidden_state[:, 0, :]\n", "embeddings = torch.nn.functional.normalize(embeddings)\n", "return embeddings[0].cpu().numpy()\n", "\n", "print(embed_bert_cls('привет мир', model, tokenizer).shape)\n", "# (312,)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["> 此模型来源于：[https://huggingface.co/cointegrated/rubert-tiny](https://huggingface.co/https://huggingface.co/cointegrated/rubert-tiny)"]}, {"cell_type": "markdown", "metadata": {}, "source": "> this model is from [cointegrated/rubert-tiny](https://huggingface.co/cointegrated/rubert-tiny)"}], "metadata": {"language_info": {"name": "python"}, "orig_nbformat": 4}, "nbformat": 4, "nbformat_minor": 2}