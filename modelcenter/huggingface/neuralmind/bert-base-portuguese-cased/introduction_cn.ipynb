{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# BERTimbau Base (aka \"bert-base-portuguese-cased\")\n", "\n", "![Bert holding a berimbau](https://imgur.com/JZ7Hynh.jpg)\n", "\n", "## Introduction\n", "\n", "BERTimbau Base is a pretrained BERT model for Brazilian Portuguese that achieves state-of-the-art performances on three downstream NLP tasks: Named Entity Recognition, Sentence Textual Similarity and Recognizing Textual Entailment. It is available in two sizes: Base and Large.\n", "\n", "For further information or requests, please go to [BERTimbau repository](https://github.com/neuralmind-ai/portuguese-bert/).\n", "\n", "## Available models\n", "\n", "| Model                                    | Arch.      | #Layers | #Params |\n", "| ---------------------------------------- | ---------- | ------- | ------- |\n", "| `neuralmind/bert-base-portuguese-cased`  | BERT-Base  | 12      | 110M    |\n", "| `neuralmind/bert-large-portuguese-cased` | BERT-Large | 24      | 335M    |\n", "\n", "## Usage\n"]}, {"cell_type": "code", "metadata": {}, "source": ["from transformers import AutoTokenizer  # Or BertTokenizer\n", "from transformers import AutoModelForPreTraining  # Or BertForPreTraining for loading pretraining heads\n", "from transformers import AutoModel  # or BertModel, for BERT without pretraining heads\n", "\n", "model = AutoModelForPreTraining.from_pretrained('neuralmind/bert-base-portuguese-cased')\n", "tokenizer = AutoTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased', do_lower_case=False)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Masked language modeling prediction example\n"]}, {"cell_type": "code", "metadata": {}, "source": ["from transformers import pipeline\n", "\n", "pipe = pipeline('fill-mask', model=model, tokenizer=tokenizer)\n", "\n", "pipe('Tinha uma [MASK] no meio do caminho.')\n", "# [{'score': 0.14287759363651276,\n", "#  'sequence': '[CLS] Tinha uma pedra no meio do caminho. [SEP]',\n", "#  'token': 5028,\n", "#  'token_str': 'pedra'},\n", "# {'score': 0.06213393807411194,\n", "#  'sequence': '[CLS] Tinha uma árvore no meio do caminho. [SEP]',\n", "#  'token': 7411,\n", "#  'token_str': 'árvore'},\n", "# {'score': 0.05515013635158539,\n", "#  'sequence': '[CLS] Tinha uma estrada no meio do caminho. [SEP]',\n", "#  'token': 5675,\n", "#  'token_str': 'estrada'},\n", "# {'score': 0.0299188531935215,\n", "#  'sequence': '[CLS] Tinha uma casa no meio do caminho. [SEP]',\n", "#  'token': 1105,\n", "#  'token_str': 'casa'},\n", "# {'score': 0.025660505518317223,\n", "#  'sequence': '[CLS] Tinha uma cruz no meio do caminho. [SEP]',\n", "#  'token': 3466,\n", "#  'token_str': 'cruz'}]\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### For BERT embeddings\n"]}, {"cell_type": "code", "metadata": {}, "source": ["import torch\n", "\n", "model = AutoModel.from_pretrained('neuralmind/bert-base-portuguese-cased')\n", "input_ids = tokenizer.encode('Tinha uma pedra no meio do caminho.', return_tensors='pt')\n", "\n", "with torch.no_grad():\n", "outs = model(input_ids)\n", "encoded = outs[0][0, 1:-1]  # Ignore [CLS] and [SEP] special tokens\n", "\n", "# encoded.shape: (8, 768)\n", "# tensor([[-0.0398, -0.3057,  0.2431,  ..., -0.5420,  0.1857, -0.5775],\n", "#         [-0.2926, -0.1957,  0.7020,  ..., -0.2843,  0.0530, -0.4304],\n", "#         [ 0.2463, -0.1467,  0.5496,  ...,  0.3781, -0.2325, -0.5469],\n", "#         ...,\n", "#         [ 0.0662,  0.7817,  0.3486,  ..., -0.4131, -0.2852, -0.2819],\n", "#         [ 0.0662,  0.2845,  0.1871,  ..., -0.2542, -0.2933, -0.0661],\n", "#         [ 0.2761, -0.1657,  0.3288,  ..., -0.2102,  0.0029, -0.2009]])\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Citation\n", "\n", "If you use our work, please cite:\n"]}, {"cell_type": "code", "metadata": {}, "source": ["@inproceedings{souza2020bertimbau,\n", "author    = {F{\\'a}bio Souza and\n", "Rodrigo Nogueira and\n", "Roberto Lotufo},\n", "title     = {{BERT}imbau: pretrained {BERT} models for {B}razilian {P}ortuguese},\n", "booktitle = {9th Brazilian Conference on Intelligent Systems, {BRACIS}, Rio Grande do Sul, Brazil, October 20-23 (to appear)},\n", "year      = {2020}\n", "}\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["> 此模型来源于：[https://huggingface.co/neuralmind/bert-base-portuguese-cased](https://huggingface.co/https://huggingface.co/neuralmind/bert-base-portuguese-cased)"]}, {"cell_type": "markdown", "metadata": {}, "source": "> this model is from [neuralmind/bert-base-portuguese-cased](https://huggingface.co/neuralmind/bert-base-portuguese-cased)"}], "metadata": {"language_info": {"name": "python"}, "orig_nbformat": 4}, "nbformat": 4, "nbformat_minor": 2}